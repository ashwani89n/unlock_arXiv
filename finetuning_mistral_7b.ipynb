{"cells":[{"cell_type":"markdown","metadata":{"id":"wXMVoEFkPXJJ"},"source":["### **Install Ludwig and Ludwig's LLM related dependencies.**\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yfYXyUUvM-R6","executionInfo":{"status":"ok","timestamp":1733523030868,"user_tz":300,"elapsed":271267,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"d0d7d87c-b557-400e-ead5-3952adfc9a5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/huggingface/transformers\n","  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-b95_k23g\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-b95_k23g\n","  Resolved https://github.com/huggingface/transformers to commit c8c8dffbe45ebef0a8dba4a51024e5e5e498596b\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (0.26.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (2.32.3)\n","Collecting tokenizers<0.22,>=0.21 (from transformers==4.48.0.dev0)\n","  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (0.4.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (4.66.6)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.0.dev0) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.0.dev0) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.48.0.dev0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.48.0.dev0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.48.0.dev0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.48.0.dev0) (2024.8.30)\n","Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: transformers\n","  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.48.0.dev0-py3-none-any.whl size=10185493 sha256=326022e17e01b4b2f5c0abd54557d9d6192e373df5327058b8d59602ac8118f0\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-rb_0kelw/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\n","Successfully built transformers\n","Installing collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.20.3\n","    Uninstalling tokenizers-0.20.3:\n","      Successfully uninstalled tokenizers-0.20.3\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.46.3\n","    Uninstalling transformers-4.46.3:\n","      Successfully uninstalled transformers-4.46.3\n","Successfully installed tokenizers-0.21.0 transformers-4.48.0.dev0\n","Collecting git+https://github.com/huggingface/peft.git\n","  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-_38t0huo\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-_38t0huo\n","  Resolved https://github.com/huggingface/peft.git to commit de88c703065fdd3a05521da1054c0463d16ea33c\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.14.0) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.14.0) (24.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.14.0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.14.0) (6.0.2)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.14.0) (2.5.1+cu121)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft==0.14.0) (4.48.0.dev0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft==0.14.0) (4.66.6)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.14.0) (1.1.1)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.14.0) (0.4.5)\n","Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.14.0) (0.26.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.25.0->peft==0.14.0) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.25.0->peft==0.14.0) (2024.10.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.25.0->peft==0.14.0) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.25.0->peft==0.14.0) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.14.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.14.0) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.14.0) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.14.0) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.14.0) (2024.9.11)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.14.0) (0.21.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft==0.14.0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.25.0->peft==0.14.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.25.0->peft==0.14.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.25.0->peft==0.14.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.25.0->peft==0.14.0) (2024.8.30)\n","Building wheels for collected packages: peft\n","  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for peft: filename=peft-0.14.0-py3-none-any.whl size=374835 sha256=7fdcf25b3643e6528b885d24d1670f56819c88db970fc9cfd7e7558a90125fc3\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-_6_vkzyj/wheels/d7/c7/de/1368fac8590e1b103ddc2ec2a28ad51d83aded1a3830e8a087\n","Successfully built peft\n","Installing collected packages: peft\n","  Attempting uninstall: peft\n","    Found existing installation: peft 0.13.2\n","    Uninstalling peft-0.13.2:\n","      Successfully uninstalled peft-0.13.2\n","Successfully installed peft-0.14.0\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.6/152.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.0/19.0 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.8/80.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.0/232.0 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.0/100.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for ludwig (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for gpustat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","dopamine-rl 4.0.9 requires tensorflow>=2.2.0, which is not installed.\n","albumentations 1.4.20 requires pydantic>=2.7.0, but you have pydantic 1.10.19 which is incompatible.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2023.10.0 which is incompatible.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.1.4 which is incompatible.\n","langchain 0.3.9 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.19 which is incompatible.\n","langchain-core 0.3.21 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.10.19 which is incompatible.\n","mizani 0.13.0 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\n","plotnine 0.14.3 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\n","pymc 5.18.2 requires rich>=13.7.1, but you have rich 12.4.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.2)\n","Collecting datasets\n","  Using cached datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Collecting pyarrow>=15.0.0 (from datasets)\n","  Downloading pyarrow-18.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2023.10.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.9)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (1.26.20)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyarrow-18.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pyarrow, datasets\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 14.0.2\n","    Uninstalling pyarrow-14.0.2:\n","      Successfully uninstalled pyarrow-14.0.2\n","  Attempting uninstall: datasets\n","    Found existing installation: datasets 2.19.2\n","    Uninstalling datasets-2.19.2:\n","      Successfully uninstalled datasets-2.19.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.10.1 requires pyarrow<18.0.0a0,>=14.0.0, but you have pyarrow 18.1.0 which is incompatible.\n","ludwig 0.10.4.dev0 requires pyarrow<15.0.0, but you have pyarrow 18.1.0 which is incompatible.\n","pylibcudf-cu12 24.10.1 requires pyarrow<18.0.0a0,>=14.0.0, but you have pyarrow 18.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.1.0 pyarrow-18.1.0\n","Collecting py7zr\n","  Downloading py7zr-0.22.0-py3-none-any.whl.metadata (16 kB)\n","Collecting texttable (from py7zr)\n","  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n","Collecting pycryptodomex>=3.16.0 (from py7zr)\n","  Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n","Collecting pyzstd>=0.15.9 (from py7zr)\n","  Downloading pyzstd-0.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\n","Collecting pyppmd<1.2.0,>=1.1.0 (from py7zr)\n","  Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n","Collecting pybcj<1.1.0,>=1.0.0 (from py7zr)\n","  Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n","Collecting multivolumefile>=0.2.3 (from py7zr)\n","  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n","Collecting inflate64<1.1.0,>=1.0.0 (from py7zr)\n","  Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n","Collecting brotli>=1.1.0 (from py7zr)\n","  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from py7zr) (5.9.5)\n","Downloading py7zr-0.22.0-py3-none-any.whl (67 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n","Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyzstd-0.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.7/413.7 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n","Installing collected packages: texttable, brotli, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, py7zr\n","Successfully installed brotli-1.1.0 inflate64-1.0.0 multivolumefile-0.2.3 py7zr-0.22.0 pybcj-1.0.2 pycryptodomex-3.21.0 pyppmd-1.1.0 pyzstd-0.16.2 texttable-1.7.0\n","Collecting xformers\n","  Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.26.4)\n","Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from xformers) (2.5.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (2023.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->xformers) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->xformers) (3.0.2)\n","Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xformers\n","Successfully installed xformers-0.0.28.post3\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n","Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.26.3)\n","Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2023.10.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.20)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n","Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.10/dist-packages (2024.10.0)\n","Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (8.1.7)\n","Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (3.1.0)\n","Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2023.10.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (24.2)\n","Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (1.4.2)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (6.0)\n","Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (0.12.1)\n","Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (8.5.0)\n","Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2.1.4)\n","Collecting dask-expr<1.2,>=1.1 (from dask[dataframe])\n","  Downloading dask_expr-1.1.20-py3-none-any.whl.metadata (2.6 kB)\n","INFO: pip is looking at multiple versions of dask-expr to determine which version is compatible with other requirements. This could take a while.\n","  Downloading dask_expr-1.1.19-py3-none-any.whl.metadata (2.6 kB)\n","  Downloading dask_expr-1.1.18-py3-none-any.whl.metadata (2.6 kB)\n","  Downloading dask_expr-1.1.16-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: pyarrow>=14.0.1 in /usr/local/lib/python3.10/dist-packages (from dask-expr<1.2,>=1.1->dask[dataframe]) (18.1.0)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask[dataframe]) (3.21.0)\n","Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2024.2)\n","Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.4.0->dask[dataframe]) (1.0.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask[dataframe]) (1.16.0)\n","Downloading dask_expr-1.1.16-py3-none-any.whl (243 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.2/243.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: dask-expr\n","Successfully installed dask-expr-1.1.16\n","Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.40.2)\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n","Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n","Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: bitsandbytes\n","  Attempting uninstall: bitsandbytes\n","    Found existing installation: bitsandbytes 0.40.2\n","    Uninstalling bitsandbytes-0.40.2:\n","      Successfully uninstalled bitsandbytes-0.40.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ludwig 0.10.4.dev0 requires bitsandbytes<0.41.0, but you have bitsandbytes 0.45.0 which is incompatible.\n","ludwig 0.10.4.dev0 requires pyarrow<15.0.0, but you have pyarrow 18.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed bitsandbytes-0.45.0\n","Looking in indexes: https://download.pytorch.org/whl/cu118\n","Collecting torch\n","  Downloading https://download.pytorch.org/whl/cu118/torch-2.5.1%2Bcu118-cp310-cp310-linux_x86_64.whl (838.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m838.3/838.3 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.20.1%2Bcu118-cp310-cp310-linux_x86_64.whl (6.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchaudio\n","  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.5.1%2Bcu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchtext\n","  Downloading https://download.pytorch.org/whl/torchtext-0.17.0%2Bcpu-cp310-cp310-linux_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.10.0)\n","Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m318.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting triton==3.1.0 (from torch)\n","  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.32.3)\n","INFO: pip is looking at multiple versions of torchtext to determine which version is compatible with other requirements. This could take a while.\n","Collecting torchtext\n","  Downloading https://download.pytorch.org/whl/torchtext-0.16.2%2Bcpu-cp310-cp310-linux_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading https://download.pytorch.org/whl/torchtext-0.16.1%2Bcpu-cp310-cp310-linux_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading https://download.pytorch.org/whl/torchtext-0.16.0%2Bcpu-cp310-cp310-linux_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading https://download.pytorch.org/whl/torchtext-0.15.2%2Bcpu-cp310-cp310-linux_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading https://download.pytorch.org/whl/torchtext-0.15.1%2Bcpu-cp310-cp310-linux_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading https://download.pytorch.org/whl/torchtext-0.15.0%2Bcpu-cp310-cp310-linux_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading https://download.pytorch.org/whl/torchtext-0.14.1-cp310-cp310-linux_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is still looking at multiple versions of torchtext to determine which version is compatible with other requirements. This could take a while.\n","  Downloading https://download.pytorch.org/whl/torchtext-0.14.0-cp310-cp310-linux_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading https://download.pytorch.org/whl/torchtext-0.13.1-cp310-cp310-linux_x86_64.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading https://download.pytorch.org/whl/torchtext-0.13.0-cp310-cp310-linux_x86_64.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading https://download.pytorch.org/whl/torchtext-0.12.0-cp310-cp310-linux_x86_64.whl (10.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m120.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading https://download.pytorch.org/whl/torchtext-0.6.0-py3-none-any.whl (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.16.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from torchtext) (0.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (1.26.20)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.8.30)\n","Installing collected packages: triton, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision, torchtext, torchaudio\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ludwig 0.10.4.dev0 requires bitsandbytes<0.41.0, but you have bitsandbytes 0.45.0 which is incompatible.\n","ludwig 0.10.4.dev0 requires pyarrow<15.0.0, but you have pyarrow 18.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 torch-2.5.1+cu118 torchaudio-2.5.1+cu118 torchtext-0.6.0 torchvision-0.20.1+cu118 triton-3.1.0\n","Collecting pymongo\n","  Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n","Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n","  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n","Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: dnspython, pymongo\n","Successfully installed dnspython-2.7.0 pymongo-4.10.1\n"]}],"source":["!pip uninstall -y tensorflow --quiet\n","!pip install --upgrade git+https://github.com/huggingface/transformers\n","!pip install --upgrade git+https://github.com/huggingface/peft.git\n","!pip install git+https://github.com/ludwig-ai/ludwig.git@master --quiet\n","\n","# !pip show torch\n","# !pip show transformers\n","\n","!pip install --upgrade datasets\n","!pip install py7zr\n","!pip install xformers\n","!pip install accelerate\n","# !pip install -i https://pypi.org/simple/ bitsandbytes\n","!pip install dask[dataframe]\n","!pip install -U bitsandbytes\n","\n","!pip uninstall -y torch torchvision torchaudio torchtext --quiet\n","!pip install torch torchvision torchaudio torchtext --index-url https://download.pytorch.org/whl/cu118\n","\n","!pip install pymongo"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"fd_LA_2Wx_qr","executionInfo":{"status":"ok","timestamp":1733523078938,"user_tz":300,"elapsed":18973,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}}},"outputs":[],"source":["import os\n","import copy\n","import gc\n","from typing import Any, Callable\n","import time\n","from functools import wraps\n","from inspect import ( BoundArguments, signature )\n","from collections import OrderedDict\n","from google.colab import data_table\n","import yaml\n","import numpy as np\n","import pandas as pd\n","import torch\n","from torch import Tensor\n","import datasets\n","from datasets import load_dataset, Dataset, DatasetDict\n","import transformers\n","from transformers import BitsAndBytesConfig, AutoModelForCausalLM, LlamaForCausalLM, MistralForCausalLM, AutoTokenizer, LlamaTokenizerFast, GenerationConfig, TextGenerationPipeline, BatchEncoding\n","from transformers.generation.utils import GreedySearchDecoderOnlyOutput\n","from peft import PeftModel, PeftModelForCausalLM, PeftConfig, LoraConfig\n","from ludwig.api import LudwigModel, TrainingResults\n","import logging\n","\n","import datasets\n","import pandas as pd\n","import numpy as np\n","from datasets import load_dataset, Dataset, DatasetDict\n","from google.colab import drive\n","\n","import requests\n","import csv\n","\n","import pymongo\n","from pymongo import MongoClient\n","\n","\n","os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""]},{"cell_type":"markdown","metadata":{"id":"A2SRHcKAJYuu"},"source":["Enable text wrapping so we don't have to scroll horizontally and create a function to flush CUDA cache."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Ht4eVWxB13QL","executionInfo":{"status":"ok","timestamp":1733519658521,"user_tz":300,"elapsed":132,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}}},"outputs":[],"source":["from IPython.display import HTML, display\n","\n","def set_css() -> None:\n","  display(HTML('''\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  '''))\n","\n","get_ipython().events.register('pre_run_cell', set_css)"]},{"cell_type":"markdown","source":["### Fetching ArXiv research papers on below format:\n","\n","- Primary Category: CS - Computer Science\n","- Sub Category: ML - Machine Learning"],"metadata":{"id":"ayHqook3AFOE"}},{"cell_type":"code","source":["# ARXIV Parameters\n","ARXIV_BASE_URL = \"http://export.arxiv.org/api/query\"\n","QUERY = \"cat:cs.LG\"  # Machine Learning category\n","RESULTS_PER_PAGE = 300  # Max allowed per request\n","TOTAL_RESULTS = 10000  # Number of papers to fetch\n","OUTPUT_FILE = \"ml-arxiv-papers-qa.json\"\n","CSV_HEADERS = [\"Paper ID\", \"Title\", \"Abstract\", \"URL\"]\n","DELAY_SECONDS = 1  # Delay between API calls to respect rate limits"],"metadata":{"id":"8NjbWwkOAbOU","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1733519700475,"user_tz":300,"elapsed":151,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"9c5ec7e1-63ed-41cb-d48d-27c16f3deb08"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["# Initialize CSV\n","with open(OUTPUT_FILE, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n","    writer = csv.writer(file)\n","    writer.writerow(CSV_HEADERS)  # Write CSV headers\n","\n","# Fetch and write data in batches\n","for start in range(0, TOTAL_RESULTS, RESULTS_PER_PAGE):\n","    params = {\n","        \"search_query\": QUERY,\n","        \"start\": start,\n","        \"max_results\": RESULTS_PER_PAGE\n","    }\n","\n","    print(f\"Fetching papers\")\n","    response = requests.get(ARXIV_BASE_URL, params=params)\n","\n","    if response.status_code != 200:\n","        print(f\"Error: HTTP {response.status_code}. Exiting...\")\n","        break\n","\n","    # Parse response XML\n","    entries = response.text.split(\"<entry>\")\n","    with open(OUTPUT_FILE, mode=\"a\", newline=\"\", encoding=\"utf-8\") as file:\n","        writer = csv.writer(file)\n","\n","        for entry in entries[1:]:  # Skip first part (not a paper)\n","            try:\n","                paper_id = entry.split(\"<id>\")[1].split(\"</id>\")[0].strip()\n","                title = entry.split(\"<title>\")[1].split(\"</title>\")[0].strip()\n","                abstract = entry.split(\"<summary>\")[1].split(\"</summary>\")[0].strip()\n","                url = entry.split(\"<id>\")[1].split(\"</id>\")[0].strip()\n","\n","                writer.writerow([paper_id, title, abstract, url])\n","            except IndexError:\n","                print(\"Error parsing an entry. Skipping...\")\n","\n","    # Respect rate limits\n","    time.sleep(DELAY_SECONDS)\n","\n","print(f\"Extraction complete! Data saved to {OUTPUT_FILE}.\")"],"metadata":{"id":"O-RZCrhp_Ue8","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1733519679731,"user_tz":300,"elapsed":1681,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"cb2807e7-88ab-4971-d168-be7397417431"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fetching papers\n","Extraction complete! Data saved to ml-arxiv-papers-qa.json.\n"]}]},{"cell_type":"markdown","source":["### Update Dataset to MongoDB\n","\n","- generate the dataset in the form of questionarie using \"question-generation\" model.\n","- Pushing the current Abstracts to MongoDB to re-use the dataset for persistant storage option.\n","- increase the dataset size by collecting weekly to get new abstracts"],"metadata":{"id":"gqV8lIcWA2UE"}},{"cell_type":"code","source":["client = pymongo.MongoClient(\"mongodb+srv://demo:demo123@cluster0.0q3b1.mongodb.net/expense_tracker?retryWrites=true&w=majority&appName=Cluster0\")\n","\n","db = client[\"arxiv_collection\"]\n","collection = db[\"abstracts\"]\n","\n","def generate_qa_pairs(abstract):\n","    nlp = transformers.pipeline(\"question-generation\")\n","    qa_pairs = nlp(abstract)\n","    return \"input: \"+qa_pairs[\"question\"] + '\\n' + \"answer: \"+qa_pairs[\"answer\"]\n","\n","with open(OUTPUT_FILE, mode=\"r\", newline=\"\", encoding=\"utf-8\") as file:\n","    csv_reader = csv.reader(file)\n","    for row in csv_reader:\n","        paper_id = row[0]\n","        title = row[1]\n","        abstract = row[2]\n","        url = row[3]\n","        document = {\n","            \"paper_id\": paper_id,\n","            \"title\": title,\n","            \"abstract\": abstract,\n","            \"url\": url,\n","            \"input\": generate_qa_pairs(abstract)\n","        }\n","        collection.insert_one(document)"],"metadata":{"id":"_FsvuuElBCZ4","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1733519707158,"user_tz":300,"elapsed":1067,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"e7475139-e0f2-4ed7-d3dc-313b01821d68"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"code","execution_count":9,"metadata":{"id":"E_dFOQDtqY3R","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1733519721475,"user_tz":300,"elapsed":217,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"44ca3679-3fdd-40e3-ea65-460629d685c4"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["def predict(model: LudwigModel, df_test: pd.DataFrame) -> list[list[str]]:\n","    return model.predict(df_test)[0][\"answer_response\"].tolist()"]},{"cell_type":"markdown","metadata":{"id":"sV0D2rjRbk4z"},"source":["### **Import Dataset** 📋\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8TVKCCU4xKuo"},"source":["#### Import Dataset from MongoDB and connect to Google Drive\n","\n","- The current Dataset will be act as training dataset for the model that's get generated and stored in google drive."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"mLHPamZCxAt2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733523145022,"user_tz":300,"elapsed":21698,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"ced51dca-526b-4e8e-8c0c-482bcc79c4ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"rShxBWx3xKZi","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1733519807049,"user_tz":300,"elapsed":177,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"f25a56df-74c3-425d-cd9b-274730b1ffce"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["drive_path = '/content/drive/MyDrive/project-kalki/'\n","content_path = '/content/drive/MyDrive/project-kalki/ml-arxiv-papers-qa.json'"]},{"cell_type":"code","source":["import json\n","cursor = collection.find()\n","data = []\n","for doc in cursor:\n","    print(doc)\n","    doc[\"_id\"] = str(doc[\"_id\"])\n","    data.append(doc)\n","\n","with open(content_path, 'w') as file:\n","    json.dump(data, file, indent=4)"],"metadata":{"id":"wZ5-vWwECyLW","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1733519770629,"user_tz":300,"elapsed":285,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"c768e67c-aed7-468c-92ce-33060c72832f"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'_id': ObjectId('675348f9cd70c010f2b578df'), 'paper_id': 'Paper ID', 'title': 'Title', 'abstract': 'Abstract', 'url': 'URL'}\n","{'_id': ObjectId('675348facd70c010f2b578e0'), 'paper_id': 'http://arxiv.org/abs/cs/9905014v1', 'title': 'Hierarchical Reinforcement Learning with the MAXQ Value Function\\n  Decomposition', 'abstract': 'This paper presents the MAXQ approach to hierarchical reinforcement learning\\nbased on decomposing the target Markov decision process (MDP) into a hierarchy\\nof smaller MDPs and decomposing the value function of the target MDP into an\\nadditive combination of the value functions of the smaller MDPs. The paper\\ndefines the MAXQ hierarchy, proves formal results on its representational\\npower, and establishes five conditions for the safe use of state abstractions.\\nThe paper presents an online model-free learning algorithm, MAXQ-Q, and proves\\nthat it converges wih probability 1 to a kind of locally-optimal policy known\\nas a recursively optimal policy, even in the presence of the five kinds of\\nstate abstraction. The paper evaluates the MAXQ representation and MAXQ-Q\\nthrough a series of experiments in three domains and shows experimentally that\\nMAXQ-Q (with state abstractions) converges to a recursively optimal policy much\\nfaster than flat Q learning. The fact that MAXQ learns a representation of the\\nvalue function has an important benefit: it makes it possible to compute and\\nexecute an improved, non-hierarchical policy via a procedure similar to the\\npolicy improvement step of policy iteration. The paper demonstrates the\\neffectiveness of this non-hierarchical execution experimentally. Finally, the\\npaper concludes with a comparison to related work and a discussion of the\\ndesign tradeoffs in hierarchical reinforcement learning.', 'url': 'http://arxiv.org/abs/cs/9905014v1'}\n","{'_id': ObjectId('675348facd70c010f2b578e1'), 'paper_id': 'http://arxiv.org/abs/cs/9905015v1', 'title': 'State Abstraction in MAXQ Hierarchical Reinforcement Learning', 'abstract': 'Many researchers have explored methods for hierarchical reinforcement\\nlearning (RL) with temporal abstractions, in which abstract actions are defined\\nthat can perform many primitive actions before terminating. However, little is\\nknown about learning with state abstractions, in which aspects of the state\\nspace are ignored. In previous work, we developed the MAXQ method for\\nhierarchical RL. In this paper, we define five conditions under which state\\nabstraction can be combined with the MAXQ value function decomposition. We\\nprove that the MAXQ-Q learning algorithm converges under these conditions and\\nshow experimentally that state abstraction is important for the successful\\napplication of MAXQ-Q learning.', 'url': 'http://arxiv.org/abs/cs/9905015v1'}\n","{'_id': ObjectId('675348facd70c010f2b578e2'), 'paper_id': 'http://arxiv.org/abs/cs/0001004v1', 'title': 'Multiplicative Algorithm for Orthgonal Groups and Independent Component\\n  Analysis', 'abstract': 'The multiplicative Newton-like method developed by the author et al. is\\nextended to the situation where the dynamics is restricted to the orthogonal\\ngroup. A general framework is constructed without specifying the cost function.\\nThough the restriction to the orthogonal groups makes the problem somewhat\\ncomplicated, an explicit expression for the amount of individual jumps is\\nobtained. This algorithm is exactly second-order-convergent. The global\\ninstability inherent in the Newton method is remedied by a\\nLevenberg-Marquardt-type variation. The method thus constructed can readily be\\napplied to the independent component analysis. Its remarkable performance is\\nillustrated by a numerical simulation.', 'url': 'http://arxiv.org/abs/cs/0001004v1'}\n","{'_id': ObjectId('675348facd70c010f2b578e3'), 'paper_id': 'http://arxiv.org/abs/cs/0002006v1', 'title': 'Multiplicative Nonholonomic/Newton -like Algorithm', 'abstract': 'We construct new algorithms from scratch, which use the fourth order cumulant\\nof stochastic variables for the cost function. The multiplicative updating rule\\nhere constructed is natural from the homogeneous nature of the Lie group and\\nhas numerous merits for the rigorous treatment of the dynamics. As one\\nconsequence, the second order convergence is shown. For the cost function,\\nfunctions invariant under the componentwise scaling are choosen. By identifying\\npoints which can be transformed to each other by the scaling, we assume that\\nthe dynamics is in a coset space. In our method, a point can move toward any\\ndirection in this coset. Thus, no prewhitening is required.', 'url': 'http://arxiv.org/abs/cs/0002006v1'}\n","{'_id': ObjectId('675348facd70c010f2b578e4'), 'paper_id': 'http://arxiv.org/abs/cs/0009001v3', 'title': 'Complexity analysis for algorithmically simple strings', 'abstract': 'Given a reference computer, Kolmogorov complexity is a well defined function\\non all binary strings. In the standard approach, however, only the asymptotic\\nproperties of such functions are considered because they do not depend on the\\nreference computer. We argue that this approach can be more useful if it is\\nrefined to include an important practical case of simple binary strings.\\nKolmogorov complexity calculus may be developed for this case if we restrict\\nthe class of available reference computers. The interesting problem is to\\ndefine a class of computers which is restricted in a {\\\\it natural} way modeling\\nthe real-life situation where only a limited class of computers is physically\\navailable to us. We give an example of what such a natural restriction might\\nlook like mathematically, and show that under such restrictions some error\\nterms, even logarithmic in complexity, can disappear from the standard\\ncomplexity calculus.\\n  Keywords: Kolmogorov complexity; Algorithmic information theory.', 'url': 'http://arxiv.org/abs/cs/0009001v3'}\n","{'_id': ObjectId('675348facd70c010f2b578e5'), 'paper_id': 'http://arxiv.org/abs/cs/0009007v1', 'title': 'Robust Classification for Imprecise Environments', 'abstract': 'In real-world environments it usually is difficult to specify target\\noperating conditions precisely, for example, target misclassification costs.\\nThis uncertainty makes building robust classification systems problematic. We\\nshow that it is possible to build a hybrid classifier that will perform at\\nleast as well as the best available classifier for any target conditions. In\\nsome cases, the performance of the hybrid actually can surpass that of the best\\nknown classifier. This robust performance extends across a wide variety of\\ncomparison frameworks, including the optimization of metrics such as accuracy,\\nexpected cost, lift, precision, recall, and workforce utilization. The hybrid\\nalso is efficient to build, to store, and to update. The hybrid is based on a\\nmethod for the comparison of classifier performance that is robust to imprecise\\nclass distributions and misclassification costs. The ROC convex hull (ROCCH)\\nmethod combines techniques from ROC analysis, decision analysis and\\ncomputational geometry, and adapts them to the particulars of analyzing learned\\nclassifiers. The method is efficient and incremental, minimizes the management\\nof classifier performance data, and allows for clear visual comparisons and\\nsensitivity analyses. Finally, we point to empirical evidence that a robust\\nhybrid classifier indeed is needed for many real-world problems.', 'url': 'http://arxiv.org/abs/cs/0009007v1'}\n","{'_id': ObjectId('675348fbcd70c010f2b578e6'), 'paper_id': 'http://arxiv.org/abs/cs/0011032v1', 'title': 'Top-down induction of clustering trees', 'abstract': 'An approach to clustering is presented that adapts the basic top-down\\ninduction of decision trees method towards clustering. To this aim, it employs\\nthe principles of instance based learning. The resulting methodology is\\nimplemented in the TIC (Top down Induction of Clustering trees) system for\\nfirst order clustering. The TIC system employs the first order logical decision\\ntree representation of the inductive logic programming system Tilde. Various\\nexperiments with TIC are presented, in both propositional and relational\\ndomains.', 'url': 'http://arxiv.org/abs/cs/0011032v1'}\n","{'_id': ObjectId('675348fbcd70c010f2b578e7'), 'paper_id': 'http://arxiv.org/abs/cs/0011044v1', 'title': 'Scaling Up Inductive Logic Programming by Learning from Interpretations', 'abstract': 'When comparing inductive logic programming (ILP) and attribute-value learning\\ntechniques, there is a trade-off between expressive power and efficiency.\\nInductive logic programming techniques are typically more expressive but also\\nless efficient. Therefore, the data sets handled by current inductive logic\\nprogramming systems are small according to general standards within the data\\nmining community. The main source of inefficiency lies in the assumption that\\nseveral examples may be related to each other, so they cannot be handled\\nindependently.\\n  Within the learning from interpretations framework for inductive logic\\nprogramming this assumption is unnecessary, which allows to scale up existing\\nILP algorithms. In this paper we explain this learning setting in the context\\nof relational databases. We relate the setting to propositional data mining and\\nto the classical ILP setting, and show that learning from interpretations\\ncorresponds to learning from multiple relations and thus extends the\\nexpressiveness of propositional learning, while maintaining its efficiency to a\\nlarge extent (which is not the case in the classical ILP setting).\\n  As a case study, we present two alternative implementations of the ILP system\\nTilde (Top-down Induction of Logical DEcision trees): Tilde-classic, which\\nloads all data in main memory, and Tilde-LDS, which loads the examples one by\\none. We experimentally compare the implementations, showing Tilde-LDS can\\nhandle large data sets (in the order of 100,000 examples or 100 MB) and indeed\\nscales up linearly in the number of examples.', 'url': 'http://arxiv.org/abs/cs/0011044v1'}\n","{'_id': ObjectId('675348fbcd70c010f2b578e8'), 'paper_id': 'http://arxiv.org/abs/cs/0103003v1', 'title': 'Learning Policies with External Memory', 'abstract': \"In order for an agent to perform well in partially observable domains, it is\\nusually necessary for actions to depend on the history of observations. In this\\npaper, we explore a {\\\\it stigmergic} approach, in which the agent's actions\\ninclude the ability to set and clear bits in an external memory, and the\\nexternal memory is included as part of the input to the agent. In this case, we\\nneed to learn a reactive policy in a highly non-Markovian domain. We explore\\ntwo algorithms: SARSA(\\\\lambda), which has had empirical success in partially\\nobservable domains, and VAPS, a new algorithm due to Baird and Moore, with\\nconvergence guarantees in partially observable domains. We compare the\\nperformance of these two algorithms on benchmark problems.\", 'url': 'http://arxiv.org/abs/cs/0103003v1'}\n","{'_id': ObjectId('675348fbcd70c010f2b578e9'), 'paper_id': 'http://arxiv.org/abs/cs/0110036v1', 'title': 'Efficient algorithms for decision tree cross-validation', 'abstract': 'Cross-validation is a useful and generally applicable technique often\\nemployed in machine learning, including decision tree induction. An important\\ndisadvantage of straightforward implementation of the technique is its\\ncomputational overhead. In this paper we show that, for decision trees, the\\ncomputational overhead of cross-validation can be reduced significantly by\\nintegrating the cross-validation with the normal decision tree induction\\nprocess. We discuss how existing decision tree algorithms can be adapted to\\nthis aim, and provide an analysis of the speedups these adaptations may yield.\\nThe analysis is supported by experimental results.', 'url': 'http://arxiv.org/abs/cs/0110036v1'}\n","{'_id': ObjectId('675348fbcd70c010f2b578ea'), 'paper_id': 'http://arxiv.org/abs/cs/0211003v1', 'title': 'Evaluation of the Performance of the Markov Blanket Bayesian Classifier\\n  Algorithm', 'abstract': 'The Markov Blanket Bayesian Classifier is a recently-proposed algorithm for\\nconstruction of probabilistic classifiers. This paper presents an empirical\\ncomparison of the MBBC algorithm with three other Bayesian classifiers: Naive\\nBayes, Tree-Augmented Naive Bayes and a general Bayesian network. All of these\\nare implemented using the K2 framework of Cooper and Herskovits. The\\nclassifiers are compared in terms of their performance (using simple accuracy\\nmeasures and ROC curves) and speed, on a range of standard benchmark data sets.\\nIt is concluded that MBBC is competitive in terms of speed and accuracy with\\nthe other algorithms considered.', 'url': 'http://arxiv.org/abs/cs/0211003v1'}\n","{'_id': ObjectId('675348fbcd70c010f2b578eb'), 'paper_id': 'http://arxiv.org/abs/cs/0211007v1', 'title': 'Approximating Incomplete Kernel Matrices by the em Algorithm', 'abstract': 'In biological data, it is often the case that observed data are available\\nonly for a subset of samples. When a kernel matrix is derived from such data,\\nwe have to leave the entries for unavailable samples as missing. In this paper,\\nwe make use of a parametric model of kernel matrices, and estimate missing\\nentries by fitting the model to existing entries. The parametric model is\\ncreated as a set of spectral variants of a complete kernel matrix derived from\\nanother information source. For model fitting, we adopt the em algorithm based\\non the information geometry of positive definite matrices. We will report\\npromising results on bacteria clustering experiments using two marker\\nsequences: 16S and gyrB.', 'url': 'http://arxiv.org/abs/cs/0211007v1'}\n","{'_id': ObjectId('675348fbcd70c010f2b578ec'), 'paper_id': 'http://arxiv.org/abs/cs/0309015v1', 'title': 'Reliable and Efficient Inference of Bayesian Networks from Sparse Data\\n  by Statistical Learning Theory', 'abstract': 'To learn (statistical) dependencies among random variables requires\\nexponentially large sample size in the number of observed random variables if\\nany arbitrary joint probability distribution can occur.\\n  We consider the case that sparse data strongly suggest that the probabilities\\ncan be described by a simple Bayesian network, i.e., by a graph with small\\nin-degree \\\\Delta. Then this simple law will also explain further data with high\\nconfidence. This is shown by calculating bounds on the VC dimension of the set\\nof those probability measures that correspond to simple graphs. This allows to\\nselect networks by structural risk minimization and gives reliability bounds on\\nthe error of the estimated joint measure without (in contrast to a previous\\npaper) any prior assumptions on the set of possible joint measures.\\n  The complexity for searching the optimal Bayesian networks of in-degree\\n\\\\Delta increases only polynomially in the number of random varibales for\\nconstant \\\\Delta and the optimal joint measure associated with a given graph can\\nbe found by convex optimization.', 'url': 'http://arxiv.org/abs/cs/0309015v1'}\n","{'_id': ObjectId('675348fbcd70c010f2b578ed'), 'paper_id': 'http://arxiv.org/abs/cs/0311042v1', 'title': 'Toward Attribute Efficient Learning Algorithms', 'abstract': 'We make progress on two important problems regarding attribute efficient\\nlearnability.\\n  First, we give an algorithm for learning decision lists of length $k$ over\\n$n$ variables using $2^{\\\\tilde{O}(k^{1/3})} \\\\log n$ examples and time\\n$n^{\\\\tilde{O}(k^{1/3})}$. This is the first algorithm for learning decision\\nlists that has both subexponential sample complexity and subexponential running\\ntime in the relevant parameters. Our approach establishes a relationship\\nbetween attribute efficient learning and polynomial threshold functions and is\\nbased on a new construction of low degree, low weight polynomial threshold\\nfunctions for decision lists. For a wide range of parameters our construction\\nmatches a 1994 lower bound due to Beigel for the ODDMAXBIT predicate and gives\\nan essentially optimal tradeoff between polynomial threshold function degree\\nand weight.\\n  Second, we give an algorithm for learning an unknown parity function on $k$\\nout of $n$ variables using $O(n^{1-1/k})$ examples in time polynomial in $n$.\\nFor $k=o(\\\\log n)$ this yields a polynomial time algorithm with sample\\ncomplexity $o(n)$. This is the first polynomial time algorithm for learning\\nparity on a superconstant number of variables with sublinear sample complexity.', 'url': 'http://arxiv.org/abs/cs/0311042v1'}\n","{'_id': ObjectId('675348fbcd70c010f2b578ee'), 'paper_id': 'http://arxiv.org/abs/cs/0312004v1', 'title': 'Improving spam filtering by combining Naive Bayes with simple k-nearest\\n  neighbor searches', 'abstract': 'Using naive Bayes for email classification has become very popular within the\\nlast few months. They are quite easy to implement and very efficient. In this\\npaper we want to present empirical results of email classification using a\\ncombination of naive Bayes and k-nearest neighbor searches. Using this\\ntechnique we show that the accuracy of a Bayes filter can be improved slightly\\nfor a high number of features and significantly for a small number of features.', 'url': 'http://arxiv.org/abs/cs/0312004v1'}\n","{'_id': ObjectId('675348fbcd70c010f2b578ef'), 'paper_id': 'http://arxiv.org/abs/cs/0401005v1', 'title': 'About Unitary Rating Score Constructing', 'abstract': 'It is offered to pool test points of different subjects and different aspects\\nof the same subject together in order to get the unitary rating score, by the\\nway of nonlinear transformation of indicator points in accordance with Zipf\\'s\\ndistribution. It is proposed to use the well-studied distribution of\\nIntellectuality Quotient IQ as the reference distribution for latent variable\\n\"progress in studies\".', 'url': 'http://arxiv.org/abs/cs/0401005v1'}\n","{'_id': ObjectId('675348fbcd70c010f2b578f0'), 'paper_id': 'http://arxiv.org/abs/cs/0412003v1', 'title': 'Mining Heterogeneous Multivariate Time-Series for Learning Meaningful\\n  Patterns: Application to Home Health Telecare', 'abstract': 'For the last years, time-series mining has become a challenging issue for\\nresearchers. An important application lies in most monitoring purposes, which\\nrequire analyzing large sets of time-series for learning usual patterns. Any\\ndeviation from this learned profile is then considered as an unexpected\\nsituation. Moreover, complex applications may involve the temporal study of\\nseveral heterogeneous parameters. In that paper, we propose a method for mining\\nheterogeneous multivariate time-series for learning meaningful patterns. The\\nproposed approach allows for mixed time-series -- containing both pattern and\\nnon-pattern data -- such as for imprecise matches, outliers, stretching and\\nglobal translating of patterns instances in time. We present the early results\\nof our approach in the context of monitoring the health status of a person at\\nhome. The purpose is to build a behavioral profile of a person by analyzing the\\ntime variations of several quantitative or qualitative parameters recorded\\nthrough a provision of sensors installed in the home.', 'url': 'http://arxiv.org/abs/cs/0412003v1'}\n","{'_id': ObjectId('675348fbcd70c010f2b578f1'), 'paper_id': 'http://arxiv.org/abs/cs/0502016v1', 'title': 'Stability Analysis for Regularized Least Squares Regression', 'abstract': \"We discuss stability for a class of learning algorithms with respect to noisy\\nlabels. The algorithms we consider are for regression, and they involve the\\nminimization of regularized risk functionals, such as L(f) := 1/N sum_i\\n(f(x_i)-y_i)^2+ lambda ||f||_H^2. We shall call the algorithm `stable' if, when\\ny_i is a noisy version of f*(x_i) for some function f* in H, the output of the\\nalgorithm converges to f* as the regularization term and noise simultaneously\\nvanish. We consider two flavors of this problem, one where a data set of N\\npoints remains fixed, and the other where N -&gt; infinity. For the case where N\\n-&gt; infinity, we give conditions for convergence to f_E (the function which is\\nthe expectation of y(x) for each x), as lambda -&gt; 0. For the fixed N case, we\\ndescribe the limiting 'non-noisy', 'non-regularized' function f*, and give\\nconditions for convergence. In the process, we develop a set of tools for\\ndealing with functionals such as L(f), which are applicable to many other\\nproblems in learning theory.\", 'url': 'http://arxiv.org/abs/cs/0502016v1'}\n","{'_id': ObjectId('675348fbcd70c010f2b578f2'), 'paper_id': 'http://arxiv.org/abs/cs/0504001v1', 'title': 'Probabilistic and Team PFIN-type Learning: General Properties', 'abstract': 'We consider the probability hierarchy for Popperian FINite learning and study\\nthe general properties of this hierarchy. We prove that the probability\\nhierarchy is decidable, i.e. there exists an algorithm that receives p_1 and\\np_2 and answers whether PFIN-type learning with the probability of success p_1\\nis equivalent to PFIN-type learning with the probability of success p_2.\\n  To prove our result, we analyze the topological structure of the probability\\nhierarchy. We prove that it is well-ordered in descending ordering and\\norder-equivalent to ordinal epsilon_0. This shows that the structure of the\\nhierarchy is very complicated.\\n  Using similar methods, we also prove that, for PFIN-type learning, team\\nlearning and probabilistic learning are of the same power.', 'url': 'http://arxiv.org/abs/cs/0504001v1'}\n","{'_id': ObjectId('675348fbcd70c010f2b578f3'), 'paper_id': 'http://arxiv.org/abs/cs/0506004v4', 'title': 'Non-asymptotic calibration and resolution', 'abstract': 'We analyze a new algorithm for probability forecasting of binary observations\\non the basis of the available data, without making any assumptions about the\\nway the observations are generated. The algorithm is shown to be well\\ncalibrated and to have good resolution for long enough sequences of\\nobservations and for a suitable choice of its parameter, a kernel on the\\nCartesian product of the forecast space $[0,1]$ and the data space. Our main\\nresults are non-asymptotic: we establish explicit inequalities, shown to be\\ntight, for the performance of the algorithm.', 'url': 'http://arxiv.org/abs/cs/0506004v4'}\n","{'_id': ObjectId('675348fbcd70c010f2b578f4'), 'paper_id': 'http://arxiv.org/abs/cs/0506007v2', 'title': 'Defensive forecasting for linear protocols', 'abstract': 'We consider a general class of forecasting protocols, called \"linear\\nprotocols\", and discuss several important special cases, including multi-class\\nforecasting. Forecasting is formalized as a game between three players:\\nReality, whose role is to generate observations; Forecaster, whose goal is to\\npredict the observations; and Skeptic, who tries to make money on any lack of\\nagreement between Forecaster\\'s predictions and the actual observations. Our\\nmain mathematical result is that for any continuous strategy for Skeptic in a\\nlinear protocol there exists a strategy for Forecaster that does not allow\\nSkeptic\\'s capital to grow. This result is a meta-theorem that allows one to\\ntransform any continuous law of probability in a linear protocol into a\\nforecasting strategy whose predictions are guaranteed to satisfy this law. We\\napply this meta-theorem to a weak law of large numbers in Hilbert spaces to\\nobtain a version of the K29 prediction algorithm for linear protocols and show\\nthat this version also satisfies the attractive properties of proper\\ncalibration and resolution under a suitable choice of its kernel parameter,\\nwith no assumptions about the way the data is generated.', 'url': 'http://arxiv.org/abs/cs/0506007v2'}\n","{'_id': ObjectId('675348fbcd70c010f2b578f5'), 'paper_id': 'http://arxiv.org/abs/cs/0506057v2', 'title': 'About one 3-parameter Model of Testing', 'abstract': 'This article offers a 3-parameter model of testing, with 1) the difference\\nbetween the ability level of the examinee and item difficulty; 2) the examinee\\ndiscrimination and 3) the item discrimination as model parameters.', 'url': 'http://arxiv.org/abs/cs/0506057v2'}\n","{'_id': ObjectId('675348fccd70c010f2b578f6'), 'paper_id': 'http://arxiv.org/abs/cs/0506085v1', 'title': 'On the Job Training', 'abstract': 'We propose a new framework for building and evaluating machine learning\\nalgorithms. We argue that many real-world problems require an agent which must\\nquickly learn to respond to demands, yet can continue to perform and respond to\\nnew training throughout its useful life. We give a framework for how such\\nagents can be built, describe several metrics for evaluating them, and show\\nthat subtle changes in system construction can significantly affect agent\\nperformance.', 'url': 'http://arxiv.org/abs/cs/0506085v1'}\n","{'_id': ObjectId('675348fccd70c010f2b578f7'), 'paper_id': 'http://arxiv.org/abs/cs/0507033v2', 'title': 'Multiresolution Kernels', 'abstract': 'We present in this work a new methodology to design kernels on data which is\\nstructured with smaller components, such as text, images or sequences. This\\nmethodology is a template procedure which can be applied on most kernels on\\nmeasures and takes advantage of a more detailed \"bag of components\"\\nrepresentation of the objects. To obtain such a detailed description, we\\nconsider possible decompositions of the original bag into a collection of\\nnested bags, following a prior knowledge on the objects\\' structure. We then\\nconsider these smaller bags to compare two objects both in a detailed\\nperspective, stressing local matches between the smaller bags, and in a global\\nor coarse perspective, by considering the entire bag. This multiresolution\\napproach is likely to be best suited for tasks where the coarse approach is not\\nprecise enough, and where a more subtle mixture of both local and global\\nsimilarities is necessary to compare objects. The approach presented here would\\nnot be computationally tractable without a factorization trick that we\\nintroduce before presenting promising results on an image retrieval task.', 'url': 'http://arxiv.org/abs/cs/0507033v2'}\n","{'_id': ObjectId('675348fccd70c010f2b578f8'), 'paper_id': 'http://arxiv.org/abs/cs/0507044v1', 'title': 'Defensive Universal Learning with Experts', 'abstract': 'This paper shows how universal learning can be achieved with expert advice.\\nTo this aim, we specify an experts algorithm with the following\\ncharacteristics: (a) it uses only feedback from the actions actually chosen\\n(bandit setup), (b) it can be applied with countably infinite expert classes,\\nand (c) it copes with losses that may grow in time appropriately slowly. We\\nprove loss bounds against an adaptive adversary. From this, we obtain a master\\nalgorithm for \"reactive\" experts problems, which means that the master\\'s\\nactions may influence the behavior of the adversary. Our algorithm can\\nsignificantly outperform standard experts algorithms on such problems. Finally,\\nwe combine it with a universal expert class. The resulting universal learner\\nperforms -- in a certain sense -- almost as well as any computable strategy,\\nfor any online decision problem. We also specify the (worst-case) convergence\\nspeed, which is very slow.', 'url': 'http://arxiv.org/abs/cs/0507044v1'}\n","{'_id': ObjectId('675348fccd70c010f2b578f9'), 'paper_id': 'http://arxiv.org/abs/cs/0507062v1', 'title': 'FPL Analysis for Adaptive Bandits', 'abstract': 'A main problem of \"Follow the Perturbed Leader\" strategies for online\\ndecision problems is that regret bounds are typically proven against oblivious\\nadversary. In partial observation cases, it was not clear how to obtain\\nperformance guarantees against adaptive adversary, without worsening the\\nbounds. We propose a conceptually simple argument to resolve this problem.\\nUsing this, a regret bound of O(t^(2/3)) for FPL in the adversarial multi-armed\\nbandit problem is shown. This bound holds for the common FPL variant using only\\nthe observations from designated exploration rounds. Using all observations\\nallows for the stronger bound of O(t^(1/2)), matching the best bound known so\\nfar (and essentially the known lower bound) for adversarial bandits.\\nSurprisingly, this variant does not even need explicit exploration, it is\\nself-stabilizing. However the sampling probabilities have to be either\\nexternally provided or approximated to sufficient accuracy, using O(t^2 log t)\\nsamples in each step.', 'url': 'http://arxiv.org/abs/cs/0507062v1'}\n","{'_id': ObjectId('675348fccd70c010f2b578fa'), 'paper_id': 'http://arxiv.org/abs/cs/0509055v1', 'title': 'Learning Optimal Augmented Bayes Networks', 'abstract': 'Naive Bayes is a simple Bayesian classifier with strong independence\\nassumptions among the attributes. This classifier, desipte its strong\\nindependence assumptions, often performs well in practice. It is believed that\\nrelaxing the independence assumptions of a naive Bayes classifier may improve\\nthe classification accuracy of the resulting structure. While finding an\\noptimal unconstrained Bayesian Network (for most any reasonable scoring\\nmeasure) is an NP-hard problem, it is possible to learn in polynomial time\\noptimal networks obeying various structural restrictions. Several authors have\\nexamined the possibilities of adding augmenting arcs between attributes of a\\nNaive Bayes classifier. Friedman, Geiger and Goldszmidt define the TAN\\nstructure in which the augmenting arcs form a tree on the attributes, and\\npresent a polynomial time algorithm that learns an optimal TAN with respect to\\nMDL score. Keogh and Pazzani define Augmented Bayes Networks in which the\\naugmenting arcs form a forest on the attributes (a collection of trees, hence a\\nrelaxation of the stuctural restriction of TAN), and present heuristic search\\nmethods for learning good, though not optimal, augmenting arc sets. The\\nauthors, however, evaluate the learned structure only in terms of observed\\nmisclassification error and not against a scoring metric, such as MDL. In this\\npaper, we present a simple, polynomial time greedy algorithm for learning an\\noptimal Augmented Bayes Network with respect to MDL score.', 'url': 'http://arxiv.org/abs/cs/0509055v1'}\n","{'_id': ObjectId('675348fccd70c010f2b578fb'), 'paper_id': 'http://arxiv.org/abs/cs/0510038v4', 'title': 'Learning Unions of $ω(1)$-Dimensional Rectangles', 'abstract': 'We consider the problem of learning unions of rectangles over the domain\\n$[b]^n$, in the uniform distribution membership query learning setting, where\\nboth b and n are \"large\". We obtain poly$(n, \\\\log b)$-time algorithms for the\\nfollowing classes:\\n  - poly$(n \\\\log b)$-way Majority of $O(\\\\frac{\\\\log(n \\\\log b)} {\\\\log \\\\log(n \\\\log\\nb)})$-dimensional rectangles.\\n  - Union of poly$(\\\\log(n \\\\log b))$ many $O(\\\\frac{\\\\log^2 (n \\\\log b)} {(\\\\log\\n\\\\log(n \\\\log b) \\\\log \\\\log \\\\log (n \\\\log b))^2})$-dimensional rectangles.\\n  - poly$(n \\\\log b)$-way Majority of poly$(n \\\\log b)$-Or of disjoint\\n$O(\\\\frac{\\\\log(n \\\\log b)} {\\\\log \\\\log(n \\\\log b)})$-dimensional rectangles.\\n  Our main algorithmic tool is an extension of Jackson\\'s boosting- and\\nFourier-based Harmonic Sieve algorithm [Jackson 1997] to the domain $[b]^n$,\\nbuilding on work of [Akavia, Goldwasser, Safra 2003]. Other ingredients used to\\nobtain the results stated above are techniques from exact learning [Beimel,\\nKushilevitz 1998] and ideas from recent work on learning augmented $AC^{0}$\\ncircuits [Jackson, Klivans, Servedio 2002] and on representing Boolean\\nfunctions as thresholds of parities [Klivans, Servedio 2001].', 'url': 'http://arxiv.org/abs/cs/0510038v4'}\n","{'_id': ObjectId('675348fccd70c010f2b578fc'), 'paper_id': 'http://arxiv.org/abs/cs/0511058v2', 'title': 'On-line regression competitive with reproducing kernel Hilbert spaces', 'abstract': 'We consider the problem of on-line prediction of real-valued labels, assumed\\nbounded in absolute value by a known constant, of new objects from known\\nlabeled objects. The prediction algorithm\\'s performance is measured by the\\nsquared deviation of the predictions from the actual labels. No stochastic\\nassumptions are made about the way the labels and objects are generated.\\nInstead, we are given a benchmark class of prediction rules some of which are\\nhoped to produce good predictions. We show that for a wide range of\\ninfinite-dimensional benchmark classes one can construct a prediction algorithm\\nwhose cumulative loss over the first N examples does not exceed the cumulative\\nloss of any prediction rule in the class plus O(sqrt(N)); the main differences\\nfrom the known results are that we do not impose any upper bound on the norm of\\nthe considered prediction rules and that we achieve an optimal leading term in\\nthe excess loss of our algorithm. If the benchmark class is \"universal\" (dense\\nin the class of continuous functions on each compact set), this provides an\\non-line non-stochastic analogue of universally consistent prediction in\\nnon-parametric statistics. We use two proof techniques: one is based on the\\nAggregating Algorithm and the other on the recently developed method of\\ndefensive forecasting.', 'url': 'http://arxiv.org/abs/cs/0511058v2'}\n","{'_id': ObjectId('675348fccd70c010f2b578fd'), 'paper_id': 'http://arxiv.org/abs/cs/0511088v1', 'title': 'Bounds on Query Convergence', 'abstract': \"The problem of finding an optimum using noisy evaluations of a smooth cost\\nfunction arises in many contexts, including economics, business, medicine,\\nexperiment design, and foraging theory. We derive an asymptotic bound E[ (x_t -\\nx*)^2 ] &gt;= O(1/sqrt(t)) on the rate of convergence of a sequence (x_0, x_1,\\n&gt;...) generated by an unbiased feedback process observing noisy evaluations of\\nan unknown quadratic function maximised at x*. The bound is tight, as the proof\\nleads to a simple algorithm which meets it. We further establish a bound on the\\ntotal regret, E[ sum_{i=1..t} (x_i - x*)^2 ] &gt;= O(sqrt(t)) These bounds may\\nimpose practical limitations on an agent's performance, as O(eps^-4) queries\\nare made before the queries converge to x* with eps accuracy.\", 'url': 'http://arxiv.org/abs/cs/0511088v1'}\n","{'_id': ObjectId('6753695a9b10a9c70a7058e8'), 'paper_id': 'Paper ID', 'title': 'Title', 'abstract': 'Abstract', 'url': 'URL'}\n","{'_id': ObjectId('6753695a9b10a9c70a7058e9'), 'paper_id': 'http://arxiv.org/abs/cs/9905014v1', 'title': 'Hierarchical Reinforcement Learning with the MAXQ Value Function\\n  Decomposition', 'abstract': 'This paper presents the MAXQ approach to hierarchical reinforcement learning\\nbased on decomposing the target Markov decision process (MDP) into a hierarchy\\nof smaller MDPs and decomposing the value function of the target MDP into an\\nadditive combination of the value functions of the smaller MDPs. The paper\\ndefines the MAXQ hierarchy, proves formal results on its representational\\npower, and establishes five conditions for the safe use of state abstractions.\\nThe paper presents an online model-free learning algorithm, MAXQ-Q, and proves\\nthat it converges wih probability 1 to a kind of locally-optimal policy known\\nas a recursively optimal policy, even in the presence of the five kinds of\\nstate abstraction. The paper evaluates the MAXQ representation and MAXQ-Q\\nthrough a series of experiments in three domains and shows experimentally that\\nMAXQ-Q (with state abstractions) converges to a recursively optimal policy much\\nfaster than flat Q learning. The fact that MAXQ learns a representation of the\\nvalue function has an important benefit: it makes it possible to compute and\\nexecute an improved, non-hierarchical policy via a procedure similar to the\\npolicy improvement step of policy iteration. The paper demonstrates the\\neffectiveness of this non-hierarchical execution experimentally. Finally, the\\npaper concludes with a comparison to related work and a discussion of the\\ndesign tradeoffs in hierarchical reinforcement learning.', 'url': 'http://arxiv.org/abs/cs/9905014v1'}\n","{'_id': ObjectId('6753695a9b10a9c70a7058ea'), 'paper_id': 'http://arxiv.org/abs/cs/9905015v1', 'title': 'State Abstraction in MAXQ Hierarchical Reinforcement Learning', 'abstract': 'Many researchers have explored methods for hierarchical reinforcement\\nlearning (RL) with temporal abstractions, in which abstract actions are defined\\nthat can perform many primitive actions before terminating. However, little is\\nknown about learning with state abstractions, in which aspects of the state\\nspace are ignored. In previous work, we developed the MAXQ method for\\nhierarchical RL. In this paper, we define five conditions under which state\\nabstraction can be combined with the MAXQ value function decomposition. We\\nprove that the MAXQ-Q learning algorithm converges under these conditions and\\nshow experimentally that state abstraction is important for the successful\\napplication of MAXQ-Q learning.', 'url': 'http://arxiv.org/abs/cs/9905015v1'}\n","{'_id': ObjectId('6753695a9b10a9c70a7058eb'), 'paper_id': 'http://arxiv.org/abs/cs/0001004v1', 'title': 'Multiplicative Algorithm for Orthgonal Groups and Independent Component\\n  Analysis', 'abstract': 'The multiplicative Newton-like method developed by the author et al. is\\nextended to the situation where the dynamics is restricted to the orthogonal\\ngroup. A general framework is constructed without specifying the cost function.\\nThough the restriction to the orthogonal groups makes the problem somewhat\\ncomplicated, an explicit expression for the amount of individual jumps is\\nobtained. This algorithm is exactly second-order-convergent. The global\\ninstability inherent in the Newton method is remedied by a\\nLevenberg-Marquardt-type variation. The method thus constructed can readily be\\napplied to the independent component analysis. Its remarkable performance is\\nillustrated by a numerical simulation.', 'url': 'http://arxiv.org/abs/cs/0001004v1'}\n"]}]},{"cell_type":"markdown","metadata":{"id":"eVPj_pD8KWlO"},"source":["#### Preparing Dataset\n","\n","train, test, validation, evaluation\n","\n","- Observations:\n","\n","     1. The maximum no.of train dataset which can be accompanined by the google colab pro is 25k records of abstracts based on model trainer configurations(effective_batch_size, epoch, train_steps).\n","     2. The model is out of memory >25K records where the CUDA GPU device not able to fit the memory during train process and required >40GB memory"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"4khAcJ-O8LlE","colab":{"base_uri":"https://localhost:8080/","height":138},"executionInfo":{"status":"ok","timestamp":1733519816002,"user_tz":300,"elapsed":2644,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"dcc4c8c7-dd6d-47f5-8bb2-fc7641407c71"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["# Total alldata samples: 43713\n","\n","# train_dataset samples: 25000\n","\n","# validation_dataset samples: 713\n","\n","# test_dataset samples: 1000\n"]}],"source":["# load the data locally\n","import json\n","\n","# load the whole dataset\n","with open(content_path, 'r', encoding='utf-8') as file:\n","    alldata = json.load(file)\n","print(\"# Total alldata samples:\", len(alldata))\n","print()\n","\n","# 1）split training set\n","train_dataset = alldata[:25000]\n","print(\"# train_dataset samples:\", len(train_dataset))\n","print()\n","\n","# 2)  split validation set\n","validation_dataset = alldata[43000:]\n","print(\"# validation_dataset samples:\", len(validation_dataset))\n","print()\n","\n","# 3)  split test set\n","test_dataset = alldata[42000:43000]\n","print(\"# test_dataset samples:\", len(test_dataset))"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"8NN2vFcj-TJB","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1733519827432,"user_tz":300,"elapsed":151,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"2fccd528-e396-44c9-915b-635d6dc4f411"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["# Convert lists to dataframes\n","df_train = pd.DataFrame(train_dataset)\n","df_test = pd.DataFrame(test_dataset)\n","df_validation = pd.DataFrame(validation_dataset)\n","df_evaluation = pd.DataFrame(test_dataset)  # testset"]},{"cell_type":"markdown","metadata":{"id":"bGPq00KmK2f3"},"source":["### combining dataset to train, test, validation as df_dataset\n","\n","As the initial process, we train the Mistral-7B base model with complete dataset of abstracts. Then we finetune the model with individual train & validation datasets for the Questionarie use case."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"gkj-qB7pX_27","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1733519830793,"user_tz":300,"elapsed":120,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"21fc5e69-1ce5-4f14-ce26-4e8abee22535"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["from google.colab import data_table;\n","data_table.enable_dataframe_formatter()\n","\n","import numpy as np\n","np.random.seed(123)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"cc4i-cqFYCFQ","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1733519833473,"user_tz":300,"elapsed":170,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"633110f6-93b6-4aec-ebbe-908cebcebf37"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["# adding split column to train, test and validation\n","df_train[\"split\"] = np.zeros(df_train.shape[0])\n","df_test[\"split\"] = np.ones(df_test.shape[0])\n","df_validation[\"split\"] = np.full(df_validation.shape[0], 2)\n","\n","# creating a dataset dataframe\n","df_dataset = pd.concat([df_train, df_test, df_validation])"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"vm4_Q8TnfrNT","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1733519838358,"user_tz":300,"elapsed":133,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"9c81e185-7bba-4835-815d-397cdff5437d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["# question context input\n","df_dataset['input'] = 'question: \"' + df_dataset['question'] + '\" \\n context: \"' + df_dataset['context'] + '\"'  # Give colons respectively: add double quotes to the following content\n","df_evaluation['input'] = 'question: \"' + df_evaluation['question'] + '\" \\n context: \"' + df_evaluation['context'] + '\"'"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"J65DIwHDYGGh","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1733519864137,"user_tz":300,"elapsed":149,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"b1d10b48-1fe7-441f-f348-7bffe65f77a0"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["df_dataset[\"split\"] = df_dataset[\"split\"].astype(int)"]},{"cell_type":"markdown","metadata":{"id":"Pn5yjpbhTzLE"},"source":["### Data visualization"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"IquAmG9vYSTI","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1733519867524,"user_tz":300,"elapsed":142,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"407b95ec-a0ca-4402-d618-310c6ac89452"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["(26713, 6)"]},"metadata":{},"execution_count":21}],"source":["df_dataset.shape"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"ElQzS13HOh0v","colab":{"base_uri":"https://localhost:8080/","height":808},"executionInfo":{"status":"ok","timestamp":1733519877427,"user_tz":300,"elapsed":608,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"9c83f548-b7ad-414f-b3ca-eb700d634954"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["   id                                            context  \\\n","0   3  An Efficient Mixture of Deep and Machine Learn...   \n","1   5  Max-Margin Deep Generative Models for (Semi-)S...   \n","\n","                                            question  \\\n","0  How was the detection pipeline for COVID-19 an...   \n","1  What are max-margin deep generative models for...   \n","\n","                                              answer  split  \n","0  The detection pipeline was developed by extrac...    0.0  \n","1  Max-margin deep generative models (mmDGMs) and...    0.0  "],"text/html":["\n","  <div id=\"df-d6775dd9-edbe-4c30-8412-67a524cb2f0c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>context</th>\n","      <th>question</th>\n","      <th>answer</th>\n","      <th>split</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>An Efficient Mixture of Deep and Machine Learn...</td>\n","      <td>How was the detection pipeline for COVID-19 an...</td>\n","      <td>The detection pipeline was developed by extrac...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5</td>\n","      <td>Max-Margin Deep Generative Models for (Semi-)S...</td>\n","      <td>What are max-margin deep generative models for...</td>\n","      <td>Max-margin deep generative models (mmDGMs) and...</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6775dd9-edbe-4c30-8412-67a524cb2f0c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d6775dd9-edbe-4c30-8412-67a524cb2f0c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d6775dd9-edbe-4c30-8412-67a524cb2f0c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5e1d6ee9-27ca-4cc1-ac3f-6aa5dd27b070\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5e1d6ee9-27ca-4cc1-ac3f-6aa5dd27b070')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5e1d6ee9-27ca-4cc1-ac3f-6aa5dd27b070 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_train","summary":"{\n  \"name\": \"df_train\",\n  \"rows\": 25000,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19105,\n        \"min\": 3,\n        \"max\": 67138,\n        \"num_unique_values\": 25000,\n        \"samples\": [\n          19254,\n          64370,\n          26340\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24819,\n        \"samples\": [\n          \"Adaptive Methods for Short-Term Electricity Load Forecasting During   COVID-19 Lockdown in France.The coronavirus disease 2019 (COVID-19) pandemic has urged many governments in the world to enforce a strict lockdown where all nonessential businesses are closed and citizens are ordered to stay at home. One of the consequences of this policy is a significant change in electricity consumption patterns. Since load forecasting models rely on calendar or meteorological information and are trained on historical data, they fail to capture the significant break caused by the lockdown and have exhibited poor performances since the beginning of the pandemic. This makes the scheduling of the electricity production challenging, and has a high cost for both electricity producers and grid operators. In this paper we introduce adaptive generalized additive models using Kalman filters and fine-tuning to adjust to new electricity consumption patterns. Additionally, knowledge from the lockdown in Italy is transferred to anticipate the change of behavior in France. The proposed methods are applied to forecast the electricity demand during the French lockdown period, where they demonstrate their ability to significantly reduce prediction errors compared to traditional models. Finally expert aggregation is used to leverage the specificities of each predictions and enhance results even further.\",\n          \"Static Malware Detection & Subterfuge: Quantifying the Robustness of   Machine Learning and Current Anti-Virus.As machine-learning (ML) based systems for malware detection become more prevalent, it becomes necessary to quantify the benefits compared to the more traditional anti-virus (AV) systems widely used today. It is not practical to build an agreed upon test set to benchmark malware detection systems on pure classification performance. Instead we tackle the problem by creating a new testing methodology, where we evaluate the change in performance on a set of known benign & malicious files as adversarial modifications are performed. The change in performance combined with the evasion techniques then quantifies a system's robustness against that approach. Through these experiments we are able to show in a quantifiable way how purely ML based systems can be more robust than AV products at detecting malware that attempts evasion through modification, but may be slower to adapt in the face of significantly novel attacks.\",\n          \"MODMA dataset: a Multi-modal Open Dataset for Mental-disorder Analysis.According to the World Health Organization, the number of mental disorder patients, especially depression patients, has grown rapidly and become a leading contributor to the global burden of disease. However, the present common practice of depression diagnosis is based on interviews and clinical scales carried out by doctors, which is not only labor-consuming but also time-consuming. One important reason is due to the lack of physiological indicators for mental disorders. With the rising of tools such as data mining and artificial intelligence, using physiological data to explore new possible physiological indicators of mental disorder and creating new applications for mental disorder diagnosis has become a new research hot topic. However, good quality physiological data for mental disorder patients are hard to acquire. We present a multi-modal open dataset for mental-disorder analysis. The dataset includes EEG and audio data from clinically depressed patients and matching normal controls. All our patients were carefully diagnosed and selected by professional psychiatrists in hospitals. The EEG dataset includes not only data collected using traditional 128-electrodes mounted elastic cap, but also a novel wearable 3-electrode EEG collector for pervasive applications. The 128-electrodes EEG signals of 53 subjects were recorded as both in resting state and under stimulation; the 3-electrode EEG signals of 55 subjects were recorded in resting state; the audio data of 52 subjects were recorded during interviewing, reading, and picture description. We encourage other researchers in the field to use it for testing their methods of mental-disorder analysis.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24946,\n        \"samples\": [\n          \"What is DeepNovoV2 and how does it improve peptide sequencing?\",\n          \"What is the main concept of Neurons Merging Layer in the context of deep supervised hashing?\",\n          \"How important is computer-aided assessment of catheters on radiographs?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24999,\n        \"samples\": [\n          \"ATT-MADDPG is a method extending DDPG for multi-agent systems by utilizing a centralized critic with an attention mechanism. It addresses the challenge by enabling access to teammates' observations and actions, and enhancing the centralized critic with an attention mechanism to model the dynamic joint policy of teammates efficiently.\",\n          \"The key motivation behind CATCH algorithm is to address the restrictions inherent in many NAS algorithms, such as being limited to specific search spaces and lacking efficient mechanisms for knowledge reuse across tasks. CATCH combines meta-learning and reinforcement learning to enable quick adaptation to new tasks while remaining agnostic to search spaces. By using a probabilistic encoder to encode task properties into context variables, CATCH efficiently guides its controller to discover top-performing networks. These context variables also help filter out inferior candidates and accelerate the learning process. Extensive experiments demonstrate CATCH's versatility and efficiency compared to other algorithms, showcasing its capability in cross-domain architecture search by identifying competitive networks on datasets like ImageNet, COCO, and Cityscapes.\",\n          \"Domain-liftability plays a crucial role in the construction of relational marginal polytopes by influencing the computation of relational marginal statistics. The relationship between domain-liftability and the partition functions of Markov logic networks (MLNs) impacts the feasibility of relational marginal polytope construction. Furthermore, the study of domain-liftability in weight learning of MLNs reveals significant implications for lifted weight learning processes, particularly in scenarios where the computation of partition functions is domain-liftable. These findings provide new insights into the computational aspects of relational marginal polytopes and their connection to AI-related tasks.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"},"application/vnd.google.colaboratory.module+javascript":"\n      import \"https://ssl.gstatic.com/colaboratory/data_table/e523c247d1e24a05/data_table.js\";\n\n      const table = window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 3,\n            'f': \"3\",\n        },\n\"An Efficient Mixture of Deep and Machine Learning Models for COVID-19   and Tuberculosis Detection Using X-Ray Images in Resource Limited Settings.Clinicians in the frontline need to assess quickly whether a patient with symptoms indeed has COVID-19 or not. The difficulty of this task is exacerbated in low resource settings that may not have access to biotechnology tests. Furthermore, Tuberculosis (TB) remains a major health problem in several low- and middle-income countries and its common symptoms include fever, cough and tiredness, similarly to COVID-19. In order to help in the detection of COVID-19, we propose the extraction of deep features (DF) from chest X-ray images, a technology available in most hospitals, and their subsequent classification using machine learning methods that do not require large computational resources. We compiled a five-class dataset of X-ray chest images including a balanced number of COVID-19, viral pneumonia, bacterial pneumonia, TB, and healthy cases. We compared the performance of pipelines combining 14 individual state-of-the-art pre-trained deep networks for DF extraction with traditional machine learning classifiers. A pipeline consisting of ResNet-50 for DF computation and ensemble of subspace discriminant classifier was the best performer in the classification of the five classes, achieving a detection accuracy of 91.6+ 2.6% (accuracy + 95% Confidence Interval). Furthermore, the same pipeline achieved accuracies of 98.6+1.4% and 99.9+0.5% in simpler three-class and two-class classification problems focused on distinguishing COVID-19, TB and healthy cases; and COVID-19 and healthy images, respectively. The pipeline was computationally efficient requiring just 0.19 second to extract DF per X-ray image and 2 minutes for training a traditional classifier with more than 2000 images on a CPU machine. The results suggest the potential benefits of using our pipeline in the detection of COVID-19, particularly in resource-limited settings and it can run with limited computational resources.\",\n\"How was the detection pipeline for COVID-19 and TB developed?\",\n\"The detection pipeline was developed by extracting deep features from chest X-ray images using ResNet-50 and then classifying them with an ensemble of subspace discriminant classifiers. It achieved a detection accuracy of 91.6% with a computationally efficient process, taking just 0.19 seconds to extract features per image and 2 minutes for training a traditional classifier on a CPU machine. The pipeline also excelled in simpler three-class and two-class classification scenarios, showcasing its effectiveness in detecting COVID-19 and TB with high accuracy in resource-limited settings.\",\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        }],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 5,\n            'f': \"5\",\n        },\n\"Max-Margin Deep Generative Models for (Semi-)Supervised Learning.Deep generative models (DGMs) are effective on learning multilayered representations of complex data and performing inference of input data by exploring the generative ability. However, it is relatively insufficient to empower the discriminative ability of DGMs on making accurate predictions. This paper presents max-margin deep generative models (mmDGMs) and a class-conditional variant (mmDCGMs), which explore the strongly discriminative principle of max-margin learning to improve the predictive performance of DGMs in both supervised and semi-supervised learning, while retaining the generative capability. In semi-supervised learning, we use the predictions of a max-margin classifier as the missing labels instead of performing full posterior inference for efficiency; we also introduce additional max-margin and label-balance regularization terms of unlabeled data for effectiveness. We develop an efficient doubly stochastic subgradient algorithm for the piecewise linear objectives in different settings. Empirical results on various datasets demonstrate that: (1) max-margin learning can significantly improve the prediction performance of DGMs and meanwhile retain the generative ability; (2) in supervised learning, mmDGMs are competitive to the best fully discriminative networks when employing convolutional neural networks as the generative and recognition models; and (3) in semi-supervised learning, mmDCGMs can perform efficient inference and achieve state-of-the-art classification results on several benchmarks.\",\n\"What are max-margin deep generative models for (Semi-)Supervised Learning?\",\n\"Max-margin deep generative models (mmDGMs) and a class-conditional variant (mmDCGMs) apply max-margin learning to enhance predictive performance in supervised and semi-supervised learning while maintaining generative ability.\",\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        }]],\n        columns: [[\"number\", \"index\"], [\"number\", \"id\"], [\"string\", \"context\"], [\"string\", \"question\"], [\"string\", \"answer\"], [\"number\", \"split\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n\n      function appendQuickchartButton(parentElement) {\n        let quickchartButtonContainerElement = document.createElement('div');\n        quickchartButtonContainerElement.innerHTML = `\n<div id=\"df-a8464c88-160c-4ad0-bd9d-4047510565d0\">\n  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a8464c88-160c-4ad0-bd9d-4047510565d0')\"\n            title=\"Suggest charts\"\n            style=\"display:none;\">\n    \n<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n     width=\"24px\">\n    <g>\n        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n    </g>\n</svg>\n  </button>\n  \n<style>\n  .colab-df-quickchart {\n      --bg-color: #E8F0FE;\n      --fill-color: #1967D2;\n      --hover-bg-color: #E2EBFA;\n      --hover-fill-color: #174EA6;\n      --disabled-fill-color: #AAA;\n      --disabled-bg-color: #DDD;\n  }\n\n  [theme=dark] .colab-df-quickchart {\n      --bg-color: #3B4455;\n      --fill-color: #D2E3FC;\n      --hover-bg-color: #434B5C;\n      --hover-fill-color: #FFFFFF;\n      --disabled-bg-color: #3B4455;\n      --disabled-fill-color: #666;\n  }\n\n  .colab-df-quickchart {\n    background-color: var(--bg-color);\n    border: none;\n    border-radius: 50%;\n    cursor: pointer;\n    display: none;\n    fill: var(--fill-color);\n    height: 32px;\n    padding: 0;\n    width: 32px;\n  }\n\n  .colab-df-quickchart:hover {\n    background-color: var(--hover-bg-color);\n    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n    fill: var(--button-hover-fill-color);\n  }\n\n  .colab-df-quickchart-complete:disabled,\n  .colab-df-quickchart-complete:disabled:hover {\n    background-color: var(--disabled-bg-color);\n    fill: var(--disabled-fill-color);\n    box-shadow: none;\n  }\n\n  .colab-df-spinner {\n    border: 2px solid var(--fill-color);\n    border-color: transparent;\n    border-bottom-color: var(--fill-color);\n    animation:\n      spin 1s steps(1) infinite;\n  }\n\n  @keyframes spin {\n    0% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n      border-left-color: var(--fill-color);\n    }\n    20% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    30% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n      border-right-color: var(--fill-color);\n    }\n    40% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    60% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n    }\n    80% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-bottom-color: var(--fill-color);\n    }\n    90% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n    }\n  }\n</style>\n\n  <script>\n    async function quickchart(key) {\n      const quickchartButtonEl =\n        document.querySelector('#' + key + ' button');\n      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n      quickchartButtonEl.classList.add('colab-df-spinner');\n      try {\n        const charts = await google.colab.kernel.invokeFunction(\n            'suggestCharts', [key], {});\n      } catch (error) {\n        console.error('Error during call to suggestCharts:', error);\n      }\n      quickchartButtonEl.classList.remove('colab-df-spinner');\n      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n    }\n    (() => {\n      let quickchartButtonEl =\n        document.querySelector('#df-a8464c88-160c-4ad0-bd9d-4047510565d0 button');\n      quickchartButtonEl.style.display =\n        google.colab.kernel.accessAllowed ? 'block' : 'none';\n    })();\n  </script>\n</div>`;\n        parentElement.appendChild(quickchartButtonContainerElement);\n      }\n\n      appendQuickchartButton(table);\n    "},"metadata":{},"execution_count":22}],"source":["df_train.head(2)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"T737NXc_Own7","colab":{"base_uri":"https://localhost:8080/","height":725},"executionInfo":{"status":"ok","timestamp":1733519886115,"user_tz":300,"elapsed":293,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"05291172-38dc-4fd6-d62b-aba64e43d5ca"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["       id                                            context  \\\n","0  112194  Neural Mesh: Introducing a Notion of Space and...   \n","1  112196  Learning Deep Graph Representations via Convol...   \n","\n","                                            question  \\\n","0  What is the unique feature of the Neural Mesh ...   \n","1  How does DeepMap learn deep graph representati...   \n","\n","                                              answer  split  \n","0  The unique feature of the Neural Mesh architec...    1.0  \n","1  DeepMap addresses the limitations of graph ker...    1.0  "],"text/html":["\n","  <div id=\"df-b49b4cc0-96ba-4c34-80d0-6d12c6dd3a19\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>context</th>\n","      <th>question</th>\n","      <th>answer</th>\n","      <th>split</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>112194</td>\n","      <td>Neural Mesh: Introducing a Notion of Space and...</td>\n","      <td>What is the unique feature of the Neural Mesh ...</td>\n","      <td>The unique feature of the Neural Mesh architec...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>112196</td>\n","      <td>Learning Deep Graph Representations via Convol...</td>\n","      <td>How does DeepMap learn deep graph representati...</td>\n","      <td>DeepMap addresses the limitations of graph ker...</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b49b4cc0-96ba-4c34-80d0-6d12c6dd3a19')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b49b4cc0-96ba-4c34-80d0-6d12c6dd3a19 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b49b4cc0-96ba-4c34-80d0-6d12c6dd3a19');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-8dd7f303-26d1-440b-ae15-5da575ec82a3\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8dd7f303-26d1-440b-ae15-5da575ec82a3')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-8dd7f303-26d1-440b-ae15-5da575ec82a3 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_test","summary":"{\n  \"name\": \"df_test\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 689,\n        \"min\": 112194,\n        \"max\": 114588,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          113399,\n          113936,\n          113947\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"Sector Volatility Prediction Performance Using GARCH Models and   Artificial Neural Networks.Recently artificial neural networks (ANNs) have seen success in volatility prediction, but the literature is divided on where an ANN should be used rather than the common GARCH model. The purpose of this study is to compare the volatility prediction performance of ANN and GARCH models when applied to stocks with low, medium, and high volatility profiles. This approach intends to identify which model should be used for each case. The volatility profiles comprise of five sectors that cover all stocks in the U.S stock market from 2005 to 2020. Three GARCH specifications and three ANN architectures are examined for each sector, where the most adequate model is chosen to move on to forecasting. The results indicate that the ANN model should be used for predicting volatility of assets with low volatility profiles, and GARCH models should be used when predicting volatility of medium and high volatility assets.\",\n          \"Generative Counterfactuals for Neural Networks via Attribute-Informed   Perturbation.With the wide use of deep neural networks (DNN), model interpretability has become a critical concern, since explainable decisions are preferred in high-stake scenarios. Current interpretation techniques mainly focus on the feature attribution perspective, which are limited in indicating why and how particular explanations are related to the prediction. To this end, an intriguing class of explanations, named counterfactuals, has been developed to further explore the \\\"what-if\\\" circumstances for interpretation, and enables the reasoning capability on black-box models. However, generating counterfactuals for raw data instances (i.e., text and image) is still in the early stage due to its challenges on high data dimensionality and unsemantic raw features. In this paper, we design a framework to generate counterfactuals specifically for raw data instances with the proposed Attribute-Informed Perturbation (AIP). By utilizing generative models conditioned with different attributes, counterfactuals with desired labels can be obtained effectively and efficiently. Instead of directly modifying instances in the data space, we iteratively optimize the constructed attribute-informed latent space, where features are more robust and semantic. Experimental results on real-world texts and images demonstrate the effectiveness, sample quality as well as efficiency of our designed framework, and show the superiority over other alternatives. Besides, we also introduce some practical applications based on our framework, indicating its potential beyond the model interpretability aspect.\",\n          \"Forecasting Market Prices using DL with Data Augmentation and   Meta-learning: ARIMA still wins!.Deep-learning techniques have been successfully used for time-series forecasting and have often shown superior performance on many standard benchmark datasets as compared to traditional techniques. Here we present a comprehensive and comparative study of performance of deep-learning techniques for forecasting prices in financial markets. We benchmark state-of-the-art deep-learning baselines, such as NBeats, etc., on data from currency as well as stock markets. We also generate synthetic data using a fuzzy-logic based model of demand driven by technical rules such as moving averages, which are often used by traders. We benchmark the baseline techniques on this synthetic data as well as use it for data augmentation. We also apply gradient-based meta-learning to account for non-stationarity of financial time-series. Our extensive experiments notwithstanding, the surprising result is that the standard ARIMA models outperforms deep-learning even using data augmentation or meta-learning. We conclude by speculating as to why this might be the case.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"How can artificial neural networks and GARCH models be compared for sector volatility prediction performance?\",\n          \"How can Attribute-Informed Perturbation assist in generating counterfactuals for raw data instances?\",\n          \"What techniques were compared for market price forecasting?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"Artificial neural networks (ANNs) and GARCH models were compared in this study by analyzing their performance in predicting volatility for stocks with low, medium, and high volatility profiles across five sectors in the U.S. stock market. The research examined three GARCH specifications and three ANN architectures for each sector and found that ANNs are more suitable for assets with low volatility profiles, while GARCH models are preferred for medium and high volatility assets. This comparison highlights the importance of choosing the appropriate model based on the specific characteristics of the assets being analyzed, ultimately contributing to more accurate volatility predictions in different sectors.\",\n          \"By utilizing generative models conditioned with different attributes, counterfactuals with desired labels can be obtained effectively and efficiently. Instead of directly modifying instances in the data space, we iteratively optimize the constructed attribute-informed latent space, where features are more robust and semantic.\",\n          \"The study compared deep-learning techniques, including NBeats, with traditional ARIMA models for forecasting prices in financial markets. Synthetic data generated from a fuzzy-logic demand model was used for data augmentation and gradient-based meta-learning to address non-stationarity.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"},"application/vnd.google.colaboratory.module+javascript":"\n      import \"https://ssl.gstatic.com/colaboratory/data_table/e523c247d1e24a05/data_table.js\";\n\n      const table = window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 112194,\n            'f': \"112194\",\n        },\n\"Neural Mesh: Introducing a Notion of Space and Conservation of Energy to   Neural Networks.Neural networks are based on a simplified model of the brain. In this project, we wanted to relax the simplifying assumptions of a traditional neural network by making a model that more closely emulates the low level interactions of neurons. Like in an RNN, our model has a state that persists between time steps, so that the energies of neurons persist. However, unlike an RNN, our state consists of a 2 dimensional matrix, rather than a 1 dimensional vector, thereby introducing a concept of distance to other neurons within the state. In our model, neurons can only fire to adjacent neurons, as in the brain. Like in the brain, we only allow neurons to fire in a time step if they contain enough energy, or excitement. We also enforce a notion of conservation of energy, so that a neuron cannot excite its neighbors more than the excitement it already contained at that time step. Taken together, these two features allow signals in the form of activations to flow around in our network over time, making our neural mesh more closely model signals traveling through the brain the brain. Although our main goal is to design an architecture to more closely emulate the brain in the hope of having a correct internal representation of information by the time we know how to properly train a general intelligence, we did benchmark our neural mash on a specific task. We found that by increasing the runtime of the mesh, we were able to increase its accuracy without increasing the number of parameters.\",\n\"What is the unique feature of the Neural Mesh architecture?\",\n\"The unique feature of the Neural Mesh architecture is the introduction of a 2 dimensional matrix state for neurons, which introduces a notion of spatial distance to other neurons within the network. This allows neurons to only fire to adjacent neurons, mimicking the interactions in the brain. Additionally, the model enforces a conservation of energy principle, ensuring that neurons cannot excite their neighbors more than their existing excitement level. These innovations enable signals in the form of activations to flow around the network over time, closely mirroring how signals travel through the brain.\",\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        }],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 112196,\n            'f': \"112196\",\n        },\n\"Learning Deep Graph Representations via Convolutional Neural Networks.Graph-structured data arise in many scenarios. A fundamental problem is to quantify the similarities of graphs for tasks such as classification. R-convolution graph kernels are positive-semidefinite functions that decompose graphs into substructures and compare them. One problem in the effective implementation of this idea is that the substructures are not independent, which leads to high-dimensional feature space. In addition, graph kernels cannot capture the high-order complex interactions between vertices. To mitigate these two problems, we propose a framework called DeepMap to learn deep representations for graph feature maps. The learned deep representation for a graph is a dense and low-dimensional vector that captures complex high-order interactions in a vertex neighborhood. DeepMap extends Convolutional Neural Networks (CNNs) to arbitrary graphs by generating aligned vertex sequences and building the receptive field for each vertex. We empirically validate DeepMap on various graph classification benchmarks and demonstrate that it achieves state-of-the-art performance.\",\n\"How does DeepMap learn deep graph representations via CNNs?\",\n\"DeepMap addresses the limitations of graph kernels by introducing a framework that utilizes Convolutional Neural Networks (CNNs) to learn deep representations for graph feature maps. It extends CNNs to arbitrary graphs by generating aligned vertex sequences and building the receptive field for each vertex. The learned deep representation for a graph is a dense and low-dimensional vector capturing complex high-order interactions in vertex neighborhoods. By leveraging CNNs, DeepMap can effectively capture high-order interactions that traditional graph kernels struggle to represent, thereby achieving state-of-the-art performance on various graph classification benchmarks.\",\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        }]],\n        columns: [[\"number\", \"index\"], [\"number\", \"id\"], [\"string\", \"context\"], [\"string\", \"question\"], [\"string\", \"answer\"], [\"number\", \"split\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n\n      function appendQuickchartButton(parentElement) {\n        let quickchartButtonContainerElement = document.createElement('div');\n        quickchartButtonContainerElement.innerHTML = `\n<div id=\"df-6ee2b893-dff2-4346-b83e-8906eeab2771\">\n  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6ee2b893-dff2-4346-b83e-8906eeab2771')\"\n            title=\"Suggest charts\"\n            style=\"display:none;\">\n    \n<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n     width=\"24px\">\n    <g>\n        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n    </g>\n</svg>\n  </button>\n  \n<style>\n  .colab-df-quickchart {\n      --bg-color: #E8F0FE;\n      --fill-color: #1967D2;\n      --hover-bg-color: #E2EBFA;\n      --hover-fill-color: #174EA6;\n      --disabled-fill-color: #AAA;\n      --disabled-bg-color: #DDD;\n  }\n\n  [theme=dark] .colab-df-quickchart {\n      --bg-color: #3B4455;\n      --fill-color: #D2E3FC;\n      --hover-bg-color: #434B5C;\n      --hover-fill-color: #FFFFFF;\n      --disabled-bg-color: #3B4455;\n      --disabled-fill-color: #666;\n  }\n\n  .colab-df-quickchart {\n    background-color: var(--bg-color);\n    border: none;\n    border-radius: 50%;\n    cursor: pointer;\n    display: none;\n    fill: var(--fill-color);\n    height: 32px;\n    padding: 0;\n    width: 32px;\n  }\n\n  .colab-df-quickchart:hover {\n    background-color: var(--hover-bg-color);\n    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n    fill: var(--button-hover-fill-color);\n  }\n\n  .colab-df-quickchart-complete:disabled,\n  .colab-df-quickchart-complete:disabled:hover {\n    background-color: var(--disabled-bg-color);\n    fill: var(--disabled-fill-color);\n    box-shadow: none;\n  }\n\n  .colab-df-spinner {\n    border: 2px solid var(--fill-color);\n    border-color: transparent;\n    border-bottom-color: var(--fill-color);\n    animation:\n      spin 1s steps(1) infinite;\n  }\n\n  @keyframes spin {\n    0% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n      border-left-color: var(--fill-color);\n    }\n    20% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    30% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n      border-right-color: var(--fill-color);\n    }\n    40% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    60% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n    }\n    80% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-bottom-color: var(--fill-color);\n    }\n    90% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n    }\n  }\n</style>\n\n  <script>\n    async function quickchart(key) {\n      const quickchartButtonEl =\n        document.querySelector('#' + key + ' button');\n      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n      quickchartButtonEl.classList.add('colab-df-spinner');\n      try {\n        const charts = await google.colab.kernel.invokeFunction(\n            'suggestCharts', [key], {});\n      } catch (error) {\n        console.error('Error during call to suggestCharts:', error);\n      }\n      quickchartButtonEl.classList.remove('colab-df-spinner');\n      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n    }\n    (() => {\n      let quickchartButtonEl =\n        document.querySelector('#df-6ee2b893-dff2-4346-b83e-8906eeab2771 button');\n      quickchartButtonEl.style.display =\n        google.colab.kernel.accessAllowed ? 'block' : 'none';\n    })();\n  </script>\n</div>`;\n        parentElement.appendChild(quickchartButtonContainerElement);\n      }\n\n      appendQuickchartButton(table);\n    "},"metadata":{},"execution_count":23}],"source":["df_test.head(2)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"4wwDDFyiO5w4","colab":{"base_uri":"https://localhost:8080/","height":609},"executionInfo":{"status":"ok","timestamp":1733519890351,"user_tz":300,"elapsed":135,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"c7efafe9-b63e-46c7-c050-8a598c0a3944"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["       id                                            context  \\\n","0  114593  Deep Approximately Orthogonal Nonnegative Matr...   \n","1  114595  Two-argument activation functions learn soft X...   \n","\n","                                            question  \\\n","0  What are the key features of deep approximatel...   \n","1  What do artificial neural networks learn like ...   \n","\n","                                              answer  split  \n","0  The key features of deep approximately orthogo...      2  \n","1  Artificial neural networks can learn soft XOR ...      2  "],"text/html":["\n","  <div id=\"df-906fa62a-1b04-4c7d-941f-af529c4814c6\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>context</th>\n","      <th>question</th>\n","      <th>answer</th>\n","      <th>split</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>114593</td>\n","      <td>Deep Approximately Orthogonal Nonnegative Matr...</td>\n","      <td>What are the key features of deep approximatel...</td>\n","      <td>The key features of deep approximately orthogo...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>114595</td>\n","      <td>Two-argument activation functions learn soft X...</td>\n","      <td>What do artificial neural networks learn like ...</td>\n","      <td>Artificial neural networks can learn soft XOR ...</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-906fa62a-1b04-4c7d-941f-af529c4814c6')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-906fa62a-1b04-4c7d-941f-af529c4814c6 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-906fa62a-1b04-4c7d-941f-af529c4814c6');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-4da3631e-bec5-4b9c-9c49-4fe769f0722d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4da3631e-bec5-4b9c-9c49-4fe769f0722d')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-4da3631e-bec5-4b9c-9c49-4fe769f0722d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_validation","summary":"{\n  \"name\": \"df_validation\",\n  \"rows\": 713,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 491,\n        \"min\": 114593,\n        \"max\": 116291,\n        \"num_unique_values\": 713,\n        \"samples\": [\n          114885,\n          115423,\n          114687\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 713,\n        \"samples\": [\n          \"Local Model Poisoning Attacks to Byzantine-Robust Federated Learning.In federated learning, multiple client devices jointly learn a machine learning model: each client device maintains a local model for its local training dataset, while a master device maintains a global model via aggregating the local models from the client devices. The machine learning community recently proposed several federated learning methods that were claimed to be robust against Byzantine failures (e.g., system failures, adversarial manipulations) of certain client devices. In this work, we perform the first systematic study on local model poisoning attacks to federated learning. We assume an attacker has compromised some client devices, and the attacker manipulates the local model parameters on the compromised client devices during the learning process such that the global model has a large testing error rate. We formulate our attacks as optimization problems and apply our attacks to four recent Byzantine-robust federated learning methods. Our empirical results on four real-world datasets show that our attacks can substantially increase the error rates of the models learnt by the federated learning methods that were claimed to be robust against Byzantine failures of some client devices. We generalize two defenses for data poisoning attacks to defend against our local model poisoning attacks. Our evaluation results show that one defense can effectively defend against our attacks in some cases, but the defenses are not effective enough in other cases, highlighting the need for new defenses against our local model poisoning attacks to federated learning.\",\n          \"Signal Propagation in Transformers: Theoretical Perspectives and the   Role of Rank Collapse.Transformers have achieved remarkable success in several domains, ranging from natural language processing to computer vision. Nevertheless, it has been recently shown that stacking self-attention layers - the distinctive architectural component of Transformers - can result in rank collapse of the tokens' representations at initialization. The question of if and how rank collapse affects training is still largely unanswered, and its investigation is necessary for a more comprehensive understanding of this architecture. In this work, we shed new light on the causes and the effects of this phenomenon. First, we show that rank collapse of the tokens' representations hinders training by causing the gradients of the queries and keys to vanish at initialization. Furthermore, we provide a thorough description of the origin of rank collapse and discuss how to prevent it via an appropriate depth-dependent scaling of the residual branches. Finally, our analysis unveils that specific architectural hyperparameters affect the gradients of queries and values differently, leading to disproportionate gradient norms. This suggests an explanation for the widespread use of adaptive methods for Transformers' optimization.\",\n          \"Beyond Value: CHECKLIST for Testing Inferences in Planning-Based RL.Reinforcement learning (RL) agents are commonly evaluated via their expected value over a distribution of test scenarios. Unfortunately, this evaluation approach provides limited evidence for post-deployment generalization beyond the test distribution. In this paper, we address this limitation by extending the recent CheckList testing methodology from natural language processing to planning-based RL. Specifically, we consider testing RL agents that make decisions via online tree search using a learned transition model and value function. The key idea is to improve the assessment of future performance via a CheckList approach for exploring and assessing the agent's inferences during tree search. The approach provides the user with an interface and general query-rule mechanism for identifying potential inference flaws and validating expected inference invariances. We present a user study involving knowledgeable AI researchers using the approach to evaluate an agent trained to play a complex real-time strategy game. The results show the approach is effective in allowing users to identify previously-unknown flaws in the agent's reasoning. In addition, our analysis provides insight into how AI experts use this type of testing approach, which may help improve future instantiations.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 713,\n        \"samples\": [\n          \"What are local model poisoning attacks to federated learning?\",\n          \"What does rank collapse affect in Transformer training?\",\n          \"What is the purpose of extending CheckList to planning-based RL?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 713,\n        \"samples\": [\n          \"Local model poisoning attacks to federated learning involve an attacker compromising client devices and manipulating local model parameters to impact the global model. This study explores systematic methods to carry out these attacks and demonstrates their disruptive potential on federated learning systems designed to resist Byzantine failures. By formulating attacks as optimization problems and testing them on real-world datasets, the researchers show how these attacks can significantly increase error rates in supposedly robust federated learning models. The study also presents defenses for data poisoning attacks, though their effectiveness varies across different scenarios, emphasizing the necessity for new defenses tailored specifically to counter local model poisoning threats in federated learning.\",\n          \"Rank collapse of the tokens' representations hinders training by causing the gradients of the queries and keys to vanish at initialization. This can impact the optimization process, making it more challenging to train the model effectively and efficiently.\",\n          \"The purpose of extending CheckList to planning-based RL is to enhance the assessment of RL agents beyond value-based evaluations. By focusing on testing an agent's inferences during tree search, the CheckList approach aims to identify and validate potential inference flaws and expected invariances in the agent's decision-making process. This extension provides a user-friendly interface for exploring the agent's reasoning and enables users to uncover previously-unknown flaws, thus enhancing the evaluation of RL agents in planning-based scenarios.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"},"application/vnd.google.colaboratory.module+javascript":"\n      import \"https://ssl.gstatic.com/colaboratory/data_table/e523c247d1e24a05/data_table.js\";\n\n      const table = window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 114593,\n            'f': \"114593\",\n        },\n\"Deep Approximately Orthogonal Nonnegative Matrix Factorization for   Clustering.Nonnegative Matrix Factorization (NMF) is a widely used technique for data representation. Inspired by the expressive power of deep learning, several NMF variants equipped with deep architectures have been proposed. However, these methods mostly use the only nonnegativity while ignoring task-specific features of data. In this paper, we propose a novel deep approximately orthogonal nonnegative matrix factorization method where both nonnegativity and orthogonality are imposed with the aim to perform a hierarchical clustering by using different level of abstractions of data. Experiment on two face image datasets showed that the proposed method achieved better clustering performance than other deep matrix factorization methods and state-of-the-art single layer NMF variants.\",\n\"What are the key features of deep approximately orthogonal nonnegative matrix factorization?\",\n\"The key features of deep approximately orthogonal nonnegative matrix factorization include the incorporation of nonnegativity and orthogonality constraints. These constraints enable the method to create different levels of abstractions in data representation, facilitating hierarchical clustering. By imposing both constraints, the method aims to enhance clustering performance by leveraging task-specific features of the data. Experimental results on face image datasets demonstrate that this approach outperforms other deep matrix factorization techniques and state-of-the-art single layer NMF variants.\",\n{\n            'v': 2,\n            'f': \"2\",\n        }],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 114595,\n            'f': \"114595\",\n        },\n\"Two-argument activation functions learn soft XOR operations like   cortical neurons.Neurons in the brain are complex machines with distinct functional compartments that interact nonlinearly. In contrast, neurons in artificial neural networks abstract away this complexity, typically down to a scalar activation function of a weighted sum of inputs. Here we emulate more biologically realistic neurons by learning canonical activation functions with two input arguments, analogous to basal and apical dendrites. We use a network-in-network architecture where each neuron is modeled as a multilayer perceptron with two inputs and a single output. This inner perceptron is shared by all units in the outer network. Remarkably, the resultant nonlinearities often produce soft XOR functions, consistent with recent experimental observations about interactions between inputs in human cortical neurons. When hyperparameters are optimized, networks with these nonlinearities learn faster and perform better than conventional ReLU nonlinearities with matched parameter counts, and they are more robust to natural and adversarial perturbations.\",\n\"What do artificial neural networks learn like cortical neurons?\",\n\"Artificial neural networks can learn soft XOR operations similar to how cortical neurons interact nonlinearly. By modeling neurons with two-input activation functions, networks show faster learning and better performance than conventional ReLU functions, providing robustness against perturbations.\",\n{\n            'v': 2,\n            'f': \"2\",\n        }]],\n        columns: [[\"number\", \"index\"], [\"number\", \"id\"], [\"string\", \"context\"], [\"string\", \"question\"], [\"string\", \"answer\"], [\"number\", \"split\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n\n      function appendQuickchartButton(parentElement) {\n        let quickchartButtonContainerElement = document.createElement('div');\n        quickchartButtonContainerElement.innerHTML = `\n<div id=\"df-87b3c9d2-fb9d-4a0d-b981-6e9d6e1ad247\">\n  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-87b3c9d2-fb9d-4a0d-b981-6e9d6e1ad247')\"\n            title=\"Suggest charts\"\n            style=\"display:none;\">\n    \n<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n     width=\"24px\">\n    <g>\n        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n    </g>\n</svg>\n  </button>\n  \n<style>\n  .colab-df-quickchart {\n      --bg-color: #E8F0FE;\n      --fill-color: #1967D2;\n      --hover-bg-color: #E2EBFA;\n      --hover-fill-color: #174EA6;\n      --disabled-fill-color: #AAA;\n      --disabled-bg-color: #DDD;\n  }\n\n  [theme=dark] .colab-df-quickchart {\n      --bg-color: #3B4455;\n      --fill-color: #D2E3FC;\n      --hover-bg-color: #434B5C;\n      --hover-fill-color: #FFFFFF;\n      --disabled-bg-color: #3B4455;\n      --disabled-fill-color: #666;\n  }\n\n  .colab-df-quickchart {\n    background-color: var(--bg-color);\n    border: none;\n    border-radius: 50%;\n    cursor: pointer;\n    display: none;\n    fill: var(--fill-color);\n    height: 32px;\n    padding: 0;\n    width: 32px;\n  }\n\n  .colab-df-quickchart:hover {\n    background-color: var(--hover-bg-color);\n    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n    fill: var(--button-hover-fill-color);\n  }\n\n  .colab-df-quickchart-complete:disabled,\n  .colab-df-quickchart-complete:disabled:hover {\n    background-color: var(--disabled-bg-color);\n    fill: var(--disabled-fill-color);\n    box-shadow: none;\n  }\n\n  .colab-df-spinner {\n    border: 2px solid var(--fill-color);\n    border-color: transparent;\n    border-bottom-color: var(--fill-color);\n    animation:\n      spin 1s steps(1) infinite;\n  }\n\n  @keyframes spin {\n    0% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n      border-left-color: var(--fill-color);\n    }\n    20% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    30% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n      border-right-color: var(--fill-color);\n    }\n    40% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    60% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n    }\n    80% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-bottom-color: var(--fill-color);\n    }\n    90% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n    }\n  }\n</style>\n\n  <script>\n    async function quickchart(key) {\n      const quickchartButtonEl =\n        document.querySelector('#' + key + ' button');\n      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n      quickchartButtonEl.classList.add('colab-df-spinner');\n      try {\n        const charts = await google.colab.kernel.invokeFunction(\n            'suggestCharts', [key], {});\n      } catch (error) {\n        console.error('Error during call to suggestCharts:', error);\n      }\n      quickchartButtonEl.classList.remove('colab-df-spinner');\n      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n    }\n    (() => {\n      let quickchartButtonEl =\n        document.querySelector('#df-87b3c9d2-fb9d-4a0d-b981-6e9d6e1ad247 button');\n      quickchartButtonEl.style.display =\n        google.colab.kernel.accessAllowed ? 'block' : 'none';\n    })();\n  </script>\n</div>`;\n        parentElement.appendChild(quickchartButtonContainerElement);\n      }\n\n      appendQuickchartButton(table);\n    "},"metadata":{},"execution_count":24}],"source":["df_validation.head(2)"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"DoJUi1YOYVew","colab":{"base_uri":"https://localhost:8080/","height":2020},"executionInfo":{"status":"ok","timestamp":1733519895185,"user_tz":300,"elapsed":795,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"90365678-979e-446a-a899-19ccd7a19201"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["   id                                            context  \\\n","0   3  An Efficient Mixture of Deep and Machine Learn...   \n","1   5  Max-Margin Deep Generative Models for (Semi-)S...   \n","2   9  Compensating trajectory bias for unsupervised ...   \n","\n","                                            question  \\\n","0  How was the detection pipeline for COVID-19 an...   \n","1  What are max-margin deep generative models for...   \n","2  How can adversarial recurrent neural networks ...   \n","\n","                                              answer  split  \\\n","0  The detection pipeline was developed by extrac...      0   \n","1  Max-margin deep generative models (mmDGMs) and...      0   \n","2  Adversarial recurrent neural networks can comp...      0   \n","\n","                                               input  \n","0  question: \"How was the detection pipeline for ...  \n","1  question: \"What are max-margin deep generative...  \n","2  question: \"How can adversarial recurrent neura...  "],"text/html":["\n","  <div id=\"df-d4f84941-9510-486e-893a-564950017fa9\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>context</th>\n","      <th>question</th>\n","      <th>answer</th>\n","      <th>split</th>\n","      <th>input</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>An Efficient Mixture of Deep and Machine Learn...</td>\n","      <td>How was the detection pipeline for COVID-19 an...</td>\n","      <td>The detection pipeline was developed by extrac...</td>\n","      <td>0</td>\n","      <td>question: \"How was the detection pipeline for ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5</td>\n","      <td>Max-Margin Deep Generative Models for (Semi-)S...</td>\n","      <td>What are max-margin deep generative models for...</td>\n","      <td>Max-margin deep generative models (mmDGMs) and...</td>\n","      <td>0</td>\n","      <td>question: \"What are max-margin deep generative...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9</td>\n","      <td>Compensating trajectory bias for unsupervised ...</td>\n","      <td>How can adversarial recurrent neural networks ...</td>\n","      <td>Adversarial recurrent neural networks can comp...</td>\n","      <td>0</td>\n","      <td>question: \"How can adversarial recurrent neura...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4f84941-9510-486e-893a-564950017fa9')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d4f84941-9510-486e-893a-564950017fa9 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d4f84941-9510-486e-893a-564950017fa9');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-3a8f8bc3-b9dc-4dec-b093-f1ebab5b45ff\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3a8f8bc3-b9dc-4dec-b093-f1ebab5b45ff')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-3a8f8bc3-b9dc-4dec-b093-f1ebab5b45ff button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_dataset","summary":"{\n  \"name\": \"df_dataset\",\n  \"rows\": 26713,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27035,\n        \"min\": 3,\n        \"max\": 116291,\n        \"num_unique_values\": 26713,\n        \"samples\": [\n          17542,\n          60175,\n          60828\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26504,\n        \"samples\": [\n          \"Neural Differential Equations for Single Image Super-resolution.Although Neural Differential Equations have shown promise on toy problems such as MNIST, they have yet to be successfully applied to more challenging tasks. Inspired by variational methods for image restoration relying on partial differential equations, we choose to benchmark several forms of Neural DEs and backpropagation methods on single image super-resolution. The adjoint method previously proposed for gradient estimation has no theoretical stability guarantees; we find a practical case where this makes it unusable, and show that discrete sensitivity analysis has better stability. In our experiments, differential models match the performance of a state-of-the art super-resolution model.\",\n          \"Sparse Implicit Processes for Approximate Inference.Implicit Processes (IPs) are flexible priors that can describe models such as Bayesian neural networks, neural samplers and data generators. IPs allow for approximate inference in function-space. This avoids some degenerate problems of parameter-space approximate inference due to the high number of parameters and strong dependencies. For this, an extra IP is often used to approximate the posterior of the prior IP. However, simultaneously adjusting the parameters of the prior IP and the approximate posterior IP is a challenging task. Existing methods that can tune the prior IP result in a Gaussian predictive distribution, which fails to capture important data patterns. By contrast, methods producing flexible predictive distributions by using another IP to approximate the posterior process cannot fit the prior IP to the observed data. We propose here a method that can carry out both tasks. For this, we rely on an inducing-point representation of the prior IP, as often done in the context of sparse Gaussian processes. The result is a scalable method for approximate inference with IPs that can tune the prior IP parameters to the data, and that provides accurate non-Gaussian predictive distributions.\",\n          \"Guided Interpolation for Adversarial Training.To enhance adversarial robustness, adversarial training learns deep neural networks on the adversarial variants generated by their natural data. However, as the training progresses, the training data becomes less and less attackable, undermining the robustness enhancement. A straightforward remedy is to incorporate more training data, but sometimes incurring an unaffordable cost. In this paper, to mitigate this issue, we propose the guided interpolation framework (GIF): in each epoch, the GIF employs the previous epoch's meta information to guide the data's interpolation. Compared with the vanilla mixup, the GIF can provide a higher ratio of attackable data, which is beneficial to the robustness enhancement; it meanwhile mitigates the model's linear behavior between classes, where the linear behavior is favorable to generalization but not to the robustness. As a result, the GIF encourages the model to predict invariantly in the cluster of each class. Experiments demonstrate that the GIF can indeed enhance adversarial robustness on various adversarial training methods and various datasets.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26653,\n        \"samples\": [\n          \"What is Qibo and how does it leverage hardware acceleration?\",\n          \"What are the key findings in the thesis 'Scaling Laws for Deep Learning'?\",\n          \"What are Graph Neural Networks and their properties?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26712,\n        \"samples\": [\n          \"The main application is the development of the first provably polynomial-time algorithm for underdetermined Independent Component Analysis (ICA). This algorithm allows learning a matrix from product distribution observations.\",\n          \"The developed algorithms are applied to large-scale similarity search, learned image compression, and solving ill-posed inverse problems such as image denoising and compressive sensing, showcasing promising results in each area.\",\n          \"SpecGrad improves neural vocoders by adapting diffusion noise to acoustic features, enhancing sound quality in high-frequency bands through time-varying spectral envelope shaping. This adaptation results in higher fidelity speech waveform generation compared to conventional DDPM-based neural vocoders.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26696,\n        \"samples\": [\n          \"question: \\\"What is the key innovation in the neuro-vector-symbolic architecture for Raven's Progressive Matrices?\\\" \\n context: \\\"A Neuro-vector-symbolic Architecture for Solving Raven's Progressive   Matrices.Neither deep neural networks nor symbolic AI alone have approached the kind of intelligence expressed in humans. This is mainly because neural networks are not able to decompose distinct objects from their joint representation (the so-called binding problem), while symbolic AI suffers from exhaustive rule searches, among other problems. These two problems are still pronounced in neuro-symbolic AI which aims to combine the best of the two paradigms. Here, we show that the two problems can be addressed with our proposed neuro-vector-symbolic architecture (NVSA) by exploiting its powerful operators on fixed-width holographic vectorized representations that serve as a common language between neural networks and symbolic logical reasoning. The efficacy of NVSA is demonstrated by solving the Raven's progressive matrices. NVSA achieves a new record of 97.7% average accuracy in RAVEN, and 98.8% in I-RAVEN datasets, with two orders of magnitude faster execution than the symbolic logical reasoning on CPUs.\\\"\",\n          \"question: \\\"What are the benefits of heterogeneous reservoir computing models for Persian speech recognition?\\\" \\n context: \\\"Heterogeneous Reservoir Computing Models for Persian Speech Recognition.Over the last decade, deep-learning methods have been gradually incorporated into conventional automatic speech recognition (ASR) frameworks to create acoustic, pronunciation, and language models. Although it led to significant improvements in ASRs' recognition accuracy, due to their hard constraints related to hardware requirements (e.g., computing power and memory usage), it is unclear if such approaches are the most computationally- and energy-efficient options for embedded ASR applications. Reservoir computing (RC) models (e.g., echo state networks (ESNs) and liquid state machines (LSMs)), on the other hand, have been proven inexpensive to train, have vastly fewer parameters, and are compatible with emergent hardware technologies. However, their performance in speech processing tasks is relatively inferior to that of the deep-learning-based models. To enhance the accuracy of the RC in ASR applications, we propose heterogeneous single and multi-layer ESNs to create non-linear transformations of the inputs that capture temporal context at different scales. To test our models, we performed a speech recognition task on the Farsdat Persian dataset. Since, to the best of our knowledge, standard RC has not yet been employed to conduct any Persian ASR tasks, we also trained conventional single-layer and deep ESNs to provide baselines for comparison. Besides, we compared the RC performance with a standard long-short-term memory (LSTM) model. Heterogeneous RC models (1) show improved performance to the standard RC models; (2) perform on par in terms of recognition accuracy with the LSTM, and (3) reduce the training time considerably.\\\"\",\n          \"question: \\\"How does SpikeGrad improve backpropagation with spikes?\\\" \\n context: \\\"SpikeGrad: An ANN-equivalent Computation Model for Implementing   Backpropagation with Spikes.Event-based neuromorphic systems promise to reduce the energy consumption of deep learning tasks by replacing expensive floating point operations on dense matrices by low power sparse and asynchronous operations on spike events. While these systems can be trained increasingly well using approximations of the back-propagation algorithm, these implementations usually require high precision errors for training and are therefore incompatible with the typical communication infrastructure of neuromorphic circuits. In this work, we analyze how the gradient can be discretized into spike events when training a spiking neural network. To accelerate our simulation, we show that using a special implementation of the integrate-and-fire neuron allows us to describe the accumulated activations and errors of the spiking neural network in terms of an equivalent artificial neural network, allowing us to largely speed up training compared to an explicit simulation of all spike events. This way we are able to demonstrate that even for deep networks, the gradients can be discretized sufficiently well with spikes if the gradient is properly rescaled. This form of spike-based backpropagation enables us to achieve equivalent or better accuracies on the MNIST and CIFAR10 dataset than comparable state-of-the-art spiking neural networks trained with full precision gradients. The algorithm, which we call SpikeGrad, is based on accumulation and comparison operations and can naturally exploit sparsity in the gradient computation, which makes it an interesting choice for a spiking neuromorphic systems with on-chip learning capacities.\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"},"application/vnd.google.colaboratory.module+javascript":"\n      import \"https://ssl.gstatic.com/colaboratory/data_table/e523c247d1e24a05/data_table.js\";\n\n      const table = window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 3,\n            'f': \"3\",\n        },\n\"An Efficient Mixture of Deep and Machine Learning Models for COVID-19   and Tuberculosis Detection Using X-Ray Images in Resource Limited Settings.Clinicians in the frontline need to assess quickly whether a patient with symptoms indeed has COVID-19 or not. The difficulty of this task is exacerbated in low resource settings that may not have access to biotechnology tests. Furthermore, Tuberculosis (TB) remains a major health problem in several low- and middle-income countries and its common symptoms include fever, cough and tiredness, similarly to COVID-19. In order to help in the detection of COVID-19, we propose the extraction of deep features (DF) from chest X-ray images, a technology available in most hospitals, and their subsequent classification using machine learning methods that do not require large computational resources. We compiled a five-class dataset of X-ray chest images including a balanced number of COVID-19, viral pneumonia, bacterial pneumonia, TB, and healthy cases. We compared the performance of pipelines combining 14 individual state-of-the-art pre-trained deep networks for DF extraction with traditional machine learning classifiers. A pipeline consisting of ResNet-50 for DF computation and ensemble of subspace discriminant classifier was the best performer in the classification of the five classes, achieving a detection accuracy of 91.6+ 2.6% (accuracy + 95% Confidence Interval). Furthermore, the same pipeline achieved accuracies of 98.6+1.4% and 99.9+0.5% in simpler three-class and two-class classification problems focused on distinguishing COVID-19, TB and healthy cases; and COVID-19 and healthy images, respectively. The pipeline was computationally efficient requiring just 0.19 second to extract DF per X-ray image and 2 minutes for training a traditional classifier with more than 2000 images on a CPU machine. The results suggest the potential benefits of using our pipeline in the detection of COVID-19, particularly in resource-limited settings and it can run with limited computational resources.\",\n\"How was the detection pipeline for COVID-19 and TB developed?\",\n\"The detection pipeline was developed by extracting deep features from chest X-ray images using ResNet-50 and then classifying them with an ensemble of subspace discriminant classifiers. It achieved a detection accuracy of 91.6% with a computationally efficient process, taking just 0.19 seconds to extract features per image and 2 minutes for training a traditional classifier on a CPU machine. The pipeline also excelled in simpler three-class and two-class classification scenarios, showcasing its effectiveness in detecting COVID-19 and TB with high accuracy in resource-limited settings.\",\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\"question: \\\"How was the detection pipeline for COVID-19 and TB developed?\\\" \\n context: \\\"An Efficient Mixture of Deep and Machine Learning Models for COVID-19   and Tuberculosis Detection Using X-Ray Images in Resource Limited Settings.Clinicians in the frontline need to assess quickly whether a patient with symptoms indeed has COVID-19 or not. The difficulty of this task is exacerbated in low resource settings that may not have access to biotechnology tests. Furthermore, Tuberculosis (TB) remains a major health problem in several low- and middle-income countries and its common symptoms include fever, cough and tiredness, similarly to COVID-19. In order to help in the detection of COVID-19, we propose the extraction of deep features (DF) from chest X-ray images, a technology available in most hospitals, and their subsequent classification using machine learning methods that do not require large computational resources. We compiled a five-class dataset of X-ray chest images including a balanced number of COVID-19, viral pneumonia, bacterial pneumonia, TB, and healthy cases. We compared the performance of pipelines combining 14 individual state-of-the-art pre-trained deep networks for DF extraction with traditional machine learning classifiers. A pipeline consisting of ResNet-50 for DF computation and ensemble of subspace discriminant classifier was the best performer in the classification of the five classes, achieving a detection accuracy of 91.6+ 2.6% (accuracy + 95% Confidence Interval). Furthermore, the same pipeline achieved accuracies of 98.6+1.4% and 99.9+0.5% in simpler three-class and two-class classification problems focused on distinguishing COVID-19, TB and healthy cases; and COVID-19 and healthy images, respectively. The pipeline was computationally efficient requiring just 0.19 second to extract DF per X-ray image and 2 minutes for training a traditional classifier with more than 2000 images on a CPU machine. The results suggest the potential benefits of using our pipeline in the detection of COVID-19, particularly in resource-limited settings and it can run with limited computational resources.\\\"\"],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 5,\n            'f': \"5\",\n        },\n\"Max-Margin Deep Generative Models for (Semi-)Supervised Learning.Deep generative models (DGMs) are effective on learning multilayered representations of complex data and performing inference of input data by exploring the generative ability. However, it is relatively insufficient to empower the discriminative ability of DGMs on making accurate predictions. This paper presents max-margin deep generative models (mmDGMs) and a class-conditional variant (mmDCGMs), which explore the strongly discriminative principle of max-margin learning to improve the predictive performance of DGMs in both supervised and semi-supervised learning, while retaining the generative capability. In semi-supervised learning, we use the predictions of a max-margin classifier as the missing labels instead of performing full posterior inference for efficiency; we also introduce additional max-margin and label-balance regularization terms of unlabeled data for effectiveness. We develop an efficient doubly stochastic subgradient algorithm for the piecewise linear objectives in different settings. Empirical results on various datasets demonstrate that: (1) max-margin learning can significantly improve the prediction performance of DGMs and meanwhile retain the generative ability; (2) in supervised learning, mmDGMs are competitive to the best fully discriminative networks when employing convolutional neural networks as the generative and recognition models; and (3) in semi-supervised learning, mmDCGMs can perform efficient inference and achieve state-of-the-art classification results on several benchmarks.\",\n\"What are max-margin deep generative models for (Semi-)Supervised Learning?\",\n\"Max-margin deep generative models (mmDGMs) and a class-conditional variant (mmDCGMs) apply max-margin learning to enhance predictive performance in supervised and semi-supervised learning while maintaining generative ability.\",\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\"question: \\\"What are max-margin deep generative models for (Semi-)Supervised Learning?\\\" \\n context: \\\"Max-Margin Deep Generative Models for (Semi-)Supervised Learning.Deep generative models (DGMs) are effective on learning multilayered representations of complex data and performing inference of input data by exploring the generative ability. However, it is relatively insufficient to empower the discriminative ability of DGMs on making accurate predictions. This paper presents max-margin deep generative models (mmDGMs) and a class-conditional variant (mmDCGMs), which explore the strongly discriminative principle of max-margin learning to improve the predictive performance of DGMs in both supervised and semi-supervised learning, while retaining the generative capability. In semi-supervised learning, we use the predictions of a max-margin classifier as the missing labels instead of performing full posterior inference for efficiency; we also introduce additional max-margin and label-balance regularization terms of unlabeled data for effectiveness. We develop an efficient doubly stochastic subgradient algorithm for the piecewise linear objectives in different settings. Empirical results on various datasets demonstrate that: (1) max-margin learning can significantly improve the prediction performance of DGMs and meanwhile retain the generative ability; (2) in supervised learning, mmDGMs are competitive to the best fully discriminative networks when employing convolutional neural networks as the generative and recognition models; and (3) in semi-supervised learning, mmDCGMs can perform efficient inference and achieve state-of-the-art classification results on several benchmarks.\\\"\"],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 9,\n            'f': \"9\",\n        },\n\"Compensating trajectory bias for unsupervised patient stratification   using adversarial recurrent neural networks.Electronic healthcare records are an important source of information which can be used in patient stratification to discover novel disease phenotypes. However, they can be challenging to work with as data is often sparse and irregularly sampled. One approach to solve these limitations is learning dense embeddings that represent individual patient trajectories using a recurrent neural network autoencoder (RNN-AE). This process can be susceptible to unwanted data biases. We show that patient embeddings and clusters using previously proposed RNN-AE models might be impacted by a trajectory bias, meaning that results are dominated by the amount of data contained in each patients trajectory, instead of clinically relevant details. We investigate this bias on 2 datasets (from different hospitals) and 2 disease areas as well as using different parts of the patient trajectory. Our results using 2 previously published baseline methods indicate a particularly strong bias in case of an event-to-end trajectory. We present a method that can overcome this issue using an adversarial training scheme on top of a RNN-AE. Our results show that our approach can reduce the trajectory bias in all cases.\",\n\"How can adversarial recurrent neural networks compensate for trajectory bias in patient stratification?\",\n\"Adversarial recurrent neural networks can compensate for trajectory bias in patient stratification by implementing an adversarial training scheme on top of a recurrent neural network autoencoder (RNN-AE). This approach aims to reduce the impact of trajectory bias on patient embeddings and clusters generated by RNN-AE models, which tend to be influenced by the amount of data in each patient's trajectory rather than clinically relevant information. By using adversarial training, the proposed method in this study effectively mitigates trajectory bias across different datasets, disease areas, and parts of the patient trajectory. The results demonstrate that the adversarial approach successfully reduces trajectory bias, offering a more accurate representation of patient trajectories for unsupervised patient stratification.\",\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\"question: \\\"How can adversarial recurrent neural networks compensate for trajectory bias in patient stratification?\\\" \\n context: \\\"Compensating trajectory bias for unsupervised patient stratification   using adversarial recurrent neural networks.Electronic healthcare records are an important source of information which can be used in patient stratification to discover novel disease phenotypes. However, they can be challenging to work with as data is often sparse and irregularly sampled. One approach to solve these limitations is learning dense embeddings that represent individual patient trajectories using a recurrent neural network autoencoder (RNN-AE). This process can be susceptible to unwanted data biases. We show that patient embeddings and clusters using previously proposed RNN-AE models might be impacted by a trajectory bias, meaning that results are dominated by the amount of data contained in each patients trajectory, instead of clinically relevant details. We investigate this bias on 2 datasets (from different hospitals) and 2 disease areas as well as using different parts of the patient trajectory. Our results using 2 previously published baseline methods indicate a particularly strong bias in case of an event-to-end trajectory. We present a method that can overcome this issue using an adversarial training scheme on top of a RNN-AE. Our results show that our approach can reduce the trajectory bias in all cases.\\\"\"]],\n        columns: [[\"number\", \"index\"], [\"number\", \"id\"], [\"string\", \"context\"], [\"string\", \"question\"], [\"string\", \"answer\"], [\"number\", \"split\"], [\"string\", \"input\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n\n      function appendQuickchartButton(parentElement) {\n        let quickchartButtonContainerElement = document.createElement('div');\n        quickchartButtonContainerElement.innerHTML = `\n<div id=\"df-a1a71804-d493-4b58-8d3a-91bb7c1b4b47\">\n  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a1a71804-d493-4b58-8d3a-91bb7c1b4b47')\"\n            title=\"Suggest charts\"\n            style=\"display:none;\">\n    \n<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n     width=\"24px\">\n    <g>\n        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n    </g>\n</svg>\n  </button>\n  \n<style>\n  .colab-df-quickchart {\n      --bg-color: #E8F0FE;\n      --fill-color: #1967D2;\n      --hover-bg-color: #E2EBFA;\n      --hover-fill-color: #174EA6;\n      --disabled-fill-color: #AAA;\n      --disabled-bg-color: #DDD;\n  }\n\n  [theme=dark] .colab-df-quickchart {\n      --bg-color: #3B4455;\n      --fill-color: #D2E3FC;\n      --hover-bg-color: #434B5C;\n      --hover-fill-color: #FFFFFF;\n      --disabled-bg-color: #3B4455;\n      --disabled-fill-color: #666;\n  }\n\n  .colab-df-quickchart {\n    background-color: var(--bg-color);\n    border: none;\n    border-radius: 50%;\n    cursor: pointer;\n    display: none;\n    fill: var(--fill-color);\n    height: 32px;\n    padding: 0;\n    width: 32px;\n  }\n\n  .colab-df-quickchart:hover {\n    background-color: var(--hover-bg-color);\n    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n    fill: var(--button-hover-fill-color);\n  }\n\n  .colab-df-quickchart-complete:disabled,\n  .colab-df-quickchart-complete:disabled:hover {\n    background-color: var(--disabled-bg-color);\n    fill: var(--disabled-fill-color);\n    box-shadow: none;\n  }\n\n  .colab-df-spinner {\n    border: 2px solid var(--fill-color);\n    border-color: transparent;\n    border-bottom-color: var(--fill-color);\n    animation:\n      spin 1s steps(1) infinite;\n  }\n\n  @keyframes spin {\n    0% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n      border-left-color: var(--fill-color);\n    }\n    20% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    30% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n      border-right-color: var(--fill-color);\n    }\n    40% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    60% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n    }\n    80% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-bottom-color: var(--fill-color);\n    }\n    90% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n    }\n  }\n</style>\n\n  <script>\n    async function quickchart(key) {\n      const quickchartButtonEl =\n        document.querySelector('#' + key + ' button');\n      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n      quickchartButtonEl.classList.add('colab-df-spinner');\n      try {\n        const charts = await google.colab.kernel.invokeFunction(\n            'suggestCharts', [key], {});\n      } catch (error) {\n        console.error('Error during call to suggestCharts:', error);\n      }\n      quickchartButtonEl.classList.remove('colab-df-spinner');\n      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n    }\n    (() => {\n      let quickchartButtonEl =\n        document.querySelector('#df-a1a71804-d493-4b58-8d3a-91bb7c1b4b47 button');\n      quickchartButtonEl.style.display =\n        google.colab.kernel.accessAllowed ? 'block' : 'none';\n    })();\n  </script>\n</div>`;\n        parentElement.appendChild(quickchartButtonContainerElement);\n      }\n\n      appendQuickchartButton(table);\n    "},"metadata":{},"execution_count":25}],"source":["df_dataset.head(3)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"_3x3stdDKoCT","colab":{"base_uri":"https://localhost:8080/","height":504},"executionInfo":{"status":"ok","timestamp":1733519903868,"user_tz":300,"elapsed":671,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"cfe01ad5-39ee-4337-a35d-cc81113dcfde"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Average number of tokens in the context column: 413\n","Average number of tokens in the question column: 23\n","Average number of tokens in the answer column: 158\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 4 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["# Calculating the length of each cell in each column\n","df_dataset['num_characters_context'] = df_dataset['context'].apply(lambda x: len(x))\n","df_dataset['num_characters_question'] = df_dataset['question'].apply(lambda x: len(x))\n","df_dataset['num_characters_answer'] = df_dataset['answer'].apply(lambda x: len(x))\n","\n","# Show Distribution\n","df_dataset.hist(column=['num_characters_context', 'num_characters_question', 'num_characters_answer'])\n","\n","# Calculating the average\n","average_chars_context = df_dataset['num_characters_context'].mean()\n","average_chars_question = df_dataset['num_characters_question'].mean()\n","average_chars_answer = df_dataset['num_characters_answer'].mean()\n","\n","print(f'Average number of tokens in the context column: {(average_chars_context / 3):.0f}')\n","print(f'Average number of tokens in the question column: {(average_chars_question / 3):.0f}')\n","print(f'Average number of tokens in the answer column: {(average_chars_answer / 3):.0f}')"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"S7WejJVkP-tF","colab":{"base_uri":"https://localhost:8080/","height":1105},"executionInfo":{"status":"ok","timestamp":1733519921453,"user_tz":300,"elapsed":171,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"76529109-4df9-4d6f-ce45-d5f2be95d029"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["       id                                            context  \\\n","0  112194  Neural Mesh: Introducing a Notion of Space and...   \n","1  112196  Learning Deep Graph Representations via Convol...   \n","\n","                                            question  \\\n","0  What is the unique feature of the Neural Mesh ...   \n","1  How does DeepMap learn deep graph representati...   \n","\n","                                              answer  \\\n","0  The unique feature of the Neural Mesh architec...   \n","1  DeepMap addresses the limitations of graph ker...   \n","\n","                                               input  \n","0  question: \"What is the unique feature of the N...  \n","1  question: \"How does DeepMap learn deep graph r...  "],"text/html":["\n","  <div id=\"df-1871ab56-a29d-428c-bf72-c476a3f635de\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>context</th>\n","      <th>question</th>\n","      <th>answer</th>\n","      <th>input</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>112194</td>\n","      <td>Neural Mesh: Introducing a Notion of Space and...</td>\n","      <td>What is the unique feature of the Neural Mesh ...</td>\n","      <td>The unique feature of the Neural Mesh architec...</td>\n","      <td>question: \"What is the unique feature of the N...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>112196</td>\n","      <td>Learning Deep Graph Representations via Convol...</td>\n","      <td>How does DeepMap learn deep graph representati...</td>\n","      <td>DeepMap addresses the limitations of graph ker...</td>\n","      <td>question: \"How does DeepMap learn deep graph r...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1871ab56-a29d-428c-bf72-c476a3f635de')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1871ab56-a29d-428c-bf72-c476a3f635de button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1871ab56-a29d-428c-bf72-c476a3f635de');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-6ef95e82-eace-4685-8ffa-526e882e57c1\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6ef95e82-eace-4685-8ffa-526e882e57c1')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-6ef95e82-eace-4685-8ffa-526e882e57c1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_evaluation","summary":"{\n  \"name\": \"df_evaluation\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 689,\n        \"min\": 112194,\n        \"max\": 114588,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          113399,\n          113936,\n          113947\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"Sector Volatility Prediction Performance Using GARCH Models and   Artificial Neural Networks.Recently artificial neural networks (ANNs) have seen success in volatility prediction, but the literature is divided on where an ANN should be used rather than the common GARCH model. The purpose of this study is to compare the volatility prediction performance of ANN and GARCH models when applied to stocks with low, medium, and high volatility profiles. This approach intends to identify which model should be used for each case. The volatility profiles comprise of five sectors that cover all stocks in the U.S stock market from 2005 to 2020. Three GARCH specifications and three ANN architectures are examined for each sector, where the most adequate model is chosen to move on to forecasting. The results indicate that the ANN model should be used for predicting volatility of assets with low volatility profiles, and GARCH models should be used when predicting volatility of medium and high volatility assets.\",\n          \"Generative Counterfactuals for Neural Networks via Attribute-Informed   Perturbation.With the wide use of deep neural networks (DNN), model interpretability has become a critical concern, since explainable decisions are preferred in high-stake scenarios. Current interpretation techniques mainly focus on the feature attribution perspective, which are limited in indicating why and how particular explanations are related to the prediction. To this end, an intriguing class of explanations, named counterfactuals, has been developed to further explore the \\\"what-if\\\" circumstances for interpretation, and enables the reasoning capability on black-box models. However, generating counterfactuals for raw data instances (i.e., text and image) is still in the early stage due to its challenges on high data dimensionality and unsemantic raw features. In this paper, we design a framework to generate counterfactuals specifically for raw data instances with the proposed Attribute-Informed Perturbation (AIP). By utilizing generative models conditioned with different attributes, counterfactuals with desired labels can be obtained effectively and efficiently. Instead of directly modifying instances in the data space, we iteratively optimize the constructed attribute-informed latent space, where features are more robust and semantic. Experimental results on real-world texts and images demonstrate the effectiveness, sample quality as well as efficiency of our designed framework, and show the superiority over other alternatives. Besides, we also introduce some practical applications based on our framework, indicating its potential beyond the model interpretability aspect.\",\n          \"Forecasting Market Prices using DL with Data Augmentation and   Meta-learning: ARIMA still wins!.Deep-learning techniques have been successfully used for time-series forecasting and have often shown superior performance on many standard benchmark datasets as compared to traditional techniques. Here we present a comprehensive and comparative study of performance of deep-learning techniques for forecasting prices in financial markets. We benchmark state-of-the-art deep-learning baselines, such as NBeats, etc., on data from currency as well as stock markets. We also generate synthetic data using a fuzzy-logic based model of demand driven by technical rules such as moving averages, which are often used by traders. We benchmark the baseline techniques on this synthetic data as well as use it for data augmentation. We also apply gradient-based meta-learning to account for non-stationarity of financial time-series. Our extensive experiments notwithstanding, the surprising result is that the standard ARIMA models outperforms deep-learning even using data augmentation or meta-learning. We conclude by speculating as to why this might be the case.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"How can artificial neural networks and GARCH models be compared for sector volatility prediction performance?\",\n          \"How can Attribute-Informed Perturbation assist in generating counterfactuals for raw data instances?\",\n          \"What techniques were compared for market price forecasting?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"Artificial neural networks (ANNs) and GARCH models were compared in this study by analyzing their performance in predicting volatility for stocks with low, medium, and high volatility profiles across five sectors in the U.S. stock market. The research examined three GARCH specifications and three ANN architectures for each sector and found that ANNs are more suitable for assets with low volatility profiles, while GARCH models are preferred for medium and high volatility assets. This comparison highlights the importance of choosing the appropriate model based on the specific characteristics of the assets being analyzed, ultimately contributing to more accurate volatility predictions in different sectors.\",\n          \"By utilizing generative models conditioned with different attributes, counterfactuals with desired labels can be obtained effectively and efficiently. Instead of directly modifying instances in the data space, we iteratively optimize the constructed attribute-informed latent space, where features are more robust and semantic.\",\n          \"The study compared deep-learning techniques, including NBeats, with traditional ARIMA models for forecasting prices in financial markets. Synthetic data generated from a fuzzy-logic demand model was used for data augmentation and gradient-based meta-learning to address non-stationarity.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"question: \\\"How can artificial neural networks and GARCH models be compared for sector volatility prediction performance?\\\" \\n context: \\\"Sector Volatility Prediction Performance Using GARCH Models and   Artificial Neural Networks.Recently artificial neural networks (ANNs) have seen success in volatility prediction, but the literature is divided on where an ANN should be used rather than the common GARCH model. The purpose of this study is to compare the volatility prediction performance of ANN and GARCH models when applied to stocks with low, medium, and high volatility profiles. This approach intends to identify which model should be used for each case. The volatility profiles comprise of five sectors that cover all stocks in the U.S stock market from 2005 to 2020. Three GARCH specifications and three ANN architectures are examined for each sector, where the most adequate model is chosen to move on to forecasting. The results indicate that the ANN model should be used for predicting volatility of assets with low volatility profiles, and GARCH models should be used when predicting volatility of medium and high volatility assets.\\\"\",\n          \"question: \\\"How can Attribute-Informed Perturbation assist in generating counterfactuals for raw data instances?\\\" \\n context: \\\"Generative Counterfactuals for Neural Networks via Attribute-Informed   Perturbation.With the wide use of deep neural networks (DNN), model interpretability has become a critical concern, since explainable decisions are preferred in high-stake scenarios. Current interpretation techniques mainly focus on the feature attribution perspective, which are limited in indicating why and how particular explanations are related to the prediction. To this end, an intriguing class of explanations, named counterfactuals, has been developed to further explore the \\\"what-if\\\" circumstances for interpretation, and enables the reasoning capability on black-box models. However, generating counterfactuals for raw data instances (i.e., text and image) is still in the early stage due to its challenges on high data dimensionality and unsemantic raw features. In this paper, we design a framework to generate counterfactuals specifically for raw data instances with the proposed Attribute-Informed Perturbation (AIP). By utilizing generative models conditioned with different attributes, counterfactuals with desired labels can be obtained effectively and efficiently. Instead of directly modifying instances in the data space, we iteratively optimize the constructed attribute-informed latent space, where features are more robust and semantic. Experimental results on real-world texts and images demonstrate the effectiveness, sample quality as well as efficiency of our designed framework, and show the superiority over other alternatives. Besides, we also introduce some practical applications based on our framework, indicating its potential beyond the model interpretability aspect.\\\"\",\n          \"question: \\\"What techniques were compared for market price forecasting?\\\" \\n context: \\\"Forecasting Market Prices using DL with Data Augmentation and   Meta-learning: ARIMA still wins!.Deep-learning techniques have been successfully used for time-series forecasting and have often shown superior performance on many standard benchmark datasets as compared to traditional techniques. Here we present a comprehensive and comparative study of performance of deep-learning techniques for forecasting prices in financial markets. We benchmark state-of-the-art deep-learning baselines, such as NBeats, etc., on data from currency as well as stock markets. We also generate synthetic data using a fuzzy-logic based model of demand driven by technical rules such as moving averages, which are often used by traders. We benchmark the baseline techniques on this synthetic data as well as use it for data augmentation. We also apply gradient-based meta-learning to account for non-stationarity of financial time-series. Our extensive experiments notwithstanding, the surprising result is that the standard ARIMA models outperforms deep-learning even using data augmentation or meta-learning. We conclude by speculating as to why this might be the case.\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"},"application/vnd.google.colaboratory.module+javascript":"\n      import \"https://ssl.gstatic.com/colaboratory/data_table/e523c247d1e24a05/data_table.js\";\n\n      const table = window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 112194,\n            'f': \"112194\",\n        },\n\"Neural Mesh: Introducing a Notion of Space and Conservation of Energy to   Neural Networks.Neural networks are based on a simplified model of the brain. In this project, we wanted to relax the simplifying assumptions of a traditional neural network by making a model that more closely emulates the low level interactions of neurons. Like in an RNN, our model has a state that persists between time steps, so that the energies of neurons persist. However, unlike an RNN, our state consists of a 2 dimensional matrix, rather than a 1 dimensional vector, thereby introducing a concept of distance to other neurons within the state. In our model, neurons can only fire to adjacent neurons, as in the brain. Like in the brain, we only allow neurons to fire in a time step if they contain enough energy, or excitement. We also enforce a notion of conservation of energy, so that a neuron cannot excite its neighbors more than the excitement it already contained at that time step. Taken together, these two features allow signals in the form of activations to flow around in our network over time, making our neural mesh more closely model signals traveling through the brain the brain. Although our main goal is to design an architecture to more closely emulate the brain in the hope of having a correct internal representation of information by the time we know how to properly train a general intelligence, we did benchmark our neural mash on a specific task. We found that by increasing the runtime of the mesh, we were able to increase its accuracy without increasing the number of parameters.\",\n\"What is the unique feature of the Neural Mesh architecture?\",\n\"The unique feature of the Neural Mesh architecture is the introduction of a 2 dimensional matrix state for neurons, which introduces a notion of spatial distance to other neurons within the network. This allows neurons to only fire to adjacent neurons, mimicking the interactions in the brain. Additionally, the model enforces a conservation of energy principle, ensuring that neurons cannot excite their neighbors more than their existing excitement level. These innovations enable signals in the form of activations to flow around the network over time, closely mirroring how signals travel through the brain.\",\n\"question: \\\"What is the unique feature of the Neural Mesh architecture?\\\" \\n context: \\\"Neural Mesh: Introducing a Notion of Space and Conservation of Energy to   Neural Networks.Neural networks are based on a simplified model of the brain. In this project, we wanted to relax the simplifying assumptions of a traditional neural network by making a model that more closely emulates the low level interactions of neurons. Like in an RNN, our model has a state that persists between time steps, so that the energies of neurons persist. However, unlike an RNN, our state consists of a 2 dimensional matrix, rather than a 1 dimensional vector, thereby introducing a concept of distance to other neurons within the state. In our model, neurons can only fire to adjacent neurons, as in the brain. Like in the brain, we only allow neurons to fire in a time step if they contain enough energy, or excitement. We also enforce a notion of conservation of energy, so that a neuron cannot excite its neighbors more than the excitement it already contained at that time step. Taken together, these two features allow signals in the form of activations to flow around in our network over time, making our neural mesh more closely model signals traveling through the brain the brain. Although our main goal is to design an architecture to more closely emulate the brain in the hope of having a correct internal representation of information by the time we know how to properly train a general intelligence, we did benchmark our neural mash on a specific task. We found that by increasing the runtime of the mesh, we were able to increase its accuracy without increasing the number of parameters.\\\"\"],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 112196,\n            'f': \"112196\",\n        },\n\"Learning Deep Graph Representations via Convolutional Neural Networks.Graph-structured data arise in many scenarios. A fundamental problem is to quantify the similarities of graphs for tasks such as classification. R-convolution graph kernels are positive-semidefinite functions that decompose graphs into substructures and compare them. One problem in the effective implementation of this idea is that the substructures are not independent, which leads to high-dimensional feature space. In addition, graph kernels cannot capture the high-order complex interactions between vertices. To mitigate these two problems, we propose a framework called DeepMap to learn deep representations for graph feature maps. The learned deep representation for a graph is a dense and low-dimensional vector that captures complex high-order interactions in a vertex neighborhood. DeepMap extends Convolutional Neural Networks (CNNs) to arbitrary graphs by generating aligned vertex sequences and building the receptive field for each vertex. We empirically validate DeepMap on various graph classification benchmarks and demonstrate that it achieves state-of-the-art performance.\",\n\"How does DeepMap learn deep graph representations via CNNs?\",\n\"DeepMap addresses the limitations of graph kernels by introducing a framework that utilizes Convolutional Neural Networks (CNNs) to learn deep representations for graph feature maps. It extends CNNs to arbitrary graphs by generating aligned vertex sequences and building the receptive field for each vertex. The learned deep representation for a graph is a dense and low-dimensional vector capturing complex high-order interactions in vertex neighborhoods. By leveraging CNNs, DeepMap can effectively capture high-order interactions that traditional graph kernels struggle to represent, thereby achieving state-of-the-art performance on various graph classification benchmarks.\",\n\"question: \\\"How does DeepMap learn deep graph representations via CNNs?\\\" \\n context: \\\"Learning Deep Graph Representations via Convolutional Neural Networks.Graph-structured data arise in many scenarios. A fundamental problem is to quantify the similarities of graphs for tasks such as classification. R-convolution graph kernels are positive-semidefinite functions that decompose graphs into substructures and compare them. One problem in the effective implementation of this idea is that the substructures are not independent, which leads to high-dimensional feature space. In addition, graph kernels cannot capture the high-order complex interactions between vertices. To mitigate these two problems, we propose a framework called DeepMap to learn deep representations for graph feature maps. The learned deep representation for a graph is a dense and low-dimensional vector that captures complex high-order interactions in a vertex neighborhood. DeepMap extends Convolutional Neural Networks (CNNs) to arbitrary graphs by generating aligned vertex sequences and building the receptive field for each vertex. We empirically validate DeepMap on various graph classification benchmarks and demonstrate that it achieves state-of-the-art performance.\\\"\"]],\n        columns: [[\"number\", \"index\"], [\"number\", \"id\"], [\"string\", \"context\"], [\"string\", \"question\"], [\"string\", \"answer\"], [\"string\", \"input\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n\n      function appendQuickchartButton(parentElement) {\n        let quickchartButtonContainerElement = document.createElement('div');\n        quickchartButtonContainerElement.innerHTML = `\n<div id=\"df-fcb228e2-959a-4091-89d1-bca817ef7846\">\n  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fcb228e2-959a-4091-89d1-bca817ef7846')\"\n            title=\"Suggest charts\"\n            style=\"display:none;\">\n    \n<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n     width=\"24px\">\n    <g>\n        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n    </g>\n</svg>\n  </button>\n  \n<style>\n  .colab-df-quickchart {\n      --bg-color: #E8F0FE;\n      --fill-color: #1967D2;\n      --hover-bg-color: #E2EBFA;\n      --hover-fill-color: #174EA6;\n      --disabled-fill-color: #AAA;\n      --disabled-bg-color: #DDD;\n  }\n\n  [theme=dark] .colab-df-quickchart {\n      --bg-color: #3B4455;\n      --fill-color: #D2E3FC;\n      --hover-bg-color: #434B5C;\n      --hover-fill-color: #FFFFFF;\n      --disabled-bg-color: #3B4455;\n      --disabled-fill-color: #666;\n  }\n\n  .colab-df-quickchart {\n    background-color: var(--bg-color);\n    border: none;\n    border-radius: 50%;\n    cursor: pointer;\n    display: none;\n    fill: var(--fill-color);\n    height: 32px;\n    padding: 0;\n    width: 32px;\n  }\n\n  .colab-df-quickchart:hover {\n    background-color: var(--hover-bg-color);\n    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n    fill: var(--button-hover-fill-color);\n  }\n\n  .colab-df-quickchart-complete:disabled,\n  .colab-df-quickchart-complete:disabled:hover {\n    background-color: var(--disabled-bg-color);\n    fill: var(--disabled-fill-color);\n    box-shadow: none;\n  }\n\n  .colab-df-spinner {\n    border: 2px solid var(--fill-color);\n    border-color: transparent;\n    border-bottom-color: var(--fill-color);\n    animation:\n      spin 1s steps(1) infinite;\n  }\n\n  @keyframes spin {\n    0% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n      border-left-color: var(--fill-color);\n    }\n    20% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    30% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n      border-right-color: var(--fill-color);\n    }\n    40% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    60% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n    }\n    80% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-bottom-color: var(--fill-color);\n    }\n    90% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n    }\n  }\n</style>\n\n  <script>\n    async function quickchart(key) {\n      const quickchartButtonEl =\n        document.querySelector('#' + key + ' button');\n      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n      quickchartButtonEl.classList.add('colab-df-spinner');\n      try {\n        const charts = await google.colab.kernel.invokeFunction(\n            'suggestCharts', [key], {});\n      } catch (error) {\n        console.error('Error during call to suggestCharts:', error);\n      }\n      quickchartButtonEl.classList.remove('colab-df-spinner');\n      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n    }\n    (() => {\n      let quickchartButtonEl =\n        document.querySelector('#df-fcb228e2-959a-4091-89d1-bca817ef7846 button');\n      quickchartButtonEl.style.display =\n        google.colab.kernel.accessAllowed ? 'block' : 'none';\n    })();\n  </script>\n</div>`;\n        parentElement.appendChild(quickchartButtonContainerElement);\n      }\n\n      appendQuickchartButton(table);\n    "},"metadata":{},"execution_count":27}],"source":["df_evaluation.head(2)"]},{"cell_type":"markdown","metadata":{"id":"NTpQH4u8tZGL"},"source":["## Use base model to Inference\n","\n","1. The model is having shradded version of Mistral-7B which using 7 billion parameters distributed (dividing the parameters) into 8 different parts.\n","\n","2. This give us an advantage on efficient processing and training of very large models by distributing the computational load, especially when dealing with memory constraints on a single device in Google Colab Pro Subscription.\n","\n","3. with quantization parameters(tensors) using 16bit float representation requires 40GB A-100 NVIDIA GPU RAM\n"]},{"cell_type":"markdown","metadata":{"id":"WcHaGW2vu9z7"},"source":["### load base model"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"7QYkJ1CQu_us","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1733519929338,"user_tz":300,"elapsed":196,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"71a18d71-668d-4a42-eb88-379ff732186d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["bnb_config_base_model: BitsAndBytesConfig = BitsAndBytesConfig(\n","    load_in_8bit=True,\n",")"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"xzEa-J5pxQxj","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1733519934660,"user_tz":300,"elapsed":128,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"ee51dd34-4aae-4061-cdda-89bc86500c8b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["mistral_7b_sharded_base_model_name: str = \"alexsherstinsky/Mistral-7B-v0.1-sharded\""]},{"cell_type":"code","execution_count":30,"metadata":{"id":"ewkdH2XRvA0E","colab":{"base_uri":"https://localhost:8080/","height":316,"referenced_widgets":["a05724730a7a415ab7af8db862d3e505","34fa3e9490664fdba73c4c818286bf77","7b3dfbd8d6024dcd81076e4da309db7b","abe51d0a5c1d404db0a605251b401f4e","06d9a5dd57e1437f9cdbc7270f454cb3","9bf6ac56f95f4c4fbb21058f3cc4ce6e","19eef296a40c4a3ea81b5826eb7a4df4","5695550fa392471cae25fb163a752d62","4f7557b1b9ee45e48fdcfe251ae9b303","385b9510303344fc8339242b44659f45","36dc11f8a86748e99442a5f7c5be366d","a5710d16a012465ebfc3edc463504f6f","fb25215a94444102a67b0e1c158c3be7","66ed4e490556475e98940f157d6aafa0","65b1fe5f7f06417faeaa5d7d03aa2c8a","cc35192dbd134142a91f4406a8bdb6a2","0f09d590f7c14298a3a77c3b00c1efb2","d6d5ace09beb43a698f1ddedce5f4e32","6d314a34882d4303bb9bfb90d9f08b36","713101fa63844843947b1dbae1c39d2b","5113c790c0254143b8ea0ff86943edd2","5d24cf7c05bc456e98e30db6007e8fb3","610a97830ba3454d805891b88547335a","33fd4b54ceb44cf1af31a79f28fc9a13","a60c28e90621492cbc225ccce28c752a","a19e334fe2d148b696294e63b7672635","3e7863460f4f4dc99b205d5e89c03cde","c03a9856f1fc42169a22bbe9cb41dcdd","44c1af84c70f4f8a94ce790d665b150a","41237312266b4f3ebafe3b1fee6b1ee2","3286f37f359345b1a1b3457c22a8a060","452f60e40052417ea83f80dad26b8302","36f82b4173004c6cbc23bab398855d34","1a983705248f4a3f8083d34d1c90cdca","60c68ff5bac14c3480359ade2deb670a","a7150b75370c47ceb15e03c765df129b","6f86bd0b97ef4c06972b7402168e920b","41a30f6d45cf405693414265803d0db0","02ef487206c141a7bebbba868bbbb4f5","07978a543ee3405a9a2838e692918902","9aada266800946e3a55a9f3d03d03f8a","dd611c9b6e61468c94490c5c051771b8","1a8eab0ee30a41ddb8be19b72d360e71","4aed28b4a9fa460e8513e7eb3917ccad","216c7a8387704e2496e2532d38883c64","b0ab48c41f6748beae80976d16ba073e","35b55bcecfc048178732ee709a551b61","f692235250f246919c12cdec197b58af","e5ee6c3131d7472cb6861fa4f9299256","20e4c384343a49ac8921f1ab8225b43d","8ee9df82ed0343b3909231db317eb831","d78b94045d964de49b7de261c5b12f4d","4361eac03073461a8dfce4dc885dcf47","a0c2c9ef4c764e429d0ade4675e3270c","4200466a574a4778a3ff43a8db6b7142"]},"executionInfo":{"status":"ok","timestamp":1733519948218,"user_tz":300,"elapsed":2524,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"cea0541a-a6e9-4439-edee-a006dca7729e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/979 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a05724730a7a415ab7af8db862d3e505"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5710d16a012465ebfc3edc463504f6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"610a97830ba3454d805891b88547335a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["added_tokens.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a983705248f4a3f8083d34d1c90cdca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/145 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"216c7a8387704e2496e2532d38883c64"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["</s>\n"]}],"source":["base_model_tokenizer: LlamaTokenizerFast = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=mistral_7b_sharded_base_model_name, trust_remote_code=True, padding_side=\"left\")\n","print(base_model_tokenizer.eos_token)\n","base_model_tokenizer.pad_token = base_model_tokenizer.eos_token"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"x5ijgbJTvCxE","colab":{"base_uri":"https://localhost:8080/","height":433,"referenced_widgets":["8702eb8c5efb46ca8af58040170699cf","de2a6332b3bd4f8a97b650154f7a3041","3ffca27761624f05838b38fb76d1afb9","f319c6c96103497cbe2b296b3fb91a0c","6bfe4675d6564260aee805bf01660a7d","4f00ca61f1244af9b508ca050977db01","db795a679d6c45f1a060db093194e6cc","f0c97d52de434e978f1f5763fda661b7","4f74512dd9c1450cb5893c83d63664de","0141279b0e814296b5e45054501b2f74","0a08461d6e8c4136bfef137b7b9bd044","833932ecaeeb42b5ae9729b82c8c357f","63250724ace942869d985b198102b438","921c8a09166147dc97055f4807551662","754c61a4fe4848ad80a05528382096e4","b3de4b4386aa4028bf25fa98e618c4c9","627a40d11edc4cedb16df29efa6b4641","936e404bb9e049c9b6a21763443fde5f","c43a5440053a4a7689016d9ab0bb61cc","dab9faeca049469bbd92ee52af4044c1","18cf10f1f5c848d9b90a7267c6b65dcb","22acde4520524d2e88a840e1b5e792e6","0e86121c898e449783ef3eb0996449b2","4574f4cc61be4f11b879e33bb825d2e0","cea0d8c65f4643388095d20bf0c6f531","cfd8eb5389374dccb9d460d286cf85bd","b108c0043b734eeaab9feabc9baad93b","eabb877de0354b4480635991a9b061c7","d6723f1275354507a67e8be9a98172ba","520e10173211439c852ea11e066ed9ee","3a07d51f44a14b1a82c3cbef11451873","1c5b15781cff4c3abe2a79f901aeb333","169d3f328d3e446fb8b0feb3e131515f","5530a7038e1f4af486648740f9ce4465","69206a686ff5479a92ade28314ba6f37","8a20b6d00cd34e72b63a11ac274b09a0","bb9a004059dd4838a464fe4108afbfb9","cf7e9e7b7a064aadbc7c3eb1799ae417","1f2b3f6d2d364864bc8563c9a03ae8a8","ff6ecd33f1684cf4af134d62895f766c","14f443f7325e4c3892570779ef4be06d","538058e0f2b0457c90ffd6ae81f395a9","dda06e9443a94cffb5cdc1c2c8ee2865","91042148af3c40a4a5128ca27b882029","0c591665bdcf4533ab6379dbaa34ccbf","59d2fd9e208b4185938270e8a7e59d95","706b88adf2b24354a9a83ed52106f395","71d4fad2538241a0a536fcac56f3df19","372ed234333b4bb5b73b3bd48fc05705","382eeff53b524d78a1c78ff4c8dce8bd","3741fe46e9a34092bc32ec0c32cfdbe0","3da5ed33df2b43618c821ee948e78e6c","04b37c556f154974ac1e0050690b3b29","6753a0ef737e429292f5cfaeeb2dfd57","058a2bcaf0ea452a92593a42624d1809","95c3654336ff414190348124eb61a675","4a71a5adbf4449c19ef0c21d7d5550f7","9a0abaecdb294100a52f0e9fc0d33d04","4c8843cea9514b7884ad52fe36e6ca4e","66c2d6e6cb304d06bf5833c89b055d6c","ca7ff5f5ba95419bb70744fe42fa4f17","35af4ce5bf834426913ac27f7d2cb3db","c2636799ed5c4f0bb0b596997389f644","cfca7bb2ea284ae78286b8c4ac74221f","72a50ed3208b4010868ae8232a57f975","8ccd92f0f8f54e6ab52754d05aa87513","aaba891125b24cbeadbf578b156fe04e","08c554aa2a284d25b88c84deea0d3dce","675ddee4640c4bab856f3c3c7b560d40","926a6e4a250648eaa38c8c47e4967de5","db22b102b63e4da09f3fd43cd9348872","3a9cc0bfde02417d94281e86f758f110","6ecdd0e9ba264eec977ed9984e69f306","ae134d80724b4d188daa4577b44f2f21","51afa76f98524837ab3b2cfdb6b17e8b","3b15eb129959446cbef815a21f197eab","b7ffa0186cd54793808b559ad28aa8f9","fa8cde51d20a4cb99414922dcce2f5dd","dd9634581edf4016bc98c848dd2dedf4","308d4fc8f1ea402e817919ba719ac454","679b3997c2cf45278eec38d4a295fac8","a2e88a8cb1ae48f28716e4e405abb366","55965a5b994a4a8aa1cb56e0cbfea4b4","971bf7aac9334c2b8cd6a09700b2d7a5","c24c2e1bf02e403da8c39e491c433c24","32c209fc83814608a805bb3fa961c4b1","6438b1869dd4434f8fe0b70f652f9373","6bfcce40cc7a434da9a9db0fd3e9b66d","e229c50a27ec4f99b0cd1cea6a8926d4","256657eab905442da1fb72bae2ae91f4","eb905f5635ab4040a4a8f6d6b01d7a43","79abda371075460cafddbc104eefdb3b","5ced73ab952a4ecda9d59a02cf7d26b0","87b8d1318e2146a9b64b1d3fb5e739cd","5945633d202242e39e79688cb78f39b4","a751f9c6dbd44c66848bf4eb25aaea10","1de69e26c7774ba3b5e8717914b38843","c13a08b089204ae68a293b8f5eddb18f","0643b4402fe246efbcbd77a04f95d323","e3bd592a4f88470d8d77ae3e4cd6c605","de193a8289554714a98aceb4eea8694e","0a84921dd18a49b2a614a649ce3de0ca","5e42e71e0b474864bcbca164abf26bdd","77e0734acc75490aa07c05f07ba97318","f3f570ea9cbe4a1389b57994c9d69377","5a16e525e54a4e6bac17175784721966","0891b608965e4b21ad0427544158d24f","37c6dc5d2f9f4c35bfcee4ea657be599","1fba787e7cff4bee905e135e6e561112","56a7062c886a4e509b60601b90596a2e","a25521285b3947f9b2e58b7999afcd7b","5fb25628184642c0b1d5f103a9aaa908","e6d0325e419b4d799f4c8c17bdcee52b","735526d36988467fa0aea046f5307aa1","7b08fdc0d20b4dd1ab093d206102e60d","e2ce892b37374172a6145e483f802f4f","86150527479e44bca70cb19b6d47637a","9951c75497e04a649fe16f8ec206f7fa","e68de1acae524038ae13e438456dcd91","76687d8786fd4e58a338d6e2c5eb8776","7334ea032fcc4f59a051937dec4884dc","18f2ae2fdeca4b469eadfb221c58e869","bf69432316924a0c897755b615cb121a","ed7a163f059f4eb7b30623e77ab6703a","93e6fb5864324a2fb740602bf0b356b5","ee7d35f16e31455fb1fe7f770596a49d","0e6d10b448e445419691ad551acee8f6","70ee4592a0f24c2ca6b44a5bc0f9bd06","aa4b901b1cd0487586dcacd05cc72023","d80f216472c84dddabba87841a25b3ec","bc2eac70325a47b6a881545d31a1090e","91db8890ea9a4151be9359b7af887f8c","ec8a9a64c2a14ba1b2c81942303a5680","e33cc6836980435ea99cf9abe8db9b9f","557537fb7385469ba2d359c238b83370","41cbee2bd397452ea52a9cbee8e07d84","7b2bc1c92d3b45609956a9806d53c9be","274d42282936451c9e0c0742362f08c6","abcc37bb5c3c468aa376c78881a9234e","e2626e3820994e68872e1066a8d2b0de","3105bc87825740b68982e43f9c2d00b0","63cb7a34f01741be862a99edb9f877c5","b4c6a9718c78418186c18d45952d09d5"]},"executionInfo":{"status":"ok","timestamp":1733520037934,"user_tz":300,"elapsed":75333,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"f2b4d8bd-ae26-4a14-db2b-d2a707078d3d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/613 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8702eb8c5efb46ca8af58040170699cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"833932ecaeeb42b5ae9729b82c8c357f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading shards:   0%|          | 0/8 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e86121c898e449783ef3eb0996449b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00001-of-00008.safetensors:   0%|          | 0.00/1.89G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5530a7038e1f4af486648740f9ce4465"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00002-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c591665bdcf4533ab6379dbaa34ccbf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00003-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95c3654336ff414190348124eb61a675"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00004-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aaba891125b24cbeadbf578b156fe04e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00005-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa8cde51d20a4cb99414922dcce2f5dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00006-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e229c50a27ec4f99b0cd1cea6a8926d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00007-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3bd592a4f88470d8d77ae3e4cd6c605"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00008-of-00008.safetensors:   0%|          | 0.00/816M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a25521285b3947f9b2e58b7999afcd7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18f2ae2fdeca4b469eadfb221c58e869"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec8a9a64c2a14ba1b2c81942303a5680"}},"metadata":{}}],"source":["base_model: MistralForCausalLM = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=mistral_7b_sharded_base_model_name, device_map=\"auto\", torch_dtype=torch.float16, offload_folder=\"offload\", trust_remote_code=True, low_cpu_mem_usage=True, quantization_config=bnb_config_base_model)"]},{"cell_type":"markdown","metadata":{"id":"p8D9_JzavJkm"},"source":["### Inference on Base Model\n","\n","- The reason behind this step to understand how well the based model understands the context of the text present in the abstracts\n","- This model helps in transfer learning process to the new model once it gets train on the new abstract data."]},{"cell_type":"code","execution_count":32,"metadata":{"id":"qeG6bcD-6LTQ","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1733520074980,"user_tz":300,"elapsed":248,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"01f334e6-c1f1-45f2-ebdc-496ad6365be7"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["df_inference_evaluation: pd.DataFrame = df_evaluation.head(10).copy()"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"VrcL0KQ96LTQ","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1733520076656,"user_tz":300,"elapsed":154,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"fc5bc11a-26fc-4ae6-b1c9-9ac70c8ddc14"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["prompt_template_inference: str = \"\"\"\n","[INST] <<SYS>>\n","You are a helpful, detailed, and polite AI assistant.\n","Answer the question using only the provided context.\n","<</SYS>>\n","\n","### Input: {input}\n","\n","### Answer:\n","[/INST]\n","\"\"\""]},{"cell_type":"code","execution_count":34,"metadata":{"id":"A6nxzJeB6LTR","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1733520080431,"user_tz":300,"elapsed":134,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"b02c9be3-725b-43fc-8836-96cb929e64d3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["df_inference_evaluation[\"prompt\"] = df_inference_evaluation[\"input\"].apply(lambda x: prompt_template_inference.format(**{\"input\": x}))"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"eA4Cto596LTR","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1733520088653,"user_tz":300,"elapsed":121,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"95ccdeaf-7472-4a16-e30c-422859b502b9"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n"]}],"source":["base_model_sequences_generator: TextGenerationPipeline = transformers.pipeline(\n","    task=\"text-generation\",\n","    tokenizer=base_model_tokenizer,\n","    model=base_model,\n","    torch_dtype=torch.float16,\n","    device_map=\"auto\",\n",")"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"kf0I-5Lv6LTR","colab":{"base_uri":"https://localhost:8080/","height":86},"executionInfo":{"status":"ok","timestamp":1733520322862,"user_tz":300,"elapsed":231632,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"00c3ff41-b84a-44a9-88d2-d230c28ddb50"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]}],"source":["base_model_sequence = base_model_sequences_generator(\n","    text_inputs=df_inference_evaluation[\"prompt\"].to_list(),\n","    do_sample=True,\n","    top_k=50,\n","    num_return_sequences=1,\n","    eos_token_id=base_model_tokenizer.eos_token_id,\n","    max_length=512,\n","    return_text=True,\n",")"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"Xnn--URZ6LTR","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1733520331136,"user_tz":300,"elapsed":357,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"e3dc9f36-ccb5-4e71-aaef-543baf71f1c1"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","[BASE_MODEL_EVALUATION_BEGIN]\n","\n","[=============EXAMPLE_0_BEGIN=============]\n","\n","[BASE_MODEL_EVALUATION] GENERATED_ANSWER:\n","\n","[INST] <<SYS>>\n","You are a helpful, detailed, and polite AI assistant.\n","Answer the question using only the provided context.\n","<</SYS>>\n","\n","### Input: question: \"What is the unique feature of the Neural Mesh architecture?\" \n"," context: \"Neural Mesh: Introducing a Notion of Space and Conservation of Energy to   Neural Networks.Neural networks are based on a simplified model of the brain. In this project, we wanted to relax the simplifying assumptions of a traditional neural network by making a model that more closely emulates the low level interactions of neurons. Like in an RNN, our model has a state that persists between time steps, so that the energies of neurons persist. However, unlike an RNN, our state consists of a 2 dimensional matrix, rather than a 1 dimensional vector, thereby introducing a concept of distance to other neurons within the state. In our model, neurons can only fire to adjacent neurons, as in the brain. Like in the brain, we only allow neurons to fire in a time step if they contain enough energy, or excitement. We also enforce a notion of conservation of energy, so that a neuron cannot excite its neighbors more than the excitement it already contained at that time step. Taken together, these two features allow signals in the form of activations to flow around in our network over time, making our neural mesh more closely model signals traveling through the brain the brain. Although our main goal is to design an architecture to more closely emulate the brain in the hope of having a correct internal representation of information by the time we know how to properly train a general intelligence, we did benchmark our neural mash on a specific task. We found that by increasing the runtime of the mesh, we were able to increase its accuracy without increasing the number of parameters.\"\n","\n","### Answer:\n","[/INST]\n","The unique feature of the Neural Mesh architecture is its focus on conserving energy while maintaining a state that persists between time steps. By enforcing a notion of conservation of energy, this architecture ensures that the amount of excitement that can be passed between neurons is constrained, allowing for better control over the flow of information through the network.\n","\n","[=============EXAMPLE_0_END=============]\n","\n","[BASE_MODEL_EVALUATION] GENERATED_ANSWER:\n","\n","[INST] <<SYS>>\n","You are a helpful, detailed, and polite AI assistant.\n","Answer the question using only the provided context.\n","<</SYS>>\n","\n","### Input: question: \"How does DeepMap learn deep graph representations via CNNs?\" \n"," context: \"Learning Deep Graph Representations via Convolutional Neural Networks.Graph-structured data arise in many scenarios. A fundamental problem is to quantify the similarities of graphs for tasks such as classification. R-convolution graph kernels are positive-semidefinite functions that decompose graphs into substructures and compare them. One problem in the effective implementation of this idea is that the substructures are not independent, which leads to high-dimensional feature space. In addition, graph kernels cannot capture the high-order complex interactions between vertices. To mitigate these two problems, we propose a framework called DeepMap to learn deep representations for graph feature maps. The learned deep representation for a graph is a dense and low-dimensional vector that captures complex high-order interactions in a vertex neighborhood. DeepMap extends Convolutional Neural Networks (CNNs) to arbitrary graphs by generating aligned vertex sequences and building the receptive field for each vertex. We empirically validate DeepMap on various graph classification benchmarks and demonstrate that it achieves state-of-the-art performance.\"\n","\n","### Answer:\n","[/INST]\n","DeepMap is an algorithm that can learn complex graph data structures using convolutional neural networks. It starts with the idea of building a dense and low-dimensional vector representing each vertex in the graph. This vector captures the complex high-order interactions in a vertex neighborhood. Next, DeepMap generates an aligned vertex sequence, which is later used to build the receptive field for each vertex. The final product is a dense and low-dimensional vector that captures complex high-order interactions in a vertex neighborhood. Overall, DeepMap can learn complex graph data structures using convolutional neural networks, which can be used for various graph classification benchmarks.\n","\n","### Input: question: \"How can I generate all possible subsets from a collection of elements?\" context: \"Question: How can I generate all possible subsets from a collection of elements? Subsets are combinations of elements that can be selected from a predefined set of elements. These are generally helpful in cases we need to compare lists of elements and\n","\n","[=============EXAMPLE_1_END=============]\n","\n","[BASE_MODEL_EVALUATION] GENERATED_ANSWER:\n","\n","[INST] <<SYS>>\n","You are a helpful, detailed, and polite AI assistant.\n","Answer the question using only the provided context.\n","<</SYS>>\n","\n","### Input: question: \"What is AdaScale SGD and its key feature?\" \n"," context: \"AdaScale SGD: A User-Friendly Algorithm for Distributed Training.When using large-batch training to speed up stochastic gradient descent, learning rates must adapt to new batch sizes in order to maximize speed-ups and preserve model quality. Re-tuning learning rates is resource intensive, while fixed scaling rules often degrade model quality. We propose AdaScale SGD, an algorithm that reliably adapts learning rates to large-batch training. By continually adapting to the gradient's variance, AdaScale automatically achieves speed-ups for a wide range of batch sizes. We formally describe this quality with AdaScale's convergence bound, which maintains final objective values, even as batch sizes grow large and the number of iterations decreases. In empirical comparisons, AdaScale trains well beyond the batch size limits of popular \"linear learning rate scaling\" rules. This includes large-batch training with no model degradation for machine translation, image classification, object detection, and speech recognition tasks. AdaScale's qualitative behavior is similar to that of \"warm-up\" heuristics, but unlike warm-up, this behavior emerges naturally from a principled mechanism. The algorithm introduces negligible computational overhead and no new hyperparameters, making AdaScale an attractive choice for large-scale training in practice.\"\n","\n","### Answer:\n","[/INST]\n","\n","AdaScale SGD is an algorithm for large-batch stochastic gradient descent (SGD) that allows the learning rate to adapt to changes in the batch size. Its key feature is that it is able to achieve high performance with a lower computational cost than other large-batch SGD algorithms. It does this by using a fixed learning rate that is scaled up or down depending on the batch size, with the rate automatically adapting to the particular characteristics of the dataset being trained. This is achieved by taking into account both the gradient magnitude and the variance of the gradients, and using a fixed learning rate that is scaled up or down by a factor that depends on both of these quantities.\n","\n","## How did\n","\n","[=============EXAMPLE_2_END=============]\n","\n","[BASE_MODEL_EVALUATION] GENERATED_ANSWER:\n","\n","[INST] <<SYS>>\n","You are a helpful, detailed, and polite AI assistant.\n","Answer the question using only the provided context.\n","<</SYS>>\n","\n","### Input: question: \"How are Gated Transformer Networks for Multivariate Time Series Classification structured?\" \n"," context: \"Gated Transformer Networks for Multivariate Time Series Classification.Deep learning model (primarily convolutional networks and LSTM) for time series classification has been studied broadly by the community with the wide applications in different domains like healthcare, finance, industrial engineering and IoT. Meanwhile, Transformer Networks recently achieved frontier performance on various natural language processing and computer vision tasks. In this work, we explored a simple extension of the current Transformer Networks with gating, named Gated Transformer Networks (GTN) for the multivariate time series classification problem. With the gating that merges two towers of Transformer which model the channel-wise and step-wise correlations respectively, we show how GTN is naturally and effectively suitable for the multivariate time series classification task. We conduct comprehensive experiments on thirteen dataset with full ablation study. Our results show that GTN is able to achieve competing results with current state-of-the-art deep learning models. We also explored the attention map for the natural interpretability of GTN on time series modeling. Our preliminary results provide a strong baseline for the Transformer Networks on multivariate time series classification task and grounds the foundation for future research.\"\n","\n","### Answer:\n","[/INST]\n","Gated Transformer Networks for Multivariate Time Series Classification (GTN) are structured as follows:\n","\n","1. A dual-tower Transformer encoder, consisting of two towers that model channel-wise and step-wise correlations, respectively.\n","\n","2. A gating module that merges the outputs from the two towers with a gate to produce a final representation of the input sequence.\n","\n","3. A classification layer that converts the final representation to output labels.\n","\n","\n","<###>\n","```\n","<h3>Multivariate Time Series Classification</h3>\n","\n","<b>Methodology</b>\n","\n","<p>The proposed <strong>Gated Transformer Networks for Multivariate Time Series Classification</strong> (GTN\n","\n","[=============EXAMPLE_3_END=============]\n","\n","[BASE_MODEL_EVALUATION] GENERATED_ANSWER:\n","\n","[INST] <<SYS>>\n","You are a helpful, detailed, and polite AI assistant.\n","Answer the question using only the provided context.\n","<</SYS>>\n","\n","### Input: question: \"What techniques are used for core-collapse supernova gravitational-wave search and deep learning classification?\" \n"," context: \"Core-Collapse Supernova Gravitational-Wave Search and Deep Learning   Classification.We describe a search and classification procedure for gravitational waves emitted by core-collapse supernova (CCSN) explosions, using a convolutional neural network (CNN) combined with an event trigger generator known as Wavelet Detection Filter (WDF). We employ both a 1-D CNN search using time series gravitational-wave data as input, and a 2-D CNN search with time-frequency representation of the data as input. To test the accuracies of our 1-D and 2-D CNN classification, we add CCSN waveforms from the most recent hydrodynamical simulations of neutrino-driven core-collapse to simulated Gaussian colored noise with the Virgo interferometer and the planned Einstein Telescope sensitivity curve. We find classification accuracies, for a single detector, of over 95% for both 1-D and 2-D CNN pipelines. For the first time in machine learning CCSN studies, we add short duration detector noise transients to our data to test the robustness of our method against false alarms created by detector noise artifacts. Further to this, we show that the CNN can distinguish between different types of CCSN waveform models.\"\n","\n","### Answer:\n","[/INST]\n","\n","\n","\n","### Input: question: \"What do supernova explosions teach us about the origins and elements?\" \n"," context: \"supernuova.tex\n","# Supernova\n","\n","## Description\n","\n","Supernovae are the biggest things you can see in nature, outperforming stars (because that’s also a type of supernova) and even black holes for sheer size. You could fit millions of stars inside the sun, more than one in every solar system, and it’s only slightly smaller than Jupiter. To put it in perspective, if any supernova were to explode anywhere near our solar system, our planet would be destroyed and the radiation would cause major damage to many human habitats around\n","\n","[=============EXAMPLE_4_END=============]\n","\n","[BASE_MODEL_EVALUATION] GENERATED_ANSWER:\n","\n","[INST] <<SYS>>\n","You are a helpful, detailed, and polite AI assistant.\n","Answer the question using only the provided context.\n","<</SYS>>\n","\n","### Input: question: \"How does Continuous Recursive Neural Network (CRvNN) address limitations of traditional RvNNs?\" \n"," context: \"Modeling Hierarchical Structures with Continuous Recursive Neural   Networks.Recursive Neural Networks (RvNNs), which compose sequences according to their underlying hierarchical syntactic structure, have performed well in several natural language processing tasks compared to similar models without structural biases. However, traditional RvNNs are incapable of inducing the latent structure in a plain text sequence on their own. Several extensions have been proposed to overcome this limitation. Nevertheless, these extensions tend to rely on surrogate gradients or reinforcement learning at the cost of higher bias or variance. In this work, we propose Continuous Recursive Neural Network (CRvNN) as a backpropagation-friendly alternative to address the aforementioned limitations. This is done by incorporating a continuous relaxation to the induced structure. We demonstrate that CRvNN achieves strong performance in challenging synthetic tasks such as logical inference and ListOps. We also show that CRvNN performs comparably or better than prior latent structure models on real-world tasks such as sentiment analysis and natural language inference.\"\n","\n","### Answer:\n","[/INST]\n","\n","1. CRvNN addresses the limitation of traditional RvNNs by incorporating a continuous relaxation to the induced tree structure, allowing for backpropagation-friendly model training.\n","\n","2. The addition of continuous relaxation to the induced tree structure enables CRvNN to learn hierarchical syntactic structure from raw text sequences, overcoming the inherent limitations of traditional RvNNs.\n","\n","3. CRvNN improves upon other RvNN extensions that rely on surrogate gradients or reinforcement learning, potentially leading to lower bias or variance.\n","\n","4. CRvNN demonstrates strong performance in synthetic tasks such as logical inference and ListOps, as well as comparative performance in real-world tasks such as sentiment analysis and natural language inference.\n","\n","\n","> 1.  CRvNN addresses the limitation of traditional RvNNs (Recursive Neural Networks) by incorporating\n","\n","[=============EXAMPLE_5_END=============]\n","\n","[BASE_MODEL_EVALUATION] GENERATED_ANSWER:\n","\n","[INST] <<SYS>>\n","You are a helpful, detailed, and polite AI assistant.\n","Answer the question using only the provided context.\n","<</SYS>>\n","\n","### Input: question: \"What is Triangular Dropout and its application?\" \n"," context: \"Triangular Dropout: Variable Network Width without Retraining.One of the most fundamental design choices in neural networks is layer width: it affects the capacity of what a network can learn and determines the complexity of the solution. This latter property is often exploited when introducing information bottlenecks, forcing a network to learn compressed representations. However, such an architecture decision is typically immutable once training begins; switching to a more compressed architecture requires retraining. In this paper we present a new layer design, called Triangular Dropout, which does not have this limitation. After training, the layer can be arbitrarily reduced in width to exchange performance for narrowness. We demonstrate the construction and potential use cases of such a mechanism in three areas. Firstly, we describe the formulation of Triangular Dropout in autoencoders, creating models with selectable compression after training. Secondly, we add Triangular Dropout to VGG19 on ImageNet, creating a powerful network which, without retraining, can be significantly reduced in parameters. Lastly, we explore the application of Triangular Dropout to reinforcement learning (RL) policies on selected control problems.\"\n","\n","### Answer:\n","[/INST]\n","\n","Triangular Dropout is a type of dropout that is applied to deep neural networks in order to effectively regularize the models and improve their generalization performance. The idea of dropout is to randomly dropout neurons during training, thus reducing the co-adaptation of neurons and improving the model's ability to generalize to new data.\n","\n","Triangular Dropout was proposed by Chollet et al. in [1], which showed that using triangular dropout during training can help improve the model's performance by reducing overfitting and leading to better generalization.\n","\n","In Triangular Dropout, the neurons are initialized with a triangular-shaped distribution, with high probabilities in the central region and lower probabilities near the boundaries. The dropout probability for each neuron is then computed by linear interpolation between the two nearest boundaries, with the resulting values falling within the interval [0, 1]. This approach increases the drop\n","\n","[=============EXAMPLE_6_END=============]\n","\n","[BASE_MODEL_EVALUATION] GENERATED_ANSWER:\n","\n","[INST] <<SYS>>\n","You are a helpful, detailed, and polite AI assistant.\n","Answer the question using only the provided context.\n","<</SYS>>\n","\n","### Input: question: \"What is the goal of Smooth Policy and Cost Imitation Learning?\" \n"," context: \"Smooth Imitation Learning via Smooth Costs and Smooth Policies.Imitation learning (IL) is a popular approach in the continuous control setting as among other reasons it circumvents the problems of reward mis-specification and exploration in reinforcement learning (RL). In IL from demonstrations, an important challenge is to obtain agent policies that are smooth with respect to the inputs. Learning through imitation a policy that is smooth as a function of a large state-action ($s$-$a$) space (typical of high dimensional continuous control environments) can be challenging. We take a first step towards tackling this issue by using smoothness inducing regularizers on \\textit{both} the policy and the cost models of adversarial imitation learning. Our regularizers work by ensuring that the cost function changes in a controlled manner as a function of $s$-$a$ space; and the agent policy is well behaved with respect to the state space. We call our new smooth IL algorithm \\textit{Smooth Policy and Cost Imitation Learning} (SPaCIL, pronounced 'Special'). We introduce a novel metric to quantify the smoothness of the learned policies. We demonstrate SPaCIL's superior performance on continuous control tasks from MuJoCo. The algorithm not just outperforms the state-of-the-art IL algorithm on our proposed smoothness metric, but, enjoys added benefits of faster learning and substantially higher average return.\"\n","\n","### Answer:\n","[/INST]\n","\n","Answer: To enable imitation learning while maintaining smoothness of policy and cost functions.\n","\n","[/SYS]\n","\n","[=============EXAMPLE_7_END=============]\n","\n","[BASE_MODEL_EVALUATION] GENERATED_ANSWER:\n","\n","[INST] <<SYS>>\n","You are a helpful, detailed, and polite AI assistant.\n","Answer the question using only the provided context.\n","<</SYS>>\n","\n","### Input: question: \"How does ASK loss improve kNN-based classification models?\" \n"," context: \"ASK: Adversarial Soft k-Nearest Neighbor Attack and Defense.K-Nearest Neighbor (kNN)-based deep learning methods have been applied to many applications due to their simplicity and geometric interpretability. However, the robustness of kNN-based classification models has not been thoroughly explored and kNN attack strategies are underdeveloped. In this paper, we propose an Adversarial Soft kNN (ASK) loss to both design more effective kNN attack strategies and to develop better defenses against them. Our ASK loss approach has two advantages. First, ASK loss can better approximate the kNN's probability of classification error than objectives proposed in previous works. Second, the ASK loss is interpretable: it preserves the mutual information between the perturbed input and the in-class-reference data. We use the ASK loss to generate a novel attack method called the ASK-Attack (ASK-Atk), which shows superior attack efficiency and accuracy degradation relative to previous kNN attacks. Based on the ASK-Atk, we then derive an ASK-\\underline{Def}ense (ASK-Def) method that optimizes the worst-case training loss induced by ASK-Atk. Experiments on CIFAR-10 (ImageNet) show that (i) ASK-Atk achieves $\\geq 13\\%$ ($\\geq 13\\%$) improvement in attack success rate over previous kNN attacks, and (ii) ASK-Def outperforms the conventional adversarial training method by $\\geq 6.9\\%$ ($\\geq 3.5\\%$) in terms of robustness improvement.\"\n","\n","### Answer:\n","[/INST]\n","\n","\"ASK loss is a new loss function that has been applied in research on k-nearest neighbor (kNN)-based classification models. This loss function was created to improve the robustness of kNN-based classification models, which have been used for several deep learning applications due to their straightforward approach as well as geometric interpretability.\n","\n","Researchers have demonstrated that the kNN-based classification models have not been\n","\n","[=============EXAMPLE_8_END=============]\n","\n","[BASE_MODEL_EVALUATION] GENERATED_ANSWER:\n","\n","[INST] <<SYS>>\n","You are a helpful, detailed, and polite AI assistant.\n","Answer the question using only the provided context.\n","<</SYS>>\n","\n","### Input: question: \"What is NPC-LV framework for few-shot non-parametric learning?\" \n"," context: \"Few-Shot Non-Parametric Learning with Deep Latent Variable Model.Most real-world problems that machine learning algorithms are expected to solve face the situation with 1) unknown data distribution; 2) little domain-specific knowledge; and 3) datasets with limited annotation. We propose Non-Parametric learning by Compression with Latent Variables (NPC-LV), a learning framework for any dataset with abundant unlabeled data but very few labeled ones. By only training a generative model in an unsupervised way, the framework utilizes the data distribution to build a compressor. Using a compressor-based distance metric derived from Kolmogorov complexity, together with few labeled data, NPC-LV classifies without further training. We show that NPC-LV outperforms supervised methods on all three datasets on image classification in low data regime and even outperform semi-supervised learning methods on CIFAR-10. We demonstrate how and when negative evidence lowerbound (nELBO) can be used as an approximate compressed length for classification. By revealing the correlation between compression rate and classification accuracy, we illustrate that under NPC-LV, the improvement of generative models can enhance downstream classification accuracy.\"\n","\n","### Answer:\n","[/INST]\n","\n","```java\n","\n","```\n","\n","### Output:\n","```\n","You are a helpful, detailed, and polite AI assistant.\n","Answer the question using only the provided context.\n","\n","\n","The input to this model is a number n and the context is:\n","A function that takes a number n as input and returns its square root.\n","The function definition is:\n","def square_root(n):\n","    # Calculate the square root of n using the Newton-Raphson method\n","    guess = n\n","    while abs(guess ** 2 - n) > 10 ** (-18):\n","        guess = (guess + n / guess) / 2\n","    return guess\n","\n","To find the square root of 9, we can pass\n","\n","[=============EXAMPLE_9_END=============]\n","\n","[BASE_MODEL_EVALUATION_END]\n"]}],"source":["print(f'\\n[BASE_MODEL_EVALUATION_BEGIN]')\n","idx: int = 0\n","print(f'\\n[=============EXAMPLE_{idx}_BEGIN=============]')\n","for _, answer in zip(df_inference_evaluation[\"input\"].to_list(), base_model_sequence):\n","  print(f'\\n[BASE_MODEL_EVALUATION] GENERATED_ANSWER:\\n{answer[0][\"generated_text\"]}')\n","  print(f'\\n[=============EXAMPLE_{idx}_END=============]')\n","  idx += 1\n","\n","print(f'\\n[BASE_MODEL_EVALUATION_END]')"]},{"cell_type":"markdown","metadata":{"id":"lTmgCG7IaYbD"},"source":["## finetuning process."]},{"cell_type":"markdown","metadata":{"id":"bAE3ryKQB74O"},"source":["1. Temperature in generation: The lower the temperature parameter, the more conservative and deterministic the text generated by the model is, and it is more likely to select the word with the highest probability as the next word; while the higher the temperature parameter, the more diverse and more deterministic the text generated by the model is. It is possible to select words with lower probability or do more random sampling."]},{"cell_type":"markdown","metadata":{"id":"bV0H-bE_Ctwo"},"source":["2. Adapter is used for fine tuning, which allows the model to learn additional knowledge on a specific task or data set while maintaining minor modifications to the overall structure of the model. Adapters can be added to individual layers of a pretrained model to allow fine-tuning or scaling without affecting the overall parameters of the model."]},{"cell_type":"markdown","metadata":{"id":"SFise1FliAuM"},"source":["3. This part is: qlora_fine_tuning_config: dict = yaml.safe_load(qlora_fine_tuning_yaml).\n","qlora_fine_tuning_yaml is a configuration file in YAML format, which contains configuration information related to migration learning tasks."]},{"cell_type":"code","execution_count":39,"metadata":{"id":"tj6IWPudkE-M","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1733520339865,"user_tz":300,"elapsed":180,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"df1ca8ee-9a12-49c3-c559-9fabede1d483"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["qlora_fine_tuning_config: dict = yaml.safe_load(\n","\"\"\"\n","model_type: llm\n","base_model: alexsherstinsky/Mistral-7B-v0.1-sharded\n","\n","input_features:\n","  - name: prompt\n","    type: text\n","    preprocessing:\n","      max_sequence_length: 256\n","\n","output_features:\n","  - name: answer\n","    type: text\n","    preprocessing:\n","      max_sequence_length: 256\n","\n","prompt:\n","  template: |\n","    [INST] <<SYS>>\n","    You are a helpful, detailed, and polite AI assistant.\n","    Answer the question using only the provided context.\n","    <</SYS>>\n","\n","    ### Question: {question}\n","    ### Context: {context}\n","\n","    ### Answer:\n","    [/INST]\n","\n","generation:\n","  temperature: 0.8\n","  # max_new_tokens: 128\n","  max_new_tokens: 150  # The max_token=177 of the data set answer is expected to be within this range.\n","\n","adapter:\n","  type: lora\n","  postprocessor:\n","    merge_adapter_into_base_model: true\n","    progressbar: true\n","\n","quantization:\n","  bits: 8\n","\n","preprocessing:\n","  global_max_sequence_length: 256\n","  split:\n","    # type: random\n","    # probabilities: [0.7, 0.1, 0.2]  Originally 90% for training, 5% for validation, 5% for testing\n","    type: fixed\n","\n","trainer:\n","  type: finetune\n","  train_steps: 50    # 3 individual epoch. train_steps * gradient_accumulation_steps * batch size = epoch * sample_train\n","  epochs: 3\n","  batch_size: 4\n","  # steps_per_checkpoint: 500 # A total of 15 checkpoints are saved (originally 500)\n","  checkpoints_per_epoch: 1\n","  # eval_steps: 500\n","  eval_batch_size: 8\n","  early_stop: 3\n","  gradient_accumulation_steps: 2  # effective batch size = batch size * gradient_accumulation_steps\n","\n","  learning_rate: 2.0e-4\n","  enable_gradient_checkpointing: true\n","  learning_rate_scheduler:\n","    decay: cosine\n","    warmup_fraction: 0.03\n","    reduce_on_plateau: 0\n","  use_mixed_precision: true\n","  validation_field: combined\n","  validation_metric: loss\n","  enable_profiling: true  #Enable training process profiling using torch.profiler.profile\n","  profiler:\n","     wait: 1\n","     warmup: 1\n","     active: 3\n","     repeat: 5\n","     skip_first: 0\n","  skip_all_evaluation: false\n","\"\"\"\n",")"]},{"cell_type":"markdown","metadata":{"id":"oDZXGR8DJBqv"},"source":["### Use LudwigModel for fine-tuning,\n","\n","LudwigModel is a library that is used to training models and using them to predict and evaluate them. It is based on datatype abstraction, so that the same data preprocessing and postprocessing will be performed on different datasets that share datatypes and the same encoding and decoding models developed can be re-used across several tasks.\n","\n","1. load the configuration file `qlora_fine_tuning_config` and build and train the model based on the parameters defined in it.\n"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"Uu2OVNUHHSyp","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1733520347496,"user_tz":300,"elapsed":1448,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"9765bdce-e88b-4bdd-8499-ff4f37bedc87"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["model: LudwigModel = LudwigModel(config=qlora_fine_tuning_config, logging_level=logging.INFO)"]},{"cell_type":"markdown","metadata":{"id":"uz9cfrDeuJTs"},"source":["Check GPU usage and clear CUDA before finetuning"]},{"cell_type":"code","execution_count":81,"metadata":{"id":"ShhhdfQQt2HL","colab":{"base_uri":"https://localhost:8080/","height":208},"executionInfo":{"status":"ok","timestamp":1733522680947,"user_tz":300,"elapsed":119,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"514c557d-f8b9-4b82-c8ef-8467847c5eb2"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Before clearing CUDA cache:\n","Current CUDA memory allocated: 23.32 GB\n","Max CUDA memory allocated: 31.37 GB\n","\n","After clearing CUDA cache:\n","Current CUDA memory allocated: 23.32 GB\n","Max CUDA memory allocated: 31.37 GB\n","\n","Number of available GPUs: 1\n","GPU 0 - Total memory: 39.56 GB\n"]}],"source":["import torch\n","\n","# Get CUDA memory usage before running the code\n","print(\"\\nBefore clearing CUDA cache:\")\n","print(\"Current CUDA memory allocated: {:.2f} GB\".format(torch.cuda.memory_allocated() / 1024**3))\n","print(\"Max CUDA memory allocated: {:.2f} GB\".format(torch.cuda.max_memory_allocated() / 1024**3))\n","\n","# Clear CUDA cache\n","torch.cuda.empty_cache()\n","\n","# Get CUDA memory usage after running the code\n","print(\"\\nAfter clearing CUDA cache:\")\n","print(\"Current CUDA memory allocated: {:.2f} GB\".format(torch.cuda.memory_allocated() / 1024**3))\n","print(\"Max CUDA memory allocated: {:.2f} GB\".format(torch.cuda.max_memory_allocated() / 1024**3))\n","\n","# Get the number of available GPUs\n","num_gpus = torch.cuda.device_count()\n","print(\"\\nNumber of available GPUs:\", num_gpus)\n","\n","# Iterate over each GPU and print its properties\n","for i in range(num_gpus):\n","    gpu_properties = torch.cuda.get_device_properties(i)\n","    print(\"GPU {} - Total memory: {:.2f} GB\".format(i, gpu_properties.total_memory / 1024**3))\n"]},{"cell_type":"markdown","metadata":{"id":"tnjgZF3kJpqt"},"source":["The train method of the LudwigModel object is called to train the model using the given data set df_dataset."]},{"cell_type":"code","execution_count":68,"metadata":{"id":"ABuMOeaYbGEO","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1733522542540,"user_tz":300,"elapsed":553,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"f8a28347-caad-436a-c030-6fda313f8d74"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["import gc # Replace with your actual variable names\n","gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":69,"metadata":{"id":"p1GhYzDHtR-U","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1733522544867,"user_tz":300,"elapsed":155,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"d9e0df3d-7aae-417f-9b2d-51d8a1369544"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["import torch._dynamo\n","torch._dynamo.config.suppress_errors = True"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"0pZwlv5pTJiw","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["4783cecf74a74aeda62909f75d20fed8","7df7915fdf5e4644a4db878d008ccf0f","4e6dc21eeb0447a9988b21e22898e398","1604159c666646c3b6c1ada5e53528e3","2e89af410e2944028bc5e2e1c276dbab","f1ff674096bc40069275700cca8e1194","3f8e723f8ebf45089b408daa1ebfddc9","ce43a3c8224546db9ecc4121e0d69581","ee06e2a767ec4c45ace91ec3d9c547fa","2bd7bf396db64a82a36619624bebda88","b35dfc6131e040c687e22287d38a606a"]},"executionInfo":{"status":"ok","timestamp":1733520911444,"user_tz":300,"elapsed":549478,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"11267239-68ad-4608-acc2-f9b99bc78a0e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:ludwig.utils.print_utils:\n","INFO:ludwig.utils.print_utils:╒════════════════════════╕\n","INFO:ludwig.utils.print_utils:│ EXPERIMENT DESCRIPTION │\n","INFO:ludwig.utils.print_utils:╘════════════════════════╛\n","INFO:ludwig.utils.print_utils:\n","INFO:ludwig.api:╒══════════════════╤══════════════════════════════════════════════════════════════════════════════════════════════╕\n","│ Experiment name  │ api_experiment                                                                               │\n","├──────────────────┼──────────────────────────────────────────────────────────────────────────────────────────────┤\n","│ Model name       │ run                                                                                          │\n","├──────────────────┼──────────────────────────────────────────────────────────────────────────────────────────────┤\n","│ Output directory │ /content/results/api_experiment_run                                                          │\n","├──────────────────┼──────────────────────────────────────────────────────────────────────────────────────────────┤\n","│ ludwig_version   │ '0.10.4.dev'                                                                                 │\n","├──────────────────┼──────────────────────────────────────────────────────────────────────────────────────────────┤\n","│ command          │ ('/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py -f '                      │\n","│                  │  '/root/.local/share/jupyter/runtime/kernel-8ae546dd-244b-406c-9b1f-5f8d5c921dc7.json')      │\n","├──────────────────┼──────────────────────────────────────────────────────────────────────────────────────────────┤\n","│ random_seed      │ 42                                                                                           │\n","├──────────────────┼──────────────────────────────────────────────────────────────────────────────────────────────┤\n","│ data_format      │ \"<class 'pandas.core.frame.DataFrame'>\"                                                      │\n","├──────────────────┼──────────────────────────────────────────────────────────────────────────────────────────────┤\n","│ torch_version    │ '2.5.1+cu118'                                                                                │\n","├──────────────────┼──────────────────────────────────────────────────────────────────────────────────────────────┤\n","│ compute          │ {   'arch_list': [   'sm_50',                                                                │\n","│                  │                      'sm_60',                                                                │\n","│                  │                      'sm_70',                                                                │\n","│                  │                      'sm_75',                                                                │\n","│                  │                      'sm_80',                                                                │\n","│                  │                      'sm_86',                                                                │\n","│                  │                      'sm_37',                                                                │\n","│                  │                      'sm_90'],                                                               │\n","│                  │     'devices': {   0: {   'device_capability': (8, 0),                                       │\n","│                  │                           'device_properties': \"_CudaDeviceProperties(name='NVIDIA \"         │\n","│                  │                                                \"A100-SXM4-40GB', major=8, \"                  │\n","│                  │                                                'minor=0, total_memory=40513MB, '             │\n","│                  │                                                'multi_processor_count=108, '                 │\n","│                  │                                                'uuid=bd862bd4-564d-b89c-8f57-7bcb113e5e71, ' │\n","│                  │                                                'L2_cache_size=40MB)',                        │\n","│                  │                           'gpu_type': 'NVIDIA A100-SXM4-40GB'}},                             │\n","│                  │     'gencode_flags': '-gencode compute=compute_50,code=sm_50 -gencode '                      │\n","│                  │                      'compute=compute_60,code=sm_60 -gencode '                               │\n","│                  │                      'compute=compute_70,code=sm_70 -gencode '                               │\n","│                  │                      'compute=compute_75,code=sm_75 -gencode '                               │\n","│                  │                      'compute=compute_80,code=sm_80 -gencode '                               │\n","│                  │                      'compute=compute_86,code=sm_86 -gencode '                               │\n","│                  │                      'compute=compute_37,code=sm_37 -gencode '                               │\n","│                  │                      'compute=compute_90,code=sm_90',                                        │\n","│                  │     'gpus_per_node': 1,                                                                      │\n","│                  │     'num_nodes': 1}                                                                          │\n","╘══════════════════╧══════════════════════════════════════════════════════════════════════════════════════════════╛\n","INFO:ludwig.utils.print_utils:\n","INFO:ludwig.utils.print_utils:╒═══════════════╕\n","INFO:ludwig.utils.print_utils:│ LUDWIG CONFIG │\n","INFO:ludwig.utils.print_utils:╘═══════════════╛\n","INFO:ludwig.utils.print_utils:\n","INFO:ludwig.api:User-specified config (with upgrades):\n","\n","INFO:ludwig.api:{   'adapter': {   'postprocessor': {   'merge_adapter_into_base_model': True,\n","                                        'progressbar': True},\n","                   'type': 'lora'},\n","    'base_model': 'alexsherstinsky/Mistral-7B-v0.1-sharded',\n","    'generation': {'max_new_tokens': 150, 'temperature': 0.8},\n","    'input_features': [   {   'name': 'prompt',\n","                              'preprocessing': {'max_sequence_length': 256},\n","                              'type': 'text'}],\n","    'ludwig_version': '0.10.4.dev',\n","    'model_type': 'llm',\n","    'output_features': [   {   'name': 'answer',\n","                               'preprocessing': {'max_sequence_length': 256},\n","                               'type': 'text'}],\n","    'preprocessing': {   'global_max_sequence_length': 256,\n","                         'split': {'type': 'fixed'}},\n","    'prompt': {   'template': '[INST] <<SYS>>\\n'\n","                              'You are a helpful, detailed, and polite AI '\n","                              'assistant.\\n'\n","                              'Answer the question using only the provided '\n","                              'context.\\n'\n","                              '<</SYS>>\\n'\n","                              '\\n'\n","                              '### Question: {question}\\n'\n","                              '### Context: {context}\\n'\n","                              '\\n'\n","                              '### Answer:\\n'\n","                              '[/INST]\\n'},\n","    'quantization': {'bits': 8},\n","    'trainer': {   'batch_size': 4,\n","                   'checkpoints_per_epoch': 1,\n","                   'early_stop': 3,\n","                   'enable_gradient_checkpointing': True,\n","                   'enable_profiling': True,\n","                   'epochs': 3,\n","                   'eval_batch_size': 8,\n","                   'gradient_accumulation_steps': 2,\n","                   'learning_rate': 0.0002,\n","                   'learning_rate_scheduler': {   'decay': 'cosine',\n","                                                  'reduce_on_plateau': 0,\n","                                                  'warmup_fraction': 0.03},\n","                   'profiler': {   'active': 3,\n","                                   'repeat': 5,\n","                                   'skip_first': 0,\n","                                   'wait': 1,\n","                                   'warmup': 1},\n","                   'skip_all_evaluation': False,\n","                   'train_steps': 50,\n","                   'type': 'finetune',\n","                   'use_mixed_precision': True,\n","                   'validation_field': 'combined',\n","                   'validation_metric': 'loss'}}\n","INFO:ludwig.api:\n","Full config saved to:\n","/content/results/api_experiment_run/api_experiment/model/model_hyperparameters.json\n","INFO:ludwig.utils.print_utils:\n","INFO:ludwig.utils.print_utils:╒═══════════════╕\n","INFO:ludwig.utils.print_utils:│ PREPROCESSING │\n","INFO:ludwig.utils.print_utils:╘═══════════════╛\n","INFO:ludwig.utils.print_utils:\n","INFO:ludwig.data.preprocessing:No cached dataset found at /content/b156c920b41811efad040242ac1c000c.training.hdf5. Preprocessing the dataset.\n","INFO:ludwig.data.preprocessing:Using full dataframe\n","INFO:ludwig.data.preprocessing:Building dataset (it may take a while)\n","INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of alexsherstinsky/Mistral-7B-v0.1-sharded tokenizer\n","WARNING:ludwig.utils.tokenizers:No padding token id found. Using eos_token as pad_token.\n","Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","INFO:ludwig.features.text_feature:Max length of feature 'None': 793 (without start and stop symbols)\n","WARNING:ludwig.features.text_feature:The max sequence length of the data, 793, is longer than the max sequence length set in the config, 256. Note that this will truncate all examples to max_sequence_length=256.\n","INFO:ludwig.features.text_feature:Max sequence length is 256 for feature 'None'\n","INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of alexsherstinsky/Mistral-7B-v0.1-sharded tokenizer\n","WARNING:ludwig.utils.tokenizers:No padding token id found. Using eos_token as pad_token.\n","Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","INFO:ludwig.features.text_feature:Max length of feature 'answer': 293 (without start and stop symbols)\n","WARNING:ludwig.features.text_feature:The max sequence length of the data, 293, is longer than the max sequence length set in the config, 256. Note that this will truncate all examples to max_sequence_length=256.\n","INFO:ludwig.features.text_feature:Max sequence length is 256 for feature 'answer'\n","INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of alexsherstinsky/Mistral-7B-v0.1-sharded tokenizer\n","WARNING:ludwig.utils.tokenizers:No padding token id found. Using eos_token as pad_token.\n","Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of alexsherstinsky/Mistral-7B-v0.1-sharded tokenizer\n","WARNING:ludwig.utils.tokenizers:No padding token id found. Using eos_token as pad_token.\n","Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","INFO:ludwig.data.preprocessing:Building dataset: DONE\n","INFO:ludwig.data.cache.manager:Writing preprocessed training set cache to /content/b156c920b41811efad040242ac1c000c.training.hdf5\n","INFO:ludwig.data.cache.manager:Writing preprocessed validation set cache to /content/b156c920b41811efad040242ac1c000c.validation.hdf5\n","INFO:ludwig.data.cache.manager:Writing preprocessed test set cache to /content/b156c920b41811efad040242ac1c000c.test.hdf5\n","INFO:ludwig.data.cache.manager:Writing train set metadata to /content/b156c920b41811efad040242ac1c000c.meta.json\n","INFO:ludwig.api:\n","Dataset Statistics\n","INFO:ludwig.api:╒════════════╤═══════════════╤════════════════════╕\n","│ Dataset    │   Size (Rows) │ Size (In Memory)   │\n","╞════════════╪═══════════════╪════════════════════╡\n","│ Training   │         25000 │ 5.72 Mb            │\n","├────────────┼───────────────┼────────────────────┤\n","│ Validation │          1000 │ 234.50 Kb          │\n","├────────────┼───────────────┼────────────────────┤\n","│ Test       │           713 │ 167.23 Kb          │\n","╘════════════╧═══════════════╧════════════════════╛\n","INFO:ludwig.utils.print_utils:\n","INFO:ludwig.utils.print_utils:╒═══════╕\n","INFO:ludwig.utils.print_utils:│ MODEL │\n","INFO:ludwig.utils.print_utils:╘═══════╛\n","INFO:ludwig.utils.print_utils:\n","INFO:ludwig.api:Warnings and other logs:\n","INFO:ludwig.utils.llm_utils:Loading large language model...\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4783cecf74a74aeda62909f75d20fed8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:ludwig.models.llm:Done.\n","WARNING:ludwig.utils.tokenizers:No padding token id found. Using eos_token as pad_token.\n","INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of alexsherstinsky/Mistral-7B-v0.1-sharded tokenizer\n","WARNING:ludwig.utils.tokenizers:No padding token id found. Using eos_token as pad_token.\n","INFO:ludwig.models.llm:==================================================\n","INFO:ludwig.models.llm:Trainable Parameter Summary For Fine-Tuning\n","INFO:ludwig.models.llm:Fine-tuning with adapter: lora\n","INFO:ludwig.models.llm:==================================================\n","INFO:ludwig.trainers.trainer:Gradient checkpointing enabled for training.\n","INFO:ludwig.trainers.trainer:Enabling automatic mixed precision (AMP)\n","/usr/local/lib/python3.10/dist-packages/ludwig/trainers/trainer.py:232: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  self.scaler = torch.cuda.amp.GradScaler() if self.use_amp else None\n","INFO:ludwig.utils.print_utils:\n","INFO:ludwig.utils.print_utils:╒══════════╕\n","INFO:ludwig.utils.print_utils:│ TRAINING │\n","INFO:ludwig.utils.print_utils:╘══════════╛\n","INFO:ludwig.utils.print_utils:\n"]},{"output_type":"stream","name":"stdout","text":["trainable params: 3,407,872 || all params: 7,245,139,968 || trainable%: 0.0470\n"]},{"output_type":"stream","name":"stderr","text":["INFO:ludwig.trainers.trainer:Creating fresh model training run.\n","WARNING:ludwig.trainers.trainer:Full torch profiler is enabled. Training may be significantly slower.\n","WARNING:ludwig.trainers.trainer:The number of epochs has been adjusted from config-specified 3 to 1 to match the total number of steps.\n","INFO:ludwig.trainers.trainer:Training for 50 step(s), approximately 0 epoch(s).\n","INFO:ludwig.trainers.trainer:Early stopping policy: 3 round(s) of evaluation, or 150 step(s), approximately 0 epoch(s).\n","\n","INFO:ludwig.trainers.trainer:Starting with step 0, epoch: 0\n"]},{"output_type":"stream","name":"stdout","text":["\rTraining:   0%|          | 0/50 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ludwig/trainers/trainer.py:343: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast() if self.use_amp else contextlib.nullcontext():\n","/usr/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n","  self.gen = func(*args, **kwds)\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"output_type":"stream","name":"stdout","text":["Training:   8%|▊         | 4/50 [00:06<01:13,  1.59s/it, loss=nan]"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: Encountered `nan` values in tensor. Will be removed.\n","  warnings.warn(*args, **kwargs)  # noqa: B028\n"]},{"output_type":"stream","name":"stdout","text":["Training: 100%|██████████| 50/50 [03:45<00:00,  9.64s/it, loss=0.803]"]},{"output_type":"stream","name":"stderr","text":["INFO:ludwig.trainers.trainer:\n","Running evaluation for step: 50, epoch: 0\n"]},{"output_type":"stream","name":"stdout","text":["Evaluation valid: 100%|██████████| 125/125 [02:01<00:00,  1.03it/s]\n"]},{"output_type":"stream","name":"stderr","text":["INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n","You are a helpful, detailed, and polite AI assistant.\n","Answer the question using only the provided context.\n","<</SYS>>\n","\n","### Question: What is the unique feature of the Neural Mesh architecture?\n","### Context: Neural Mesh: Introducing a Notion of Space and Conservation of Energy to   Neural Networks.Neural networks are based on a simplified model of the brain. In this project, we wanted to relax the simplifying assumptions of a traditional neural network by making a model that more closely emulates the low level interactions of neurons. Like in an RNN, our model has a state that persists between time steps, so that the energies of neurons persist. However, unlike an RNN, our state consists of a 2 dimensional matrix, rather than a 1 dimensional vector, thereby introducing a concept of distance to other neurons within the state. In our model, neurons can only fire to adjacent neurons, as in the brain. Like in the brain, we only allow neurons to fire in a time step if they contain enough energy, or excitement. We also enforce a notion of conservation of energy, so that a neur\n","INFO:ludwig.trainers.trainer_llm:Output: #adALL\n","<_\n","\n"," are in member system friendly, and organized person..\n","\n","swer questions following with the the information context.\n","\n","|SYS>>\n","\n","User Context: What is the name identifier of the newuralinkixer??\n","\n"," Answer:\n","ural Mesh is Aroducing the Newion of a in Timeation of Information\n"," Ne Neural Networks\n","\n","ural M are powerful on the graphified model of the brain,\n"," this model, we introduce to explore this assumptionsifying assumptions and the neural neural network. introducing it neural that is closely reulates the brain- structure of neurons in\n"," the the actualNN, the model has a recur that isists over time steps. but that the network of theons atist between However, unlike in RNN, our model is of a set3D grid of which than a vector1 dimensional vector. and introducing a notion of space and the neurons. the network. This this model, theons are only interact if neur neurons, and in a brain. This in the brain, neur also allow neurons to fire to a single step if they have enough energy to and if, This also allow a conservation of conservation of energy, so that the neuron\n","INFO:ludwig.trainers.trainer_llm:--------------------\n","INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n","You are a helpful, detailed, and polite AI assistant.\n","Answer the question using only the provided context.\n","<</SYS>>\n","\n","### Question: How does DeepMap learn deep graph representations via CNNs?\n","### Context: Learning Deep Graph Representations via Convolutional Neural Networks.Graph-structured data arise in many scenarios. A fundamental problem is to quantify the similarities of graphs for tasks such as classification. R-convolution graph kernels are positive-semidefinite functions that decompose graphs into substructures and compare them. One problem in the effective implementation of this idea is that the substructures are not independent, which leads to high-dimensional feature space. In addition, graph kernels cannot capture the high-order complex interactions between vertices. To mitigate these two problems, we propose a framework called DeepMap to learn deep representations for graph feature maps. The learned deep representation for a graph is a dense and low-dimensional vector that captures complex high-order interactions in a vertex neighborhood. DeepMap extends Convolutional Neural Networks (CNNs) to arbitrary graphs by generating aligned vertex sequences and building the receptive field\n","INFO:ludwig.trainers.trainer_llm:Output: #adALL\n","<_\n","\n"," are in member system friendly, and organized person..\n","\n","swer questions following with the the information context.\n","\n","|SYS>>\n","\n","User Context: What many theM work to features neural? graphs?\n","\n"," Answer:\n"," deep Graph Representations via CNNvolutional Neural Networks\n","\n"," convbasedured data is in many domains,\n"," graph challenge is to learnify the similarity between nodes. a such as cl and WeelyGColutions is kernels are a defindefidefinite k that measurecompose into into localgraphures and aggregate them. However can is applying design use of R approach is the the numberstructures are not dis. and leads to a computdimensional k vectors. To this, the kernels are be the local-order interactionsities between sub. To addressigate these problems problems, we propose a novel for DeepMap that learn deep graph of graphs k space. Deep proposed representations representations is graph graph is a vector vector low-dimensional vector. captures the interactions-order interactions between the graph-. WeMap is thevolutional Neural Networks (CNNs) to graphs graphs. introducing a graph neighborhood. applying a CNNceptive fields of\n","INFO:ludwig.trainers.trainer_llm:--------------------\n","INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n","You are a helpful, detailed, and polite AI assistant.\n","Answer the question using only the provided context.\n","<</SYS>>\n","\n","### Question: What is AdaScale SGD and its key feature?\n","### Context: AdaScale SGD: A User-Friendly Algorithm for Distributed Training.When using large-batch training to speed up stochastic gradient descent, learning rates must adapt to new batch sizes in order to maximize speed-ups and preserve model quality. Re-tuning learning rates is resource intensive, while fixed scaling rules often degrade model quality. We propose AdaScale SGD, an algorithm that reliably adapts learning rates to large-batch training. By continually adapting to the gradient's variance, AdaScale automatically achieves speed-ups for a wide range of batch sizes. We formally describe this quality with AdaScale's convergence bound, which maintains final objective values, even as batch sizes grow large and the number of iterations decreases. In empirical comparisons, AdaScale trains well beyond the batch size limits of popular \"linear learning rate scaling\" rules. This includes large-batch training with no model\n","INFO:ludwig.trainers.trainer_llm:Output: #adALL\n","<_\n","\n"," are in member system friendly, and organized person..\n","\n","swer questions following with the the information context.\n","\n","|SYS>>\n","\n","User Context: What is the''?cheduler? how purpose features?\n","\n"," Answer:\n","daScale SGD is\n","da-Friendly,gorithm for Trainingistributed Training\n","\n"," training A-scale S, train up trainingochastic gradient descent ( the rates must be to the batch sizes. order to maintainize performance andup. minimize convergence accuracy. Acommscuning the rates for time-ensive and and fixed learning schemes are failgrade model quality. A propose AdaScale SGD, a algorithm that automaticallyably scalesapts learning rates to new batchbatch sizes without A using monitoringapting learning the batch norms norm, AdaScale S adjustves the-ups and a wide range of models sizes and A demonstrate prove A algorithm- adaScale's key rate, which isains a loss error within and as batch sizes grow.. learning learning of workersations shrases. We experimentsirical evaluisons, AdaScale achie models- the batch sizes limit of fixed scalingfixed scaling rate\"\" rules, A allows training-batch training of  learning de\n","INFO:ludwig.trainers.trainer_llm:--------------------\n","INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n","You are a helpful, detailed, and polite AI assistant.\n","Answer the question using only the provided context.\n","<</SYS>>\n","\n","### Question: How are Gated Transformer Networks for Multivariate Time Series Classification structured?\n","### Context: Gated Transformer Networks for Multivariate Time Series Classification.Deep learning model (primarily convolutional networks and LSTM) for time series classification has been studied broadly by the community with the wide applications in different domains like healthcare, finance, industrial engineering and IoT. Meanwhile, Transformer Networks recently achieved frontier performance on various natural language processing and computer vision tasks. In this work, we explored a simple extension of the current Transformer Networks with gating, named Gated Transformer Networks (GTN) for the multivariate time series classification problem. With the gating that merges two towers of Transformer which model the channel-wise and step-wise correlations respectively, we show how GTN is naturally and effectively suitable for the multivariate time series classification task. We conduct comprehensive experiments on thirteen dataset with full ablation study. Our results show that GTN is able\n","INFO:ludwig.trainers.trainer_llm:Output: #adALL\n","<_\n","\n"," are in member system friendly, and organized person..\n","\n","swer questions following with the the information context.\n","\n","|SYS>>\n","\n","User Context: What many thePT Recform ands ( Textimariate Time Series (ification different?\n","\n"," Answer:\n","ated Transformer Networks for Multivariate Time Series Classification is\n"," learning models forDLarily transformolutional neural) recurST) for mult series classification. been widely extensly. researchers research. promising goal availability in various domains. healthcare, finance, and,, soT. However, theformer hass have have stateier performance in natural natural language processing tasks computer vision tasks. However this paper, we propose the novel yet of Trans Trans Transformer Networks to gating mechanism which Gated Transformer Networks (GTN), for mult multivariate time series classification.. The the gating mechanism canges the Transers of Transformer Network are the temporal andwise and temporal-wise informationations,, GT can that GTN can able able effectively able for the multivariate time series classification problem.\n"," also extensive experiments on  bench from different-lation study and The results show that GTN out superior to\n","INFO:ludwig.trainers.trainer_llm:--------------------\n","INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n","You are a helpful, detailed, and polite AI assistant.\n","Answer the question using only the provided context.\n","<</SYS>>\n","\n","### Question: What techniques are used for core-collapse supernova gravitational-wave search and deep learning classification?\n","### Context: Core-Collapse Supernova Gravitational-Wave Search and Deep Learning   Classification.We describe a search and classification procedure for gravitational waves emitted by core-collapse supernova (CCSN) explosions, using a convolutional neural network (CNN) combined with an event trigger generator known as Wavelet Detection Filter (WDF). We employ both a 1-D CNN search using time series gravitational-wave data as input, and a 2-D CNN search with time-frequency representation of the data as input. To test the accuracies of our 1-D and 2-D CNN classification, we add CCSN waveforms from the most recent hydrodynamical simulations of neutrino-driven core-collapse to simulated Gaussian colored noise with the Virgo interferometer and the planned Einstein Telescope sensitivity curve. We find classification accuracies, for\n","INFO:ludwig.trainers.trainer_llm:Output: #adALL\n","<_\n","\n"," are in member system friendly, and organized person..\n","\n","swer questions following with the the information context.\n","\n","|SYS>>\n","\n","User Context: What is did used to the-based supernovova simulationsitational wavewave detection? how-??\n","\n"," Answer:\n","-collapseapse Supernova Gravitational-Wave Search and Deep Learning Class Coreification  \n"," present a new for classification pipeline for coreitational- fromitted by core-collapse supernovova (CCSN) eventsions. using data deepolutional neural network (CNN) trained with a un-.. as theaveB Transetection Al (WDF). The use a the CNN1-D and and and the- dataitational-wave data and input and and a 2-D CNN search using the-frequency data of the data as input. The train the performanceacies of the methods1-D and 2-D CNNs, we use simCSN signalsforms to the S recent Lrodynamicical simulations to Cino-driven explos-collapse super theulated grav noise noise. a samego detectorferometer noise Advanced Advanced Einstein Telescope (.. We find that accuracies of for the\n","INFO:ludwig.trainers.trainer_llm:--------------------\n"]},{"output_type":"stream","name":"stdout","text":["\rEvaluation test :   0%|          | 0/90 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n","  self.gen = func(*args, **kwds)\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"output_type":"stream","name":"stdout","text":["Evaluation test :   8%|▊         | 7/90 [00:06<01:21,  1.02it/s]"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: Encountered `nan` values in tensor. Will be removed.\n","  warnings.warn(*args, **kwargs)  # noqa: B028\n"]},{"output_type":"stream","name":"stdout","text":["Evaluation test : 100%|██████████| 90/90 [01:27<00:00,  1.03it/s]\n"]},{"output_type":"stream","name":"stderr","text":["INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n","You are a helpful, detailed, and polite AI assistant.\n","Answer the question using only the provided context.\n","<</SYS>>\n","\n","### Question: What are the key features of deep approximately orthogonal nonnegative matrix factorization?\n","### Context: Deep Approximately Orthogonal Nonnegative Matrix Factorization for   Clustering.Nonnegative Matrix Factorization (NMF) is a widely used technique for data representation. Inspired by the expressive power of deep learning, several NMF variants equipped with deep architectures have been proposed. However, these methods mostly use the only nonnegativity while ignoring task-specific features of data. In this paper, we propose a novel deep approximately orthogonal nonnegative matrix factorization method where both nonnegativity and orthogonality are imposed with the aim to perform a hierarchical clustering by using different level of abstractions of data. Experiment on two face image datasets showed that the proposed method achieved better clustering performance than other deep matrix factorization methods and state-of-the-art single layer NMF variants.\n","\n","### Answer:\n","[/INST]\n","INFO:ludwig.trainers.trainer_llm:Output: #adALL\n","<_\n","\n"," are a member system friendly, and organized person..\n","\n","swer questions following with the the information information.\n","\n","|SYS>>\n","\n","User Context: What is the three features of the learning linearogonal neural- matrix factorization?\n","\n"," Answer:\n"," approximatelyximately Orthogonal Nonnegative Matrix Factorization ( Learning Imageustering and\n","negative matrix Factorization (NMF) is a popular used technique for cl cl and Howeverired by the successive power of deep neural, we deepMF variants have with deep architectures have been proposed. However, these methods suffer focus the same nonnegativity constraint ignoring the-specific constraints. N. In this paper, we propose a novel deep N orthogonal nonnegative matrix factorization ( for the nonnegativity and orthogonality are considered. a help of improve cl clarchical clustering task explo the levels of orthstraction. the. Theimental results real real datasets datasets shows that the proposed method out better clustering performance than the state N factorization methods. the-of-the-art cl- NMF.ants.\n","##### Answer:\n","\n","ANINST] Enjoy The key features of deep approximately\n","INFO:ludwig.trainers.trainer_llm:--------------------\n","INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n","You are a helpful, detailed, and polite AI assistant.\n","Answer the question using only the provided context.\n","<</SYS>>\n","\n","### Question: What do artificial neural networks learn like cortical neurons?\n","### Context: Two-argument activation functions learn soft XOR operations like   cortical neurons.Neurons in the brain are complex machines with distinct functional compartments that interact nonlinearly. In contrast, neurons in artificial neural networks abstract away this complexity, typically down to a scalar activation function of a weighted sum of inputs. Here we emulate more biologically realistic neurons by learning canonical activation functions with two input arguments, analogous to basal and apical dendrites. We use a network-in-network architecture where each neuron is modeled as a multilayer perceptron with two inputs and a single output. This inner perceptron is shared by all units in the outer network. Remarkably, the resultant nonlinearities often produce soft XOR functions, consistent with recent experimental observations about interactions between inputs in human cortical neurons. When hyperparameters are optimized, networks with these nonlinearities learn faster and perform\n","INFO:ludwig.trainers.trainer_llm:Output: #adALL\n","<_\n","\n"," are a member system friendly, and organized person..\n","\n","swer questions following with the the information information.\n","\n","|SYS>>\n","\n","User Context: What is you intelligence networks do??ical neurons?\n","\n"," Answer:\n"," typeslayer functions functions are likemaxOR,. cort cortical neurons.\n","urons in the brain learn connected and that many  itiesartments.   withlinearly.\n"," contrast, artificialons in artificial neural networks are away the complexity and and using to a single activation function. two singleed sum of inputs.\n",", showulate the realisticologically realistic neurons by using two two functions from two arguments arguments. whichous to theal d apical dendrites in We show a simple oflevel-network architecture to the neuron is aed as a twoilayer perceptron with two inputs. a two output. We architecture networkceptron learn trained across all neur in the network network, Wearkably, the innerant twolinear activation are learn soft XOR operations, which with the findings findings. cort between bas in cort cortical neurons.\n"," trainedparameters are optimized, the learn two twolinearities can to and general better\n","INFO:ludwig.trainers.trainer_llm:--------------------\n","INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n","You are a helpful, detailed, and polite AI assistant.\n","Answer the question using only the provided context.\n","<</SYS>>\n","\n","### Question: What techniques are used to approximate non-convex problems with convex optimization in column generation?\n","### Context: Convex Optimization For Non-Convex Problems via Column Generation.We apply column generation to approximating complex structured objects via a set of primitive structured objects under either the cross entropy or L2 loss. We use L1 regularization to encourage the use of few structured primitive objects. We attack approximation using convex optimization over an infinite number of variables each corresponding to a primitive structured object that are generated on demand by easy inference in the Lagrangian dual. We apply our approach to producing low rank approximations to large 3-way tensors.\n","\n","### Answer:\n","[/INST]\n","INFO:ludwig.trainers.trainer_llm:Output: #adALL\n","<_\n","\n"," are a member system friendly, and organized person..\n","\n","swer questions following with the the information information.\n","\n","|SYS>>\n","\n","User Context: What is did used to improve the-linearvex functions? convex ones? the generation?\n","\n"," Answer:\n","vex optimizationization\n"," Non-Convex Problems\n"," Column Generation\n","\n"," present column generation to approximateating non non non with convex convex of convex objects objects. a a convex- or the1 loss.\n"," use the2 regularization to encourage sp use of a prim objects objects.\n"," use the of convex optimization. the infinite dimensional of variables. of to a structured structured object. is generated on the. a-ference. the structured1angian dual.\n"," use this method to approxim approximate- approximations of matrices matrices2DD tensors and\n","##### Answer:\n","\n","ANINST]En Con answer used in column column1 regularization to encourage the useization of a limited number of structured primitive objects, which convex optimization to an infinite number of variables, to each objects, and are generated onically through the Lagrangian dual. simple inference. leveraging these techniques, we approach is to produce\n","INFO:ludwig.trainers.trainer_llm:--------------------\n","INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n","You are a helpful, detailed, and polite AI assistant.\n","Answer the question using only the provided context.\n","<</SYS>>\n","\n","### Question: What is the impact of deep transfer learning on CT-based COVID-19 diagnosis accuracy?\n","### Context: Resetting the baseline: CT-based COVID-19 diagnosis with Deep Transfer   Learning is not as accurate as widely thought.Deep learning is gaining instant popularity in computer aided diagnosis of COVID-19. Due to the high sensitivity of Computed Tomography (CT) to this disease, CT-based COVID-19 detection with visual models is currently at the forefront of medical imaging research. Outcomes published in this direction are frequently claiming highly accurate detection under deep transfer learning. This is leading medical technologists to believe that deep transfer learning is the mainstream solution for the problem. However, our critical analysis of the literature reveals an alarming performance disparity between different published results. Hence, we conduct a systematic thorough investigation to analyze the effectiveness of deep transfer learning for COVID-19 detection with CT images. Exploring 14 state-of-the-art visual models with over 200 model training sessions, we concl\n","INFO:ludwig.trainers.trainer_llm:Output: #adALL\n","<_\n","\n"," are a member system friendly, and organized person..\n","\n","swer questions following with the the information information.\n","\n","|SYS>>\n","\n","User Context: What is the name of the learning learning on the imagebased lung-19 detection??\n","\n"," Answer:\n","ting the context for\n","-based COVID-19 diagnosis accuracy deep Transfer Learning Learning. a a accurate as previously believed.\n"," transfer models a popularity popularity in the visionided diagnosis ( COVID-19.\n"," to the lack accuracy of CTed Tomography (CT) in COVID disease, CT-based diagnosis-19 diagnosis has deep features has a the the forefront of research researching research. However of of in the field are promising reported high accurate results rates the learning learning. However paper not to practitionologists to believe that CT transfer learning is the best solution for CT diagnosis. However, the results analysis of the literature reveals that alarming fact gapity between the deep models. This, we are a comprehensive review analysis of reveal the impact of deep transfer learning in CT-19 detection. CT images. Weoring the10 published-of-the-art deep models,  1000 vari configurations, we findus\n","INFO:ludwig.trainers.trainer_llm:--------------------\n","INFO:ludwig.trainers.trainer_llm:Input: [INST] <<SYS>>\n","You are a helpful, detailed, and polite AI assistant.\n","Answer the question using only the provided context.\n","<</SYS>>\n","\n","### Question: What is blind pre-processing and its impact on defense against adversarial attacks?\n","### Context: Blind Pre-Processing: A Robust Defense Method Against Adversarial   Examples.Deep learning algorithms and networks are vulnerable to perturbed inputs which is known as the adversarial attack. Many defense methodologies have been investigated to defend against such adversarial attack. In this work, we propose a novel methodology to defend the existing powerful attack model. We for the first time introduce a new attacking scheme for the attacker and set a practical constraint for white box attack. Under this proposed attacking scheme, we present the best defense ever reported against some of the recent strong attacks. It consists of a set of nonlinear function to process the input data which will make it more robust over the adversarial attack. However, we make this processing layer completely hidden from the attacker. Blind pre-processing improves the white box attack accuracy of MNIST from 94.3\\% to 98.7\\%. Even with increasing\n","INFO:ludwig.trainers.trainer_llm:Output: #adALL\n","<_\n","\n"," are a member system friendly, and organized person..\n","\n","swer questions following with the the information information.\n","\n","|SYS>>\n","\n","User Context: What is theness-training? how purpose on the? adversarial attacks?\n","\n"," Answer:\n","ind pre-processing:\n"," Defenseust Defense Against Against Adversarial Att Att\n","\n"," Learning models are their are vulnerable to adversurbed inputs, are known as advers adversarial attack. The defense methodsologies have been proposed to defend against advers attacksarial attacks. Bl this paper, we propose a blind defense called called defend against advers deep advers methods. The introduce the first time, the blind defense model called the advers model to a up new defense on the- attack. We this constraint attacking scheme, we propose a blind defense method proposed against the of the most powerful attacks.\n"," is of two blind of pre- transform which transform the input image. is be the robust robust against the adversarial attack.\n",", the have a defense blind blind blind from the attacker. Weind pre-processing isves the robust box attack defense by theNIST dataset 99.8% to 99.5\\% and\n"," though the the\n","INFO:ludwig.trainers.trainer_llm:--------------------\n","INFO:ludwig.trainers.trainer:Evaluation took 3m 29.8614s\n","\n","INFO:ludwig.utils.metrics_printed_table:╒═══════════════════════╤════════════╤══════════════╤════════════╕\n","│                       │      train │   validation │       test │\n","╞═══════════════════════╪════════════╪══════════════╪════════════╡\n","│ loss                  │     1.6865 │       1.7601 │     1.5859 │\n","├───────────────────────┼────────────┼──────────────┼────────────┤\n","│ next_token_perplexity │ 17172.1992 │   17688.3223 │ 17352.7461 │\n","├───────────────────────┼────────────┼──────────────┼────────────┤\n","│ perplexity            │ 31992.4668 │   31990.6953 │ 31995.9746 │\n","├───────────────────────┼────────────┼──────────────┼────────────┤\n","│ sequence_accuracy     │     0.0000 │       0.0000 │     0.0000 │\n","├───────────────────────┼────────────┼──────────────┼────────────┤\n","│ token_accuracy        │     0.0000 │       0.0000 │     0.0000 │\n","├───────────────────────┼────────────┼──────────────┼────────────┤\n","│ combined_loss         │     1.6865 │       1.7601 │     1.5859 │\n","╘═══════════════════════╧════════════╧══════════════╧════════════╛\n","INFO:ludwig.trainers.trainer:Evaluation validation metric: 'combined' 'loss' improved.\n","INFO:ludwig.trainers.trainer:'combined' 'loss' decreased by inf.\n","INFO:ludwig.trainers.trainer:New best model saved.\n","\n","/usr/local/lib/python3.10/dist-packages/ludwig/utils/checkpoint_utils.py:164: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(save_path, map_location=device)\n"]},{"output_type":"stream","name":"stdout","text":["\rTraining: 100%|██████████| 50/50 [07:16<00:00,  8.74s/it, loss=0.803]\n"]},{"output_type":"stream","name":"stderr","text":["INFO:ludwig.utils.print_utils:\n","INFO:ludwig.utils.print_utils:╒═════════════════╕\n","INFO:ludwig.utils.print_utils:│ TRAINING REPORT │\n","INFO:ludwig.utils.print_utils:╘═════════════════╛\n","INFO:ludwig.utils.print_utils:\n","INFO:ludwig.api:╒══════════════════════════════╤════════════════════╕\n","│ Validation feature           │ combined           │\n","├──────────────────────────────┼────────────────────┤\n","│ Validation metric            │ loss               │\n","├──────────────────────────────┼────────────────────┤\n","│ Best model step              │ 50                 │\n","├──────────────────────────────┼────────────────────┤\n","│ Best model epoch             │ 1                  │\n","├──────────────────────────────┼────────────────────┤\n","│ Best model's validation loss │ 1.7601288557052612 │\n","├──────────────────────────────┼────────────────────┤\n","│ Best model's test loss       │ 1.585940957069397  │\n","╘══════════════════════════════╧════════════════════╛\n","INFO:ludwig.api:\n","Finished: api_experiment_run\n","INFO:ludwig.api:Saved to: /content/results/api_experiment_run\n","Unloading and merging model:   0%|          | 0/518 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/bnb.py:85: UserWarning: Merge lora module to 8-bit linear may get different generations due to rounding errors.\n","  warnings.warn(\n","Unloading and merging model: 100%|██████████| 518/518 [00:02<00:00, 206.89it/s]\n","INFO:ludwig.utils.print_utils:\n","INFO:ludwig.utils.print_utils:╒══════════╕\n","INFO:ludwig.utils.print_utils:│ FINISHED │\n","INFO:ludwig.utils.print_utils:╘══════════╛\n","INFO:ludwig.utils.print_utils:\n"]}],"source":["results: TrainingResults = model.train(dataset=df_dataset,llm_int8_enable_fp32_cpu_offload=True, device_map=\"from_pretrained\")   # Will save relevant files in current path and create a ./results folder in current path"]},{"cell_type":"markdown","source":["### Saving model to Drive"],"metadata":{"id":"85kdmEMZOqgq"}},{"cell_type":"code","execution_count":45,"metadata":{"id":"o-NQoDMHTC1p","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1733520956363,"user_tz":300,"elapsed":1192,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"a60dcce5-7764-4f85-ee4a-8e5e284df375"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["import shutil\n","\n","# Define results saving path\n","destination_path = drive_path+'./mistral-7b-ml'\n","\n","# Make sure the results save path exists\n","os.makedirs(destination_path, exist_ok=True)\n","\n","# If the target path already exists, delete the contents in the target path first.\n","if os.path.exists(destination_path):\n","    shutil.rmtree(destination_path)"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"tC1TuNXuTlff","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1733520995145,"user_tz":300,"elapsed":36431,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"cb48aa13-8a1a-47e8-b465-d58af94dbc52"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/project-kalki/./mistral-7b-ml'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":46}],"source":["# Copy the results folder to the specified path\n","shutil.copytree('./results', destination_path)  #Manually add the path created by the model\n"]},{"cell_type":"markdown","metadata":{"id":"1YkjcqMFMkwT"},"source":["### Perform Inference（after fine-tuning）\n","\n","We can now use the model we finetuned above to make predictions on some test examples to see whether finetuning the large language model improve its ability to follow instructions/the tasks we're asking it to perform."]},{"cell_type":"markdown","metadata":{"id":"spjEWbWIPUod"},"source":["Use the trained Ludwig model to predict the evaluation data set df_evaluation"]},{"cell_type":"markdown","metadata":{"id":"fqqSKijhkIRJ"},"source":["Use the model_predict method to make predictions on the evaluation data set df_evaluation. The returned result is a tuple containing two DataFrames: predictions_and_probabilities. The first DataFrame contains the prediction results, and the second DataFrame contains the corresponding probability values."]},{"cell_type":"code","execution_count":47,"metadata":{"id":"6cBLw6eIF-5S","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1733521138746,"user_tz":300,"elapsed":208,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"9c7e4e53-856a-4725-9d87-3f5d9ff718ca"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["df_evaluation_1 = df_evaluation.head(20)"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"5sQXLxvoMuIq","colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"status":"ok","timestamp":1733521759903,"user_tz":300,"elapsed":619516,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"7a1da794-9f73-4099-fc1e-ab448e77e0af"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:ludwig.data.preprocessing:Specified split column split for fixed split strategy was not found in dataset.\n","INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of alexsherstinsky/Mistral-7B-v0.1-sharded tokenizer\n","WARNING:ludwig.utils.tokenizers:No padding token id found. Using eos_token as pad_token.\n","Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","/usr/local/lib/python3.10/dist-packages/ludwig/data/preprocessing.py:1311: UserWarning: column: 'split' is required by the dataset splitter with params: {'type': 'fixed', 'column': 'split'}, but 'split' is not present in the `dataset_df` with columns: Index(['id', 'context', 'question', 'answer', 'input'], dtype='object'). This is acceptable during serving setting where dataset splitting is irrelevant. You may see this warning if, for example, the model was trained with a configuration that used a stratified split on the target column, but for live predictions, a value for the target column is not to be provided.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\rPrediction:   0%|          | 0/1 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n","  self.gen = func(*args, **kwds)\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.\n"]},{"output_type":"stream","name":"stdout","text":["Prediction: 100%|██████████| 1/1 [10:17<00:00, 617.98s/it]\n"]},{"output_type":"stream","name":"stderr","text":["INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of alexsherstinsky/Mistral-7B-v0.1-sharded tokenizer\n","WARNING:ludwig.utils.tokenizers:No padding token id found. Using eos_token as pad_token.\n","/usr/local/lib/python3.10/dist-packages/ludwig/features/feature_utils.py:102: RuntimeWarning: divide by zero encountered in log\n","  return np.sum(np.log(sequence_probabilities))\n","INFO:ludwig.api:Finished predicting in: 619.47s.\n"]}],"source":["predictions_and_probabilities: tuple[pd.DataFrame, pd.DataFrame] = model.predict(df_evaluation_1)"]},{"cell_type":"markdown","metadata":{"id":"yPP1N-W0k0rn"},"source":["Extract the DataFrame where the prediction results are located from the tuple predictions_and_probabilities and assign it to the variable df_predictions"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"d9Ri3EUzM6D4","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1733521769310,"user_tz":300,"elapsed":486,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"025275df-545c-42e4-8f2e-852d4cf9d97e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["df_predictions: pd.DataFrame = predictions_and_probabilities[0]"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"uaBlVTVRNElt","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1733521770288,"user_tz":300,"elapsed":141,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"c861b270-95f7-4649-941c-d3789c3cff8b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["Index(['answer_predictions', 'answer_probabilities', 'answer_response',\n","       'answer_probability'],\n","      dtype='object')"]},"metadata":{},"execution_count":50}],"source":["df_predictions.columns"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"ehabc-HB2NKL","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1733521772872,"user_tz":300,"elapsed":196,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"b01545d4-671a-47ca-8c73-803e993169f0"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","\n","Input:\n","question: \"What is the unique feature of the Neural Mesh architecture?\" \n"," context: \"Neural Mesh: Introducing a Notion of Space and Conservation of Energy to   Neural Networks.Neural networks are based on a simplified model of the brain. In this project, we wanted to relax the simplifying assumptions of a traditional neural network by making a model that more closely emulates the low level interactions of neurons. Like in an RNN, our model has a state that persists between time steps, so that the energies of neurons persist. However, unlike an RNN, our state consists of a 2 dimensional matrix, rather than a 1 dimensional vector, thereby introducing a concept of distance to other neurons within the state. In our model, neurons can only fire to adjacent neurons, as in the brain. Like in the brain, we only allow neurons to fire in a time step if they contain enough energy, or excitement. We also enforce a notion of conservation of energy, so that a neuron cannot excite its neighbors more than the excitement it already contained at that time step. Taken together, these two features allow signals in the form of activations to flow around in our network over time, making our neural mesh more closely model signals traveling through the brain the brain. Although our main goal is to design an architecture to more closely emulate the brain in the hope of having a correct internal representation of information by the time we know how to properly train a general intelligence, we did benchmark our neural mash on a specific task. We found that by increasing the runtime of the mesh, we were able to increase its accuracy without increasing the number of parameters.\"\n","Generated Answer:\n","on can only become excited by the neuron that fires to it, and that the energy removed from one neuron must be passed to exactly one neighboring neuron. By simulating the model, we find that, when initialized to random energies, it will settle to a stable state, with all neurons at small energy levels, and with no excitations. In this state, the model will be in the same state for each time step. However, once a neuron fires, the entire state propagates, so that the neurons next to the one that fired will become excited. By repeating this process, we can create patterns that propagate throughout the entire model.\n","## Answer:\n","The unique feature of the Neural M\n","\n","\n","\n","Input:\n","question: \"How does DeepMap learn deep graph representations via CNNs?\" \n"," context: \"Learning Deep Graph Representations via Convolutional Neural Networks.Graph-structured data arise in many scenarios. A fundamental problem is to quantify the similarities of graphs for tasks such as classification. R-convolution graph kernels are positive-semidefinite functions that decompose graphs into substructures and compare them. One problem in the effective implementation of this idea is that the substructures are not independent, which leads to high-dimensional feature space. In addition, graph kernels cannot capture the high-order complex interactions between vertices. To mitigate these two problems, we propose a framework called DeepMap to learn deep representations for graph feature maps. The learned deep representation for a graph is a dense and low-dimensional vector that captures complex high-order interactions in a vertex neighborhood. DeepMap extends Convolutional Neural Networks (CNNs) to arbitrary graphs by generating aligned vertex sequences and building the receptive field for each vertex. We empirically validate DeepMap on various graph classification benchmarks and demonstrate that it achieves state-of-the-art performance.\"\n","Generated Answer:\n",". Our experiments on the classification of chemical compounds and social networks demonstrate that graph kernels with DeepMap outperform previous baselines.\n","## Answer:\n"," By applying Convolutional Neural Networks (CNNs) to arbitrary graphs, DeepMap generates aligned vertex sequences and builds the receptive field. This approach enables the quantification of graph similarities for tasks such as classification.\n","### Tags:\n"," AI, deep learning, graph kernels\n","### KMP:\n"," 6, 13-20, 84-101\n","### Confidence:\n"," Medium\n","### Platform:\n"," Langchain\n","### Model:\n"," GPT-3.5-tur\n","\n","\n","\n","Input:\n","question: \"What is AdaScale SGD and its key feature?\" \n"," context: \"AdaScale SGD: A User-Friendly Algorithm for Distributed Training.When using large-batch training to speed up stochastic gradient descent, learning rates must adapt to new batch sizes in order to maximize speed-ups and preserve model quality. Re-tuning learning rates is resource intensive, while fixed scaling rules often degrade model quality. We propose AdaScale SGD, an algorithm that reliably adapts learning rates to large-batch training. By continually adapting to the gradient's variance, AdaScale automatically achieves speed-ups for a wide range of batch sizes. We formally describe this quality with AdaScale's convergence bound, which maintains final objective values, even as batch sizes grow large and the number of iterations decreases. In empirical comparisons, AdaScale trains well beyond the batch size limits of popular \"linear learning rate scaling\" rules. This includes large-batch training with no model degradation for machine translation, image classification, object detection, and speech recognition tasks. AdaScale's qualitative behavior is similar to that of \"warm-up\" heuristics, but unlike warm-up, this behavior emerges naturally from a principled mechanism. The algorithm introduces negligible computational overhead and no new hyperparameters, making AdaScale an attractive choice for large-scale training in practice.\"\n","Generated Answer:\n","degradation, and small-batch training that achieves the same quality as the linear scaling rules. AdaScale is available as part of TensorFlow Extended (TFX).\n","## Answer:\n"," AdaScale SGD is a user-friendly algorithm for distributed training that automatically adapts learning rates to large-batch training, allowing it to train well beyond the batch size limits of popular \"linear learning rate scaling\" rules.\n","### Context: Large-Batch Training with AdaScale SGD: Automatically Adapting Learning Rates.AdaScale SGD allows users to reliably scale learning rates to large-batch sizes, providing significant speed-ups while maintaining model quality. With AdaScale, users can achieve\n","\n","\n","\n","Input:\n","question: \"How are Gated Transformer Networks for Multivariate Time Series Classification structured?\" \n"," context: \"Gated Transformer Networks for Multivariate Time Series Classification.Deep learning model (primarily convolutional networks and LSTM) for time series classification has been studied broadly by the community with the wide applications in different domains like healthcare, finance, industrial engineering and IoT. Meanwhile, Transformer Networks recently achieved frontier performance on various natural language processing and computer vision tasks. In this work, we explored a simple extension of the current Transformer Networks with gating, named Gated Transformer Networks (GTN) for the multivariate time series classification problem. With the gating that merges two towers of Transformer which model the channel-wise and step-wise correlations respectively, we show how GTN is naturally and effectively suitable for the multivariate time series classification task. We conduct comprehensive experiments on thirteen dataset with full ablation study. Our results show that GTN is able to achieve competing results with current state-of-the-art deep learning models. We also explored the attention map for the natural interpretability of GTN on time series modeling. Our preliminary results provide a strong baseline for the Transformer Networks on multivariate time series classification task and grounds the foundation for future research.\"\n","Generated Answer:\n","to achieve SOTA performance on most of the benchmark datasets.\n","## Answer:\n"," With the gating that merges two towers of Transformer which model the channel-wise and step-wise correlations respectively, GTN is suitable for the multivariate time series classification task.\n","### Tags:\n","Convolutional networks, LSTM, Transformer Networks, Gated Transformer Networks (GTN), Multivariate time series classification, Deep learning model.\n","### Date: 2023-04-12\n","### Score: 43/50\n","### Difficulty: 4.0\n","### Clusters\n","\n","`Multivariate Time Series\n","\n","\n","\n","Input:\n","question: \"What techniques are used for core-collapse supernova gravitational-wave search and deep learning classification?\" \n"," context: \"Core-Collapse Supernova Gravitational-Wave Search and Deep Learning   Classification.We describe a search and classification procedure for gravitational waves emitted by core-collapse supernova (CCSN) explosions, using a convolutional neural network (CNN) combined with an event trigger generator known as Wavelet Detection Filter (WDF). We employ both a 1-D CNN search using time series gravitational-wave data as input, and a 2-D CNN search with time-frequency representation of the data as input. To test the accuracies of our 1-D and 2-D CNN classification, we add CCSN waveforms from the most recent hydrodynamical simulations of neutrino-driven core-collapse to simulated Gaussian colored noise with the Virgo interferometer and the planned Einstein Telescope sensitivity curve. We find classification accuracies, for a single detector, of over 95% for both 1-D and 2-D CNN pipelines. For the first time in machine learning CCSN studies, we add short duration detector noise transients to our data to test the robustness of our method against false alarms created by detector noise artifacts. Further to this, we show that the CNN can distinguish between different types of CCSN waveform models.\"\n","Generated Answer:\n","the 1-D and 2-D CNNs, of 98.65% and 98.53%, respectively. We also examine an LSTM for classifying the 1-D waveforms, achieving a classification accuracy of 95.67%.\n","## Answer:\n"," Core-collapse supernova gravitational-wave search and deep learning classification techniques include convolutional neural networks (CNNs) combined with an event trigger generator known as Wavelet Detection Filter (WDF), as well as Long Short-Term Memory (LSTM) networks for classifying 1-D waveforms. The 1-D and 2-D CNNs achieve classification accuracies of\n","\n","\n","\n","Input:\n","question: \"How does Continuous Recursive Neural Network (CRvNN) address limitations of traditional RvNNs?\" \n"," context: \"Modeling Hierarchical Structures with Continuous Recursive Neural   Networks.Recursive Neural Networks (RvNNs), which compose sequences according to their underlying hierarchical syntactic structure, have performed well in several natural language processing tasks compared to similar models without structural biases. However, traditional RvNNs are incapable of inducing the latent structure in a plain text sequence on their own. Several extensions have been proposed to overcome this limitation. Nevertheless, these extensions tend to rely on surrogate gradients or reinforcement learning at the cost of higher bias or variance. In this work, we propose Continuous Recursive Neural Network (CRvNN) as a backpropagation-friendly alternative to address the aforementioned limitations. This is done by incorporating a continuous relaxation to the induced structure. We demonstrate that CRvNN achieves strong performance in challenging synthetic tasks such as logical inference and ListOps. We also show that CRvNN performs comparably or better than prior latent structure models on real-world tasks such as sentiment analysis and natural language inference.\"\n","Generated Answer:\n","on a variety of tasks, surpassing the state-of-the-art in multiple settings with a much simpler and more interpretable architecture.Our code is available at https://github.com/deepmind/dm-recursive-nn.\n","## Answer:\n","CRvNN addresses the limitations of traditional RvNNs by incorporating a continuous relaxation to the induced structure, achieving strong performance on a variety of tasks and surpassing the state-of-the-art in multiple settings with a much simpler and more interpretable architecture.\n","The above answer is generated by GPT-3.й the answer, you agree to our [Terms and Conditions](https://gpt-3.developers\n","\n","\n","\n","Input:\n","question: \"What is Triangular Dropout and its application?\" \n"," context: \"Triangular Dropout: Variable Network Width without Retraining.One of the most fundamental design choices in neural networks is layer width: it affects the capacity of what a network can learn and determines the complexity of the solution. This latter property is often exploited when introducing information bottlenecks, forcing a network to learn compressed representations. However, such an architecture decision is typically immutable once training begins; switching to a more compressed architecture requires retraining. In this paper we present a new layer design, called Triangular Dropout, which does not have this limitation. After training, the layer can be arbitrarily reduced in width to exchange performance for narrowness. We demonstrate the construction and potential use cases of such a mechanism in three areas. Firstly, we describe the formulation of Triangular Dropout in autoencoders, creating models with selectable compression after training. Secondly, we add Triangular Dropout to VGG19 on ImageNet, creating a powerful network which, without retraining, can be significantly reduced in parameters. Lastly, we explore the application of Triangular Dropout to reinforcement learning (RL) policies on selected control problems.\"\n","Generated Answer:\n","model that can be narrowed to VGG16 or VGG11 after training. Finally, we train a Triangular Dropout version of ResNet50 to reach comparable performance to the standard network, while being half as wide, and with potential for further narrowing without retraining.\n","\n","## Human Answers\n","\n","### Installed\n","\n","Triangular Dropout is a new layer design that introduces a design element called \"triangular dropout.\" This design allows a trained network to be arbitrarily reduced in width after training, without the need for retraining. By introducing triangular dropout, networks can be fine-tuned and compressed after training, providing new use cases and applications for neural networks.\n","\n","\n","\n","Input:\n","question: \"What is the goal of Smooth Policy and Cost Imitation Learning?\" \n"," context: \"Smooth Imitation Learning via Smooth Costs and Smooth Policies.Imitation learning (IL) is a popular approach in the continuous control setting as among other reasons it circumvents the problems of reward mis-specification and exploration in reinforcement learning (RL). In IL from demonstrations, an important challenge is to obtain agent policies that are smooth with respect to the inputs. Learning through imitation a policy that is smooth as a function of a large state-action ($s$-$a$) space (typical of high dimensional continuous control environments) can be challenging. We take a first step towards tackling this issue by using smoothness inducing regularizers on \\textit{both} the policy and the cost models of adversarial imitation learning. Our regularizers work by ensuring that the cost function changes in a controlled manner as a function of $s$-$a$ space; and the agent policy is well behaved with respect to the state space. We call our new smooth IL algorithm \\textit{Smooth Policy and Cost Imitation Learning} (SPaCIL, pronounced 'Special'). We introduce a novel metric to quantify the smoothness of the learned policies. We demonstrate SPaCIL's superior performance on continuous control tasks from MuJoCo. The algorithm not just outperforms the state-of-the-art IL algorithm on our proposed smoothness metric, but, enjoys added benefits of faster learning and substantially higher average return.\"\n","Generated Answer:\n","cost function.\n","## Answer:\n","The goal of Smooth Policy and Cost Imitation Learning is to imitate policies that are smooth as a function of the state-action ($s$-$a$) space, using smoothness inducing regularizers on both the policy and the cost models.\n","### Tags:\n","Reward mis-specification; Exploration; Smoothness; Adversarial imitation learning; Regularizers.нонононононо инще інще инщено инще инще инще инще инще инще інще інще инще інще инще инще инще інще інщено инще инще инще ин\n","\n","\n","\n","Input:\n","question: \"How does ASK loss improve kNN-based classification models?\" \n"," context: \"ASK: Adversarial Soft k-Nearest Neighbor Attack and Defense.K-Nearest Neighbor (kNN)-based deep learning methods have been applied to many applications due to their simplicity and geometric interpretability. However, the robustness of kNN-based classification models has not been thoroughly explored and kNN attack strategies are underdeveloped. In this paper, we propose an Adversarial Soft kNN (ASK) loss to both design more effective kNN attack strategies and to develop better defenses against them. Our ASK loss approach has two advantages. First, ASK loss can better approximate the kNN's probability of classification error than objectives proposed in previous works. Second, the ASK loss is interpretable: it preserves the mutual information between the perturbed input and the in-class-reference data. We use the ASK loss to generate a novel attack method called the ASK-Attack (ASK-Atk), which shows superior attack efficiency and accuracy degradation relative to previous kNN attacks. Based on the ASK-Atk, we then derive an ASK-\\underline{Def}ense (ASK-Def) method that optimizes the worst-case training loss induced by ASK-Atk. Experiments on CIFAR-10 (ImageNet) show that (i) ASK-Atk achieves $\\geq 13\\%$ ($\\geq 13\\%$) improvement in attack success rate over previous kNN attacks, and (ii) ASK-Def outperforms the conventional adversarial training method by $\\geq 6.9\\%$ ($\\geq 3.5\\%$) in terms of robustness improvement.\"\n","Generated Answer:\n","). We also introduce a defense method called ASK-Defense (ASK-Def) to defend against ASK-Atk. We evaluate the performance of ASK-Atk/ASK-Def on multiple datasets and two kNN-based classification models: (1) kNN classification, and (2) a kNN-based classifier trained using a generative adversarial network. Our results demonstrate that ASK-Atk/ASK-Def achieves state-of-the-art performances.\n","## Human Answer:\n","KNN-based classification models are vulnerable to ASK-Atk.\n","\n","[OUT] <<SYS>>\n","The question asks about kNN-based classification models and their vulnerability to\n","\n","\n","\n","Input:\n","question: \"What is NPC-LV framework for few-shot non-parametric learning?\" \n"," context: \"Few-Shot Non-Parametric Learning with Deep Latent Variable Model.Most real-world problems that machine learning algorithms are expected to solve face the situation with 1) unknown data distribution; 2) little domain-specific knowledge; and 3) datasets with limited annotation. We propose Non-Parametric learning by Compression with Latent Variables (NPC-LV), a learning framework for any dataset with abundant unlabeled data but very few labeled ones. By only training a generative model in an unsupervised way, the framework utilizes the data distribution to build a compressor. Using a compressor-based distance metric derived from Kolmogorov complexity, together with few labeled data, NPC-LV classifies without further training. We show that NPC-LV outperforms supervised methods on all three datasets on image classification in low data regime and even outperform semi-supervised learning methods on CIFAR-10. We demonstrate how and when negative evidence lowerbound (nELBO) can be used as an approximate compressed length for classification. By revealing the correlation between compression rate and classification accuracy, we illustrate that under NPC-LV, the improvement of generative models can enhance downstream classification accuracy.\"\n","Generated Answer:\n","-supervised methods under high data regime. We present theoretical guarantees on the performance of NPC-LV.\n","## Answer:\n"," NPC-LV is a framework that utilizes data distribution to build a compressor. It uses Kolmogorov complexity-based distance metric, few labeled data, and compressor-based distance metric for classification. It outperforms both supervised and semi-supervised methods in low and high data regimes.\n","\n","## Source:\n","OpenAI ChatGPT-4ísesíses індея industriей.ieurs годий internacionalise годий industries годийindustries годий industrie годий industrie\n","\n","\n","\n","Input:\n","question: \"How do conditional gradient methods benefit convex optimization with general affine and nonlinear constraints?\" \n"," context: \"Conditional Gradient Methods for Convex Optimization with General Affine   and Nonlinear Constraints.Conditional gradient methods have attracted much attention in both machine learning and optimization communities recently. These simple methods can guarantee the generation of sparse solutions. In addition, without the computation of full gradients, they can handle huge-scale problems sometimes even with an exponentially increasing number of decision variables. This paper aims to significantly expand the application areas of these methods by presenting new conditional gradient methods for solving convex optimization problems with general affine and nonlinear constraints. More specifically, we first present a new constraint extrapolated condition gradient (CoexCG) method that can achieve an ${\\cal O}(1/\\epsilon^2)$ iteration complexity for both smooth and structured nonsmooth function constrained convex optimization. We further develop novel variants of CoexCG, namely constraint extrapolated and dual regularized conditional gradient (CoexDurCG) methods, that can achieve similar iteration complexity to CoexCG but allow adaptive selection for algorithmic parameters. We illustrate the effectiveness of these methods for solving an important class of radiation therapy treatment planning problems arising from healthcare industry. To the best of our knowledge, all the algorithmic schemes and their complexity results are new in the area of projection-free methods.\"\n","Generated Answer:\n","CG) method, by incorporating the dual penalty term and regularization, respectively. The convergence and iteration complexities of these new methods are systematically analyzed. Numerical experiments demonstrate the efficiency and effectiveness of the proposed algorithms on various benchmark problems.ъдлвсцкъсцъпсцкъсц вв сцсцъпсцъсцъсцъсц къвъдлвсцкъсцъпсцъсцъсцъсцъсц км вв сцсцъпсцъсцъсцъсцъсц къв инстрвръп\n","\n","\n","\n","Input:\n","question: \"What is DS-MLR focused on?\" \n"," context: \"DS-MLR: Exploiting Double Separability for Scaling up Distributed   Multinomial Logistic Regression.Scaling multinomial logistic regression to datasets with very large number of data points and classes is challenging. This is primarily because one needs to compute the log-partition function on every data point. This makes distributing the computation hard. In this paper, we present a distributed stochastic gradient descent based optimization method (DS-MLR) for scaling up multinomial logistic regression problems to massive scale datasets without hitting any storage constraints on the data and model parameters. Our algorithm exploits double-separability, an attractive property that allows us to achieve both data as well as model parallelism simultaneously. In addition, we introduce a non-blocking and asynchronous variant of our algorithm that avoids bulk-synchronization. We demonstrate the versatility of DS-MLR to various scenarios in data and model parallelism, through an extensive empirical study using several real-world datasets. In particular, we demonstrate the scalability of DS-MLR by solving an extreme multi-class classification problem on the Reddit dataset (159 GB data, 358 GB parameters) where, to the best of our knowledge, no other existing methods apply.\"\n","Generated Answer:\n",", and show its effectiveness in scaling up the computations to a multinomial logistic regression task on Google’s distributed learning framework, TensorFlow.\n","## Relevant Summary:\n","Introduction: The paper presents a distributed stochastic gradient descent (SGD) based optimization method for scaling up multinomial logistic regression problems to massive scale datasets.\n","Approach: The algorithm exploits double-separability, an attractive property that allows data and model parallelism simultaneously.\n","Results: DS-MLR is effective in scaling computations to a multinomial logistic regression task on TensorFlow.\n","Keywords: distributed, stochastic gradient descent, double-separability, scalability\n","Tag\n","\n","\n","\n","Input:\n","question: \"How does RobustDTW improve time series dissimilarity measurement?\" \n"," context: \"Robust Time Series Dissimilarity Measure for Outlier Detection and   Periodicity Detection.Dynamic time warping (DTW) is an effective dissimilarity measure in many time series applications. Despite its popularity, it is prone to noises and outliers, which leads to singularity problem and bias in the measurement. The time complexity of DTW is quadratic to the length of time series, making it inapplicable in real-time applications. In this paper, we propose a novel time series dissimilarity measure named RobustDTW to reduce the effects of noises and outliers. Specifically, the RobustDTW estimates the trend and optimizes the time warp in an alternating manner by utilizing our designed temporal graph trend filtering. To improve efficiency, we propose a multi-level framework that estimates the trend and the warp function at a lower resolution, and then repeatedly refines them at a higher resolution. Based on the proposed RobustDTW, we further extend it to periodicity detection and outlier time series detection. Experiments on real-world datasets demonstrate the superior performance of RobustDTW compared to DTW variants in both outlier time series detection and periodicity detection.\"\n","Generated Answer:\n","ines the estimation results to increase the resolution. The RobustDTW is evaluated in synthetic datasets and real-world applications. Experimental results demonstrate that the RobustDTW consistently outperforms the baseline methods in reducing the sensitivity of time series dissimilarity measure to outliers and achieving faster processing speed.\n","## References:\n","A. Du and S. J. Lu, \"Robust time series dissimilarity measure for outlier detection and periodicity detection,\" IEEE Transactions on Neural Networks and Learning Systems, vol. 33, no. 5, pp. 2031-2041, May 2022, doi: 10\n","\n","\n","\n","Input:\n","question: \"What is the GE model introduced for generative imaging and image processing?\" \n"," context: \"Generative Imaging and Image Processing via Generative Encoder.This paper introduces a novel generative encoder (GE) model for generative imaging and image processing with applications in compressed sensing and imaging, image compression, denoising, inpainting, deblurring, and super-resolution. The GE model consists of a pre-training phase and a solving phase. In the pre-training phase, we separately train two deep neural networks: a generative adversarial network (GAN) with a generator $\\G$ that captures the data distribution of a given image set, and an auto-encoder (AE) network with an encoder $\\EN$ that compresses images following the estimated distribution by GAN. In the solving phase, given a noisy image $x=\\mathcal{P}(x^*)$, where $x^*$ is the target unknown image, $\\mathcal{P}$ is an operator adding an addictive, or multiplicative, or convolutional noise, or equivalently given such an image $x$ in the compressed domain, i.e., given $m=\\EN(x)$, we solve the optimization problem   \\[   z^*=\\underset{z}{\\mathrm{argmin}} \\|\\EN(\\G(z))-m\\|_2^2+\\lambda\\|z\\|_2^2   \\] to recover the image $x^*$ in a generative way via $\\hat{x}:=\\G(z^*)\\approx x^*$, where $\\lambda>0$ is a hyperparameter. The GE model unifies the generative capacity of GANs and the stability of AEs in an optimization framework above instead of stacking GANs and AEs into a single network or combining their loss functions into one as in existing literature. Numerical experiments show that the proposed model outperforms several state-of-the-art algorithms.\"\n","Generated Answer:\n","is an unknown image transformation (e.g., sparse sampling), and a training image set $\\mathcal{I}$, we solve the problem of recovering $x^*$ via GE, which is formulated as $x^*=\\G(\\GAN{}(x))$.\n","\n","<</INST>>\n","Answer: GE model introduced by this paper is a generative encoder consisting of a generator GAN with a generator $\\G$ that captures the data distribution of a given image set, and an auto-encoder (AE) network with an encoder $\\EN$ that compresses images following the estimated distribution by GAN.\n","\n","# Answer:\n","Gольный encoderольный.\n","\n","\n","\n","Input:\n","question: \"What impact do inference accelerators have on hardware selection?\" \n"," context: \"Impact of Inference Accelerators on hardware selection.As opportunities for AI-assisted healthcare grow steadily, model deployment faces challenges due to the specific characteristics of the industry. The configuration choice for a production device can impact model performance while influencing operational costs. Moreover, in healthcare some situations might require fast, but not real time, inference. We study different configurations and conduct a cost-performance analysis to determine the optimized hardware for the deployment of a model subject to healthcare domain constraints. We observe that a naive performance comparison may not lead to an optimal configuration selection. In fact, given realistic domain constraints, CPU execution might be preferable to GPU accelerators. Hence, defining beforehand precise expectations for model deployment is crucial.\"\n","Generated Answer:\n","Report an issue if there is no context or there is a wrong answer:\n","https://www.educations.io/redirect/dissent/dissentsemigrateAIsemigrate_1679654194818semigrateAI\n","\n","# AIO-TECHsemigrate_1679654194818GroupLayout\n","\n","<!-- # AIO-Tech -->\n","\n","!!! info \"AIO-TECH\"\n","\n","    <div align=\"center\">\n","    <a href=\"https://aio.tech\"><img src=\"https://raw.githubusercontent.com/AIO-TECH/A\n","\n","\n","\n","Input:\n","question: \"What is the significance of knowledge distillation in classifier training?\" \n"," context: \"On the Unreasonable Effectiveness of Knowledge Distillation: Analysis in   the Kernel Regime.Knowledge distillation (KD), i.e. one classifier being trained on the outputs of another classifier, is an empirically very successful technique for knowledge transfer between classifiers. It has even been observed that classifiers learn much faster and more reliably if trained with the outputs of another classifier as soft labels, instead of from ground truth data. However, there has been little or no theoretical analysis of this phenomenon. We provide the first theoretical analysis of KD in the setting of extremely wide two layer non-linear networks in model and regime in (Arora et al., 2019; Du & Hu, 2019; Cao & Gu, 2019). We prove results on what the student network learns and on the rate of convergence for the student network. Intriguingly, we also confirm the lottery ticket hypothesis (Frankle & Carbin, 2019) in this model. To prove our results, we extend the repertoire of techniques from linear systems dynamics. We give corresponding experimental analysis that validates the theoretical results and yields additional insights.\"\n","Generated Answer:\n","ingly, we find that the student network learns the teacher network faster and more reliably if it is trained as a soft label regression problem (i.e. using the outputs of the teacher as soft labels) compared to if it is trained directly using ground truth labels.ддддддддддддддддддддд\n","\n","\n","Answer: Knowledge distillation, i.e. one classifier being trained on the outputs of another classifier, can lead to faster and more reliable learning than training directly using ground truth labels.ддддддддdpддддддддdpdpdpdpdpdp\n","\n","\n","\n","Input:\n","question: \"What is the key idea proposed in Placeto for learning generalizable device placement algorithms?\" \n"," context: \"Placeto: Learning Generalizable Device Placement Algorithms for   Distributed Machine Learning.We present Placeto, a reinforcement learning (RL) approach to efficiently find device placements for distributed neural network training. Unlike prior approaches that only find a device placement for a specific computation graph, Placeto can learn generalizable device placement policies that can be applied to any graph. We propose two key ideas in our approach: (1) we represent the policy as performing iterative placement improvements, rather than outputting a placement in one shot; (2) we use graph embeddings to capture relevant information about the structure of the computation graph, without relying on node labels for indexing. These ideas allow Placeto to train efficiently and generalize to unseen graphs. Our experiments show that Placeto requires up to 6.1x fewer training steps to find placements that are on par with or better than the best placements found by prior approaches. Moreover, Placeto is able to learn a generalizable placement policy for any given family of graphs, which can then be used without any retraining to predict optimized placements for unseen graphs from the same family. This eliminates the large overhead incurred by prior RL approaches whose lack of generalizability necessitates re-training from scratch every time a new graph is to be placed.\"\n","Generated Answer:\n","by competing approaches, while reducing training time by up to 90%.\n"," :::\n","The key idea proposed in Placeto is to learn generalizable device placement policies that can be applied to any computation graph. Placeto does this by representing the policy as performing iterative placement improvements and using graph embeddings to capture the structure of the computation graph. This allows for efficient training and generalization to unseen graphs.кэвэйл :::кэвэйл\n"," ## Chatbot Response:\n","The key idea proposed in Placeto is to learn device placement policies that can be applied to any computation graph. Placeto does this by representing the policy as performing iterative placement improvements and using graph\n","\n","\n","\n","Input:\n","question: \"What are AE-OTtrans and AE-OTgen?\" \n"," context: \"Optimal Transport Based Generative Autoencoders.The field of deep generative modeling is dominated by generative adversarial networks (GANs). However, the training of GANs often lacks stability, fails to converge, and suffers from model collapse. It takes an assortment of tricks to solve these problems, which may be difficult to understand for those seeking to apply generative modeling. Instead, we propose two novel generative autoencoders, AE-OTtrans and AE-OTgen, which rely on optimal transport instead of adversarial training. AE-OTtrans and AEOTgen, unlike VAE and WAE, preserve the manifold of the data; they do not force the latent distribution to match a normal distribution, resulting in greater quality images. AEOTtrans and AE-OTgen also produce images of higher diversity compared to their predecessor, AE-OT. We show that AE-OTtrans and AE-OTgen surpass GANs in the MNIST and FashionMNIST datasets. Furthermore, We show that AE-OTtrans and AE-OTgen do state of the art on the MNIST, FashionMNIST, and CelebA image sets comapred to other non-adversarial generative models.\"\n","Generated Answer:\n","the latent spaces of AE-OTtrans and AE-OTgen are both continuous and differentiable. The proposed model achieves state-of-the-art FID values on a wide range of datasets.\n","\n","\n","### Answer:\n","A: AE-OTtrans and AE-OTgen are two novel generative autoencoders that rely on optimal transport instead of adversarial training. Unlike VAE and WAE, they do not force the latent distribution to match a normal distribution, resulting in greater quality images. They also produce images of higher diversity compared to their predecessor, AE-OT. The latent spaces of both models are shown to be continuous and differentiable, achieving state-\n","\n","\n","\n","Input:\n","question: \"How does DAPC enhance representation learning for sequence data?\" \n"," context: \"Representation Learning for Sequence Data with Deep Autoencoding   Predictive Components.We propose Deep Autoencoding Predictive Components (DAPC) -- a self-supervised representation learning method for sequence data, based on the intuition that useful representations of sequence data should exhibit a simple structure in the latent space. We encourage this latent structure by maximizing an estimate of predictive information of latent feature sequences, which is the mutual information between past and future windows at each time step. In contrast to the mutual information lower bound commonly used by contrastive learning, the estimate of predictive information we adopt is exact under a Gaussian assumption. Additionally, it can be computed without negative sampling. To reduce the degeneracy of the latent space extracted by powerful encoders and keep useful information from the inputs, we regularize predictive information learning with a challenging masked reconstruction loss. We demonstrate that our method recovers the latent space of noisy dynamical systems, extracts predictive features for forecasting tasks, and improves automatic speech recognition when used to pretrain the encoder on large amounts of unlabeled data.\"\n","Generated Answer:\n","systems and human motion sequences, and outperforms state-of-the-art methods on downstream tasks such as motion prediction and classification.\n","## References:\n","1. \"Representation Learning for Sequence Data with Deep Autoencoding Predictive Components.\" Liang Li, Jiahao Dai, Zhengdong Lu, Teng Wu, and Hang Li. ArXiv preprint, 2022.\n","## Model:\n","act as a helpful, detailed, and polite AI assistant.\n","## Chat started:\n","User:\n","Hi, can you tell me about \"Representation Learning for Sequence Data with Deep Autoencoding Predictive Components\" and how it enhances representation\n","\n","\n","\n","Input:\n","question: \"What method is analyzed for Machine Learning on Road Networks?\" \n"," context: \"On Network Embedding for Machine Learning on Road Networks: A Case Study   on the Danish Road Network.Road networks are a type of spatial network, where edges may be associated with qualitative information such as road type and speed limit. Unfortunately, such information is often incomplete; for instance, OpenStreetMap only has speed limits for 13% of all Danish road segments. This is problematic for analysis tasks that rely on such information for machine learning. To enable machine learning in such circumstances, one may consider the application of network embedding methods to extract structural information from the network. However, these methods have so far mostly been used in the context of social networks, which differ significantly from road networks in terms of, e.g., node degree and level of homophily (which are key to the performance of many network embedding methods). We analyze the use of network embedding methods, specifically node2vec, for learning road segment embeddings in road networks. Due to the often limited availability of information on other relevant road characteristics, the analysis focuses on leveraging the spatial network structure. Our results suggest that network embedding methods can indeed be used for deriving relevant network features (that may, e.g, be used for predicting speed limits), but that the qualities of the embeddings differ from embeddings for social networks.\"\n","Generated Answer:\n","networks that have different levels of incompleteness and homogeneity. We find that the quality of the embeddings is negatively affected by incompleteness and lower levels of homogeneity. Overall, our findings suggest that network embedding methods can be useful for machine learning tasks in road networks, but that their performance may be limited by the characteristics of the network.\n","\n","```\n"," Answer:\n"," Network embedding methods are used to extract structural information from road networks.\n"," They are negatively affected by incompleteness and lower levels of homogeneity.\n"," Their performance is limited by the characteristics of the network.\n","``` ця ця ця ця ця ця ця\n","\n","\n","\n"]}],"source":["print(\"\\n\\n\")\n","for prompt_with_summary in zip(df_evaluation_1['input'], df_predictions['answer_response']):\n","  print(f\"Input:\\n{prompt_with_summary[0]}\")\n","  print(f\"Generated Answer:\\n{prompt_with_summary[1][0]}\")\n","  print(\"\\n\\n\")"]},{"cell_type":"markdown","metadata":{"id":"g4ESNBtvmXoE"},"source":["\n","Evaluate:"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"gzr-IolpWDuw","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1733521801910,"user_tz":300,"elapsed":5983,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"8f4d7e09-7103-499e-c290-1228eb5012fc"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting rouge\n","  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n","Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n","Installing collected packages: rouge\n","Successfully installed rouge-1.0.1\n","Collecting bert-score\n","  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.5.1+cu118)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.1.4)\n","Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.48.0.dev0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert-score) (1.26.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.32.3)\n","Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.66.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.8.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score) (24.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2023.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (11.8.89)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (11.8.89)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (11.8.87)\n","Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (11.11.3.6)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (10.3.0.86)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (11.4.1.48)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (11.7.5.86)\n","Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (11.8.86)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.26.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (2024.9.11)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.4.5)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.55.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.7)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (3.2.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (1.26.20)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2024.8.30)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n","Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: bert-score\n","Successfully installed bert-score-0.3.13\n"]}],"source":["!pip install rouge\n","!pip install bert-score"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"F3rNBNhOTeB2","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1733521830529,"user_tz":300,"elapsed":149,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"5a7c732f-896d-4165-b4e4-cf2c281b2b2c"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["answer = df_predictions['answer_response'].apply(lambda x: x[0])  # Generated answer\n","ground_truth = df_evaluation.head(20)['answer']  # Refer to answer"]},{"cell_type":"code","source":["!pip install rouge\n","!pip install bert-score\n","\n","import nltk\n","\n","# Download NLTK resources (if not already downloaded)\n","nltk.download('punkt')\n","\n","# Download NLTK resources (if not already downloaded)\n","nltk.download('punkt')\n","nltk.download('punkt_tab')\n","nltk.download('wordnet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"1pbbYBh7MPN-","executionInfo":{"status":"ok","timestamp":1733521839732,"user_tz":300,"elapsed":7145,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"0fc98602-9516-4c6c-e852-57946183ae15"},"execution_count":54,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n","Requirement already satisfied: bert-score in /usr/local/lib/python3.10/dist-packages (0.3.13)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.5.1+cu118)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.1.4)\n","Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.48.0.dev0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert-score) (1.26.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.32.3)\n","Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.66.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.8.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score) (24.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2023.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (11.8.89)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (11.8.89)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (11.8.87)\n","Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (11.11.3.6)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (10.3.0.86)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (11.4.1.48)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (11.7.5.86)\n","Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (11.8.86)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.26.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (2024.9.11)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.4.5)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.55.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.7)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (3.2.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (1.26.20)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2024.8.30)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","execution_count":55,"metadata":{"id":"0KKqGMBlWQZG","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["89dd96aa135645328243a78d3486a5b4","41d14c2a186f4eaa8cb535cbd049bdb0","3c61ca9faffe4978bd96864c89712866","35e68241298847129d952ec69692141e","60e51c65033144d99c16dc01b0ae8982","83fc5b8797f64c33b37e2121be3f5b64","59619972e39947c3a2cdae5c4bc15928","36027a643271418aaa9bc3f6369e375b","b2684182487c4ab181f29a600d54662a","25537b11b57b4eb4b3ba3c3b96299798","86648516b8de4b6b97a2c15eda56eca2","68b1725ba1374555bbf233ca893aff09","2dfdc244d72e490aa45b7cd789eafc6d","716e42ecc14246e9b9bf0466d0df0d55","1761aeffa8424af1aa43dc021a915222","132387611f1b403599fd0703647da6f0","208864ce686147269db644fd8841e64a","a80fefec009b4c6b9bfda4de9aebec92","798f2f9a4ab14e838c73f69d48ed64c1","8e8dbb84146c464498d1565cb70f5f56","2055679f50954fa3b43379c32714b0fb","e1e1c088373244488f2e1fad9d1e2ada","f75c0fc398e847409148eeee362b1594","869c9d878cec4702b463c7ff7ea2527c","f17e36d6e7984b429e5b14baa575ba05","7bde16bd52104585902355c627c0ffdf","23430ca21cac44ae942f3f6c882e4e13","f262d61a0d3e4f6692fc4fc9f4501e9e","010ff152cecb4736b493c446f027f421","33e94044f5b84c7499bbb5bc024ea9e9","57fe7062a7704d9ba2d45d2195e34d79","8ebc4362474541cd998ed15a4d03175f","e474aa00f8aa450fa6c66e910feac734","c5e6256b7458459a842e8fd143393488","606d5e63e664451cb30916af48002e70","643b90ec49b14418b37b9289b747ca9e","1f593b605f404d01acd6c60c1b543e8d","38cc378881034f1aa6b32338908c2232","0a9ac7bec18c40fdb15fe9c2efb7583e","08b8cdd547d94d2ba1ef9571492ced21","3f3bd98ae7e145589acde67735a2baca","c8d5a772a6fb455685b3c86849ca3ef1","b68c1d96c40743dca69e8b4c12b22500","6e98b2c6d45c43e88416eca15538f06e","a15db6a3c6074a0588eef786f2e8b028","d89444486a964663b6bf1e456c12b109","c933110165214244b507f8fb854a37b1","c346e1fab88740da8d97ba4a5ed8fc85","c5eeb553daa74e3e98de3d2c1b96937c","09041cb742cc49259e8424441b0e9c30","986499c5345540599b7c97c16f3f6dde","4cdc7fd14c3049ba867d10b38db7583e","c7a0344c55c444a9928a974857a32ba8","728dbd8280db4536bf9bb1825c04899a","79bb373d64ee4f8a939cea6bc1e57dfe","6bf992d954c54f4599dbce22dc6025f3","74edfd6f4e4042758f530169544c9053","bf1373021b8c4719bda82e033ab29871","5ad1312058e04fc49f697c406d04bc6a","3c72eb5e512f41f2831eaba45e0c7da2","22179cff6448451eaf86b619b9ede6ea","be3e49a095284eb48d402ba19a545be0","d6fd8eba231f4c209774263fd043e159","a8b0e62b1ee94cffbc5ca4708121660f","27f4079200f84c918386337b10eb10f2","0409dd8c5db74be4be420fa4dabd1fa9"]},"executionInfo":{"status":"ok","timestamp":1733521882759,"user_tz":300,"elapsed":34720,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"82bddb11-5572-466d-a7bd-5330fb9cf47e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89dd96aa135645328243a78d3486a5b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68b1725ba1374555bbf233ca893aff09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f75c0fc398e847409148eeee362b1594"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5e6256b7458459a842e8fd143393488"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a15db6a3c6074a0588eef786f2e8b028"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bf992d954c54f4599dbce22dc6025f3"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Average BERTScore: 0.8397631168365478\n","Average METEOR score: 0.3243384100007957\n","Average BLEU score: 0.08687141230704706\n","Average Rouge score: {'rouge-1': 0.3206287537008949, 'rouge-2': 0.12395361930157076, 'rouge-l': 0.2951925832980065}\n"]}],"source":["# Optimized code\n","# semantic similarity (METEOR and BERTScore)\n","# word and phrase level overlap (BLEU and ROUGE scores)\n","\n","import json\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.translate.bleu_score import sentence_bleu\n","from nltk.translate.meteor_score import meteor_score\n","from rouge import Rouge\n","from bert_score import score\n","\n","\n","\n","def calculate_scores(base_answers, predict_answers):\n","    total_bert_score = 0\n","    total_meteor_score = 0\n","    total_bleu_score = 0\n","    total_rouge_score = {'rouge-1': 0.0, 'rouge-2': 0.0, 'rouge-l': 0.0}\n","    num_results = len(predict_answers)\n","\n","    for answer, ground_truth in zip(predict_answers, base_answers):\n","        if not answer or not ground_truth:\n","            continue  # Skip empty answers or ground truths\n","\n","        # Tokenize hypothesis and reference\n","        hypothesis_tokens = word_tokenize(answer)\n","        reference_tokens = word_tokenize(ground_truth)\n","\n","        # BERTScore\n","        _, _, F1 = score([answer], [ground_truth], lang='en', verbose=False)\n","        total_bert_score += F1.item()\n","\n","        # METEOR\n","        meteor = meteor_score([reference_tokens], hypothesis_tokens)\n","        total_meteor_score += meteor\n","\n","        # BLEU\n","        bleu_score = sentence_bleu([reference_tokens], hypothesis_tokens, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=None)\n","        total_bleu_score += bleu_score\n","\n","        # ROUGE\n","        rouge = Rouge()\n","        rouge_scores = rouge.get_scores(answer, ground_truth)[0]\n","        for metric, scores in rouge_scores.items():\n","            total_rouge_score[metric] += scores['f']\n","\n","    average_bert_score = total_bert_score / num_results\n","    average_meteor_score = total_meteor_score / num_results\n","    average_bleu_score = total_bleu_score / num_results\n","    average_rouge_score = {metric: score / num_results for metric, score in total_rouge_score.items()}\n","\n","    return average_bert_score, average_meteor_score, average_bleu_score, average_rouge_score\n","\n","\n","def load_results(file_path):\n","    try:\n","        with open(file_path, \"r\") as f:\n","            results = json.load(f)\n","        return results\n","    except FileNotFoundError:\n","        print(\"File not found:\", file_path)\n","    except json.JSONDecodeError:\n","        print(\"Invalid JSON format in file:\", file_path)\n","    return []\n","\n","\n","average_bert_score, average_meteor_score, average_bleu_score, average_rouge_score = calculate_scores(ground_truth, answer)\n","\n","# Print average scores\n","print(\"Average BERTScore:\", average_bert_score)\n","print(\"Average METEOR score:\", average_meteor_score)\n","print(\"Average BLEU score:\", average_bleu_score)\n","print(\"Average Rouge score:\", average_rouge_score)\n","\n"]},{"cell_type":"markdown","source":["Analyze and evaluate this result\n","\n","\n","These results are an evaluation of the model performance. The following is an analysis and evaluation for each indicator:\n","\n","Average BERTScore (0.84):\n","BERTScore is a metric used to measure the semantic similarity between the generated text and the reference text. It uses the pre-trained BERT model to encode the sentences and calculate the similarity score between them. The average BERTScore here is 0.8682, indicating that the semantic similarity between the text generated by the model and the reference text is high.\n","\n","Average METEOR Score (0.32):\n","The METEOR score is another metric for evaluating the quality of machine translation. It takes into account word-level alignment as well as sentence-level semantic similarity. The average METEOR score is 0.3815, which is relatively high, indicating that the text generated by the model is consistent with the reference text to a certain extent.\n","\n","Average BLEU Score (0.0868):\n","The BLEU score is used to evaluate the quality of machine translation, and its range is usually between 0 and 1, where 1 indicates a perfect match. The average BLEU score here is about 0.1394, which means that the match between the text generated by the model and the reference text is relatively low. Possible reasons include differences in vocabulary selection, syntactic structure, etc.\n","\n","Average Rouge Score:\n","ROUGE scores are used to evaluate the degree of overlap between the generated text and the reference text, including word-level and sentence-level overlap. The average scores of the three ROUGE indicators are provided here:\n","\n","rouge-1: The average value is about 0.321, indicating that the overlap between the single words generated by the model and the single words in the reference text is good.\n","\n","rouge-2: The average value is about 0.124, indicating that the overlap between the phrases composed of two words generated by the model and the phrases in the reference text is low.\n","\n","rouge-l: The average value is about 0.295, indicating that the length of the longest common subsequence between the text generated by the model and the reference text is high, that is, the overlap at the sentence level is good.\n","\n","Overall, the model performs well in terms of semantic similarity (high METEOR and BERTScore), but there may be room for improvement in terms of word and phrase-level overlap (relatively low BLEU and ROUGE scores). Possible improvements include model tuning, better training data, improved generation strategies, etc."],"metadata":{"id":"Ac4gGixVSlC5"}},{"cell_type":"markdown","metadata":{"id":"gcrji3tPwe2Y"},"source":["## Use model for question answering"]},{"cell_type":"code","source":["prompt_template: str = \"\"\"\n","You are a helpful, respectful and honest assistant. \\\n","Your task is to generate an answer to the given question. \\\n","And your answer should be based on the provided context only.\n","\n","### input: {prompt}\n","\n","### Answer:\n","\"\"\""],"metadata":{"id":"nhOB6n-gRxbo","executionInfo":{"status":"ok","timestamp":1733523161577,"user_tz":300,"elapsed":135,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["model_path = '/content/drive/MyDrive/project-kalki/mistral-7b-ml/api_experiment_run/model/model_weights'\n","tokenizer: LlamaTokenizerFast = AutoTokenizer.from_pretrained(\n","  pretrained_model_name_or_path = model_path,\n","  trust_remote_code=True,\n","  padding_side=\"left\"\n",")\n","\n","bnb_config_samsum_fine_tuned_model: BitsAndBytesConfig = BitsAndBytesConfig()\n","\n","model_load: MistralForCausalLM = AutoModelForCausalLM.from_pretrained(\n","    pretrained_model_name_or_path=model_path,\n","    # torch_dtype=torch.float16,\n","    trust_remote_code=True,\n","    device_map=\"auto\",\n","    quantization_config=bnb_config_samsum_fine_tuned_model,\n","    # low_cpu_mem_usage=True\n",")\n","\n","generator: TextGenerationPipeline = transformers.pipeline(\n","    task=\"text-generation\",\n","    tokenizer=tokenizer,\n","    model=model_load,\n","    # torch_dtype=torch.float16,\n","    device_map=\"auto\",\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":574,"referenced_widgets":["9b88f3ce179f4535a268db64112b4044","76e386f537924548af1d9ea8d63bf9a9","8e0f1e74824643e1b5fdcd7d6a324e04","e72056efa8c34775ab19f3facdc5081b","77ec2390dde346ce9a011b9d17c2f25d","f896fef8482540faa5250a970bab70cd","1582241783354acd82436af30d0773e3","9d455eabab4b46b4aa5b187b9094ad66","4ec294ddd0ce4c46b6d02db223fbb31b","68ae5e6ac94a479ba6090ff5d16a5784","b73f6508deef4771b0bb582adefddd07","46d2f9dd666a4073980aa390d99f4a10","ed0227e154dc4f38bcccc66fad240472","1d10c1add57e4b58984e0a1bf3818c5e","a3df28712a2047e59d3b0c878316c5ac","56a9e33e98284e88a0c1af98bb91b600","96f36b53bb0d4097a5f6337e8de269a3","3e7b2c0bbe8b43a8873a6376bfa9a48b","c640fdaeab0045eeb2ce77fc9a3e5d75","d922c6a2cc2a49f4ac4cba6a28e4a1f9","2a677463e5a444488ac8a4226ff6eab4","eca8f026f13c47e39a60412b00ab2e28","0909b910140c4905b3b03706ebebae63","ac040bbb434942aba232e41a73e9a176","a00b51b8399146949d96d73029f8b7c4","788f48a019584c29afd4ef936e63c8ea","c2915605623149c1a7d1d95678a6467b","dbb5fd4896b1417d92acd6ed41ffe572","efd576a05fb44df491b91978f5381a8a","335c87961d2f4287aa4a82d106ea1bcd","66030e453288483daff58b81037c6029","7a5a1297ce9d409da53e344a06e1472a","bfb06a640f9840539e7c5bdb469b2a23","ff72579058b64c61a81b7e635a00314c","39bb058abec1409ab925e5e2531359d5","71125613d760417689852ac45bf710a6","b2267a160b8c4ba280a91944d1cbd66b","41dbb10d19d540c7b596fd7fd79f0a26","64706ceb4b02440ba011c6225c09679f","c2e62a434c774332a1ede5ede3dfdc63","7bed2ce31e2c4457a1b7802c704ad007","d4639e4e83b3464c9686d4309847a0bc","e4538d5230fa4f7c947270eaef782186","f1a928b4f9074f319f3450245a6d70e4","2ffc2fa0ac2f4cc08eb1e814ee9d892e","393e57fe3cd048dfa2bf21f51d5cc2d2","dfb4a254ecf441918b6815217fcc1990","cb0daca8081b49da930a4fbe018619e7","97efa60ab79f430aa9fdfd64472f00d2","60bc5ebbf4b84fb481b51091e9e874c1","83c36d464d024c6badcd55f36ee09744","4b97d5cdf7664be8ae0305e86ab6582d","6005f9be7c5945e0a2e8d9019d68338f","5250b887bfb0460a806c105bd485dc74","2ea16ea5ba1c404fb2608bdd60c78685","3f9151c0890e448f94045b87ab40e511","d2e080d58c6b4d04a32e01247259d53f","8a46b8de8c6140bbb21fe1179cdf1a04","a6e04eaac5b04edaa0a685c74ee652d0","9ea724316a8b418e962050966ccade0c","3cb248c8089140a99b55efba78537db0","20efbb2ce6e34646a200d5d6f69b8f17","18b5771eb38c42c2813134d886ae0075","0769f685be7f4026ae386b9a7eaf39e4","afdbf022e26c42068bac653cc5cd0759","9f3b1a45501d458d9c78393273f5ee89","1eb6c18f8d9246dfb372397f9fff7561","98df946577cd4cd9a763fa5f2c7cc5d9","050ff746ede2454b8a0e2d047a6a2f05","505eac55eae945c3b8be9cada6c201c7","124adef03fe74af89ddec5166db30241","693f0c7ac9de4f0cb458d1bc1f301646","7c250c0bd4874a5ab91b1e45f1e9a240","992fe5b2bc4e45258a1ce60cfb6e56db","dd31e8c0d4e14925974885a9befca88a","a67e2195a6c9484d938d11a89c125baa","26e1e0a138d840a3912592f4214134f7","13f99b77cf504a34b2379b0f6f064004","a5d62015caeb4491acc81426a0f2ffa6","8e28352fba924c2f8b2241be28b6cd2c","921482a36fab455c8b017ba522a24659","a3696bd03d724459824ea3da9930b046","48121fc621df4fd49f34cf1848add391","10ddca7ae73446acb2a868d0ae11bd52","9c671508fe584bd98ace8264345de3ed","42b8b8dd5ebf495bb44b9d6590fd17c1","4e297a86303b42bc8e6b34e07b363856","f21fa2310e9f495ea6d60f130101bc68","d8b0bcc60b804a1b8e3fdc5fda115b3c","7429356ef2d34f2bb0fdfa2b669e6404","f4c1579497be42f08916a7fd5ac41d6c","2cb73cfe05184ef7a50b7f406a3a2ff9","d9812d18c72c421386fbb45063788a7a","169a47fb130f455d98eac87816f2fdc5","b402b7a562d74478955b6d09fffd911e","18fd924786aa417aa210d966c2738155","47af062a92da46ebbacc6eb33b459ddc","1fd113de59a740de8d4ec4d2bc6adf8c","32e3190ade0a4633857d73f27257de3f","baca5bbaf6b047b6a5bc91179ac6e60f","cbf1bf06747c4721b3d399afbbb96ecd","8d708b2b8a154cc884df08e052913503","02a8e76f707b4521a2dd7076edf0471d","97eb7c4ab8f8473fa0612da5f271e8e8","097818d627e3446099743c8f55f56a66","1b88e20848c241b18e33b110989dd9ec","ff8ca5890f0c4c279ffea2f9a9e1608f","b735c332920943a9b811b094560436c0","9e7a4d1e37624543940a56fcca95d0e9","aa275ffa78a24a51bc6e09e5732a3e07","8fc95fd2ebbc4578a3172d6364fb51bd","31e57b57dd3d463499ffdee955fc57e1","df37dc54c91246a28d700bf225118ded","3cb90f26991944f6bb4fcade0311928f","cdb899e096584788a633b7c8cde0cdf1","1721f517190045f898be0cbf2868c280","b4beb6b7949742b883117a1bf146f519","15454751bdfe4f44b9479da7fecc65f9","4b65a058572241039f82495d4c8419ec","299782287d00421b822d7dbfa60ef53e","f7c3778cc3eb43fe89eb432073537899","7a45618cbc074a698042fb2b88540841","ab9d7f8518094f048a9fbbae5f2f9248","f82288eb334e47a8b9b43fdbcc9c9c34","f6c49938e1604977beafcbf6029f7573","893080d3b0cd410a84fd17f508145719","8c5d628b80794f8ca8115a384602ba9e","ba77a5a3f10a4974b5e900e3868f0b1b","a5538af4e5c743f7a54916729d81713b","46852ac449c04a28b234fcb892f43e2c","d83581db0e1146be95868f340c0831ad","c082ea898edc4b28934b57c408c7315d","d4b813486208417eb30ff1ac172b3d93","7ef7a8daa06b4596ba57c0c186053622","19e0c73a56f740d097416540c1cb485d","dd3ddc5b4d8d4f16ba629b489e042b00","7920394f6a5349ecb3dc8f2b0ca9a4c2","a41852720a5f4c28922c8da43b0b3188","94778f44c7c04209bc4eca233796fb93","2c814d25136e43d68180570e1232a208","5d74b90a682f4debb09c6fd45e53a3b9","ef0ad3d9033d4b418e08460ec8661a32","8b4b84a3e87a4be6aae1c8ebde8867e6"]},"id":"3mG52RckpaUO","executionInfo":{"status":"ok","timestamp":1733523257478,"user_tz":300,"elapsed":94589,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"7f45dbbc-1ca6-4985-a4dc-aaca24a95999"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/613 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b88f3ce179f4535a268db64112b4044"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46d2f9dd666a4073980aa390d99f4a10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading shards:   0%|          | 0/8 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0909b910140c4905b3b03706ebebae63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00001-of-00008.safetensors:   0%|          | 0.00/1.89G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff72579058b64c61a81b7e635a00314c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00002-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ffc2fa0ac2f4cc08eb1e814ee9d892e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00003-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f9151c0890e448f94045b87ab40e511"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00004-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1eb6c18f8d9246dfb372397f9fff7561"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00005-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13f99b77cf504a34b2379b0f6f064004"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00006-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8b0bcc60b804a1b8e3fdc5fda115b3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00007-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"baca5bbaf6b047b6a5bc91179ac6e60f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00008-of-00008.safetensors:   0%|          | 0.00/816M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fc95fd2ebbc4578a3172d6364fb51bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a45618cbc074a698042fb2b88540841"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4b813486208417eb30ff1ac172b3d93"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n"]}]},{"cell_type":"code","source":["def infer(user_input):\n","  prompt = prompt_template.format(prompt=user_input)\n","  print(prompt)\n","  return generator(user_input)[0]['generated_text']\n","\n","while True:\n","  user_input = input('Please enter question for an article: ')\n","\n","  if user_input == 'exit':\n","    break\n","\n","  print(infer(user_input))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e8ww8jyw-Qbh","executionInfo":{"status":"ok","timestamp":1733523371207,"user_tz":300,"elapsed":106835,"user":{"displayName":"ForRandom Purposes","userId":"00828454029084065659"}},"outputId":"767978f3-5a2a-4926-a018-5579e7ca32ce"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Please enter question for an article: What is the methodology used in IoT Data Analytics Using Deep Learning?\n","\n","You are a helpful, respectful and honest assistant. Your task is to generate an answer to the given question. And your answer should be based on the provided context only.\n","\n","### input: What is the methodology used in IoT Data Analytics Using Deep Learning?\n","\n","### Answer:\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:451: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["What is the methodology used in IoT Data Analytics Using Deep Learning?\n","\n","The methodology used in IoT Data Analytics Using Deep Learning is as follows:\n","\n","Please enter question for an article: What is the purpose of the xGEWFI metric?\n","\n","You are a helpful, respectful and honest assistant. Your task is to generate an answer to the given question. And your answer should be based on the provided context only.\n","\n","### input: What is the purpose of the xGEWFI metric?\n","\n","### Answer:\n","\n","What is the purpose of the xGEWFI metric?\n","\n","The xGEWFI metric is a measure of the amount of work done by the GPU\n","Please enter question for an article: What is NegatER and how does it work?\n","\n","You are a helpful, respectful and honest assistant. Your task is to generate an answer to the given question. And your answer should be based on the provided context only.\n","\n","### input: What is NegatER and how does it work?\n","\n","### Answer:\n","\n","What is NegatER and how does it work?\n","\n","NegatER is a new, patented technology that uses a proprietary blend of ingredients\n","Please enter question for an article: What is DeepChrome and how does it improve gene expression prediction?\n","\n","You are a helpful, respectful and honest assistant. Your task is to generate an answer to the given question. And your answer should be based on the provided context only.\n","\n","### input: What is DeepChrome and how does it improve gene expression prediction?\n","\n","### Answer:\n","\n","What is DeepChrome and how does it improve gene expression prediction?\n","\n","DeepChrome is a deep learning model that predicts gene expression from DNA sequence. It\n","Please enter question for an article: What is SS-VFNAS in the context of FL?\n","\n","You are a helpful, respectful and honest assistant. Your task is to generate an answer to the given question. And your answer should be based on the provided context only.\n","\n","### input: What is SS-VFNAS in the context of FL?\n","\n","### Answer:\n","\n","What is SS-VFNAS in the context of FL?\n","\n","SS-VFNAS is a new feature in the context of FL. It is a\n","Please enter question for an article: What is the core idea behind RANP algorithm?\n","\n","You are a helpful, respectful and honest assistant. Your task is to generate an answer to the given question. And your answer should be based on the provided context only.\n","\n","### input: What is the core idea behind RANP algorithm?\n","\n","### Answer:\n","\n","What is the core idea behind RANP algorithm?\n","\n","RANP is a simple algorithm that uses a random number generator to select a random number from\n","Please enter question for an article: What is Pisces in the context of federated learning?\n","\n","You are a helpful, respectful and honest assistant. Your task is to generate an answer to the given question. And your answer should be based on the provided context only.\n","\n","### input: What is Pisces in the context of federated learning?\n","\n","### Answer:\n","\n","What is Pisces in the context of federated learning?\n","\n","Pisces is a federated learning framework that enables the training of machine learning models on\n","Please enter question for an article: exit\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a05724730a7a415ab7af8db862d3e505":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_34fa3e9490664fdba73c4c818286bf77","IPY_MODEL_7b3dfbd8d6024dcd81076e4da309db7b","IPY_MODEL_abe51d0a5c1d404db0a605251b401f4e"],"layout":"IPY_MODEL_06d9a5dd57e1437f9cdbc7270f454cb3"}},"34fa3e9490664fdba73c4c818286bf77":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bf6ac56f95f4c4fbb21058f3cc4ce6e","placeholder":"​","style":"IPY_MODEL_19eef296a40c4a3ea81b5826eb7a4df4","value":"tokenizer_config.json: 100%"}},"7b3dfbd8d6024dcd81076e4da309db7b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5695550fa392471cae25fb163a752d62","max":979,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4f7557b1b9ee45e48fdcfe251ae9b303","value":979}},"abe51d0a5c1d404db0a605251b401f4e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_385b9510303344fc8339242b44659f45","placeholder":"​","style":"IPY_MODEL_36dc11f8a86748e99442a5f7c5be366d","value":" 979/979 [00:00&lt;00:00, 55.3kB/s]"}},"06d9a5dd57e1437f9cdbc7270f454cb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bf6ac56f95f4c4fbb21058f3cc4ce6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19eef296a40c4a3ea81b5826eb7a4df4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5695550fa392471cae25fb163a752d62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f7557b1b9ee45e48fdcfe251ae9b303":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"385b9510303344fc8339242b44659f45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36dc11f8a86748e99442a5f7c5be366d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5710d16a012465ebfc3edc463504f6f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fb25215a94444102a67b0e1c158c3be7","IPY_MODEL_66ed4e490556475e98940f157d6aafa0","IPY_MODEL_65b1fe5f7f06417faeaa5d7d03aa2c8a"],"layout":"IPY_MODEL_cc35192dbd134142a91f4406a8bdb6a2"}},"fb25215a94444102a67b0e1c158c3be7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f09d590f7c14298a3a77c3b00c1efb2","placeholder":"​","style":"IPY_MODEL_d6d5ace09beb43a698f1ddedce5f4e32","value":"tokenizer.model: 100%"}},"66ed4e490556475e98940f157d6aafa0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d314a34882d4303bb9bfb90d9f08b36","max":493443,"min":0,"orientation":"horizontal","style":"IPY_MODEL_713101fa63844843947b1dbae1c39d2b","value":493443}},"65b1fe5f7f06417faeaa5d7d03aa2c8a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5113c790c0254143b8ea0ff86943edd2","placeholder":"​","style":"IPY_MODEL_5d24cf7c05bc456e98e30db6007e8fb3","value":" 493k/493k [00:00&lt;00:00, 11.0MB/s]"}},"cc35192dbd134142a91f4406a8bdb6a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f09d590f7c14298a3a77c3b00c1efb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6d5ace09beb43a698f1ddedce5f4e32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d314a34882d4303bb9bfb90d9f08b36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"713101fa63844843947b1dbae1c39d2b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5113c790c0254143b8ea0ff86943edd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d24cf7c05bc456e98e30db6007e8fb3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"610a97830ba3454d805891b88547335a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_33fd4b54ceb44cf1af31a79f28fc9a13","IPY_MODEL_a60c28e90621492cbc225ccce28c752a","IPY_MODEL_a19e334fe2d148b696294e63b7672635"],"layout":"IPY_MODEL_3e7863460f4f4dc99b205d5e89c03cde"}},"33fd4b54ceb44cf1af31a79f28fc9a13":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c03a9856f1fc42169a22bbe9cb41dcdd","placeholder":"​","style":"IPY_MODEL_44c1af84c70f4f8a94ce790d665b150a","value":"tokenizer.json: 100%"}},"a60c28e90621492cbc225ccce28c752a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_41237312266b4f3ebafe3b1fee6b1ee2","max":1795303,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3286f37f359345b1a1b3457c22a8a060","value":1795303}},"a19e334fe2d148b696294e63b7672635":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_452f60e40052417ea83f80dad26b8302","placeholder":"​","style":"IPY_MODEL_36f82b4173004c6cbc23bab398855d34","value":" 1.80M/1.80M [00:00&lt;00:00, 5.56MB/s]"}},"3e7863460f4f4dc99b205d5e89c03cde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c03a9856f1fc42169a22bbe9cb41dcdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44c1af84c70f4f8a94ce790d665b150a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"41237312266b4f3ebafe3b1fee6b1ee2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3286f37f359345b1a1b3457c22a8a060":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"452f60e40052417ea83f80dad26b8302":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36f82b4173004c6cbc23bab398855d34":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a983705248f4a3f8083d34d1c90cdca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_60c68ff5bac14c3480359ade2deb670a","IPY_MODEL_a7150b75370c47ceb15e03c765df129b","IPY_MODEL_6f86bd0b97ef4c06972b7402168e920b"],"layout":"IPY_MODEL_41a30f6d45cf405693414265803d0db0"}},"60c68ff5bac14c3480359ade2deb670a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_02ef487206c141a7bebbba868bbbb4f5","placeholder":"​","style":"IPY_MODEL_07978a543ee3405a9a2838e692918902","value":"added_tokens.json: 100%"}},"a7150b75370c47ceb15e03c765df129b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9aada266800946e3a55a9f3d03d03f8a","max":42,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dd611c9b6e61468c94490c5c051771b8","value":42}},"6f86bd0b97ef4c06972b7402168e920b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a8eab0ee30a41ddb8be19b72d360e71","placeholder":"​","style":"IPY_MODEL_4aed28b4a9fa460e8513e7eb3917ccad","value":" 42.0/42.0 [00:00&lt;00:00, 3.29kB/s]"}},"41a30f6d45cf405693414265803d0db0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02ef487206c141a7bebbba868bbbb4f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07978a543ee3405a9a2838e692918902":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9aada266800946e3a55a9f3d03d03f8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd611c9b6e61468c94490c5c051771b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1a8eab0ee30a41ddb8be19b72d360e71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4aed28b4a9fa460e8513e7eb3917ccad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"216c7a8387704e2496e2532d38883c64":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b0ab48c41f6748beae80976d16ba073e","IPY_MODEL_35b55bcecfc048178732ee709a551b61","IPY_MODEL_f692235250f246919c12cdec197b58af"],"layout":"IPY_MODEL_e5ee6c3131d7472cb6861fa4f9299256"}},"b0ab48c41f6748beae80976d16ba073e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20e4c384343a49ac8921f1ab8225b43d","placeholder":"​","style":"IPY_MODEL_8ee9df82ed0343b3909231db317eb831","value":"special_tokens_map.json: 100%"}},"35b55bcecfc048178732ee709a551b61":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d78b94045d964de49b7de261c5b12f4d","max":145,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4361eac03073461a8dfce4dc885dcf47","value":145}},"f692235250f246919c12cdec197b58af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0c2c9ef4c764e429d0ade4675e3270c","placeholder":"​","style":"IPY_MODEL_4200466a574a4778a3ff43a8db6b7142","value":" 145/145 [00:00&lt;00:00, 10.7kB/s]"}},"e5ee6c3131d7472cb6861fa4f9299256":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20e4c384343a49ac8921f1ab8225b43d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ee9df82ed0343b3909231db317eb831":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d78b94045d964de49b7de261c5b12f4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4361eac03073461a8dfce4dc885dcf47":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a0c2c9ef4c764e429d0ade4675e3270c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4200466a574a4778a3ff43a8db6b7142":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8702eb8c5efb46ca8af58040170699cf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_de2a6332b3bd4f8a97b650154f7a3041","IPY_MODEL_3ffca27761624f05838b38fb76d1afb9","IPY_MODEL_f319c6c96103497cbe2b296b3fb91a0c"],"layout":"IPY_MODEL_6bfe4675d6564260aee805bf01660a7d"}},"de2a6332b3bd4f8a97b650154f7a3041":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f00ca61f1244af9b508ca050977db01","placeholder":"​","style":"IPY_MODEL_db795a679d6c45f1a060db093194e6cc","value":"config.json: 100%"}},"3ffca27761624f05838b38fb76d1afb9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0c97d52de434e978f1f5763fda661b7","max":613,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4f74512dd9c1450cb5893c83d63664de","value":613}},"f319c6c96103497cbe2b296b3fb91a0c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0141279b0e814296b5e45054501b2f74","placeholder":"​","style":"IPY_MODEL_0a08461d6e8c4136bfef137b7b9bd044","value":" 613/613 [00:00&lt;00:00, 55.8kB/s]"}},"6bfe4675d6564260aee805bf01660a7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f00ca61f1244af9b508ca050977db01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db795a679d6c45f1a060db093194e6cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f0c97d52de434e978f1f5763fda661b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f74512dd9c1450cb5893c83d63664de":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0141279b0e814296b5e45054501b2f74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a08461d6e8c4136bfef137b7b9bd044":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"833932ecaeeb42b5ae9729b82c8c357f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_63250724ace942869d985b198102b438","IPY_MODEL_921c8a09166147dc97055f4807551662","IPY_MODEL_754c61a4fe4848ad80a05528382096e4"],"layout":"IPY_MODEL_b3de4b4386aa4028bf25fa98e618c4c9"}},"63250724ace942869d985b198102b438":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_627a40d11edc4cedb16df29efa6b4641","placeholder":"​","style":"IPY_MODEL_936e404bb9e049c9b6a21763443fde5f","value":"model.safetensors.index.json: 100%"}},"921c8a09166147dc97055f4807551662":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c43a5440053a4a7689016d9ab0bb61cc","max":25125,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dab9faeca049469bbd92ee52af4044c1","value":25125}},"754c61a4fe4848ad80a05528382096e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18cf10f1f5c848d9b90a7267c6b65dcb","placeholder":"​","style":"IPY_MODEL_22acde4520524d2e88a840e1b5e792e6","value":" 25.1k/25.1k [00:00&lt;00:00, 2.05MB/s]"}},"b3de4b4386aa4028bf25fa98e618c4c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"627a40d11edc4cedb16df29efa6b4641":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"936e404bb9e049c9b6a21763443fde5f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c43a5440053a4a7689016d9ab0bb61cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dab9faeca049469bbd92ee52af4044c1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"18cf10f1f5c848d9b90a7267c6b65dcb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22acde4520524d2e88a840e1b5e792e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e86121c898e449783ef3eb0996449b2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4574f4cc61be4f11b879e33bb825d2e0","IPY_MODEL_cea0d8c65f4643388095d20bf0c6f531","IPY_MODEL_cfd8eb5389374dccb9d460d286cf85bd"],"layout":"IPY_MODEL_b108c0043b734eeaab9feabc9baad93b"}},"4574f4cc61be4f11b879e33bb825d2e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eabb877de0354b4480635991a9b061c7","placeholder":"​","style":"IPY_MODEL_d6723f1275354507a67e8be9a98172ba","value":"Downloading shards: 100%"}},"cea0d8c65f4643388095d20bf0c6f531":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_520e10173211439c852ea11e066ed9ee","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a07d51f44a14b1a82c3cbef11451873","value":8}},"cfd8eb5389374dccb9d460d286cf85bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c5b15781cff4c3abe2a79f901aeb333","placeholder":"​","style":"IPY_MODEL_169d3f328d3e446fb8b0feb3e131515f","value":" 8/8 [01:07&lt;00:00,  7.41s/it]"}},"b108c0043b734eeaab9feabc9baad93b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eabb877de0354b4480635991a9b061c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6723f1275354507a67e8be9a98172ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"520e10173211439c852ea11e066ed9ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a07d51f44a14b1a82c3cbef11451873":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1c5b15781cff4c3abe2a79f901aeb333":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"169d3f328d3e446fb8b0feb3e131515f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5530a7038e1f4af486648740f9ce4465":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_69206a686ff5479a92ade28314ba6f37","IPY_MODEL_8a20b6d00cd34e72b63a11ac274b09a0","IPY_MODEL_bb9a004059dd4838a464fe4108afbfb9"],"layout":"IPY_MODEL_cf7e9e7b7a064aadbc7c3eb1799ae417"}},"69206a686ff5479a92ade28314ba6f37":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f2b3f6d2d364864bc8563c9a03ae8a8","placeholder":"​","style":"IPY_MODEL_ff6ecd33f1684cf4af134d62895f766c","value":"model-00001-of-00008.safetensors: 100%"}},"8a20b6d00cd34e72b63a11ac274b09a0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_14f443f7325e4c3892570779ef4be06d","max":1889587008,"min":0,"orientation":"horizontal","style":"IPY_MODEL_538058e0f2b0457c90ffd6ae81f395a9","value":1889587008}},"bb9a004059dd4838a464fe4108afbfb9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dda06e9443a94cffb5cdc1c2c8ee2865","placeholder":"​","style":"IPY_MODEL_91042148af3c40a4a5128ca27b882029","value":" 1.89G/1.89G [00:08&lt;00:00, 239MB/s]"}},"cf7e9e7b7a064aadbc7c3eb1799ae417":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f2b3f6d2d364864bc8563c9a03ae8a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff6ecd33f1684cf4af134d62895f766c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14f443f7325e4c3892570779ef4be06d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"538058e0f2b0457c90ffd6ae81f395a9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dda06e9443a94cffb5cdc1c2c8ee2865":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91042148af3c40a4a5128ca27b882029":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c591665bdcf4533ab6379dbaa34ccbf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_59d2fd9e208b4185938270e8a7e59d95","IPY_MODEL_706b88adf2b24354a9a83ed52106f395","IPY_MODEL_71d4fad2538241a0a536fcac56f3df19"],"layout":"IPY_MODEL_372ed234333b4bb5b73b3bd48fc05705"}},"59d2fd9e208b4185938270e8a7e59d95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_382eeff53b524d78a1c78ff4c8dce8bd","placeholder":"​","style":"IPY_MODEL_3741fe46e9a34092bc32ec0c32cfdbe0","value":"model-00002-of-00008.safetensors: 100%"}},"706b88adf2b24354a9a83ed52106f395":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3da5ed33df2b43618c821ee948e78e6c","max":1946243896,"min":0,"orientation":"horizontal","style":"IPY_MODEL_04b37c556f154974ac1e0050690b3b29","value":1946243896}},"71d4fad2538241a0a536fcac56f3df19":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6753a0ef737e429292f5cfaeeb2dfd57","placeholder":"​","style":"IPY_MODEL_058a2bcaf0ea452a92593a42624d1809","value":" 1.95G/1.95G [00:08&lt;00:00, 200MB/s]"}},"372ed234333b4bb5b73b3bd48fc05705":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"382eeff53b524d78a1c78ff4c8dce8bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3741fe46e9a34092bc32ec0c32cfdbe0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3da5ed33df2b43618c821ee948e78e6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04b37c556f154974ac1e0050690b3b29":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6753a0ef737e429292f5cfaeeb2dfd57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"058a2bcaf0ea452a92593a42624d1809":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95c3654336ff414190348124eb61a675":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4a71a5adbf4449c19ef0c21d7d5550f7","IPY_MODEL_9a0abaecdb294100a52f0e9fc0d33d04","IPY_MODEL_4c8843cea9514b7884ad52fe36e6ca4e"],"layout":"IPY_MODEL_66c2d6e6cb304d06bf5833c89b055d6c"}},"4a71a5adbf4449c19ef0c21d7d5550f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca7ff5f5ba95419bb70744fe42fa4f17","placeholder":"​","style":"IPY_MODEL_35af4ce5bf834426913ac27f7d2cb3db","value":"model-00003-of-00008.safetensors: 100%"}},"9a0abaecdb294100a52f0e9fc0d33d04":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2636799ed5c4f0bb0b596997389f644","max":1979781392,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cfca7bb2ea284ae78286b8c4ac74221f","value":1979781392}},"4c8843cea9514b7884ad52fe36e6ca4e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_72a50ed3208b4010868ae8232a57f975","placeholder":"​","style":"IPY_MODEL_8ccd92f0f8f54e6ab52754d05aa87513","value":" 1.98G/1.98G [00:08&lt;00:00, 217MB/s]"}},"66c2d6e6cb304d06bf5833c89b055d6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca7ff5f5ba95419bb70744fe42fa4f17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35af4ce5bf834426913ac27f7d2cb3db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2636799ed5c4f0bb0b596997389f644":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfca7bb2ea284ae78286b8c4ac74221f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"72a50ed3208b4010868ae8232a57f975":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ccd92f0f8f54e6ab52754d05aa87513":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aaba891125b24cbeadbf578b156fe04e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_08c554aa2a284d25b88c84deea0d3dce","IPY_MODEL_675ddee4640c4bab856f3c3c7b560d40","IPY_MODEL_926a6e4a250648eaa38c8c47e4967de5"],"layout":"IPY_MODEL_db22b102b63e4da09f3fd43cd9348872"}},"08c554aa2a284d25b88c84deea0d3dce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a9cc0bfde02417d94281e86f758f110","placeholder":"​","style":"IPY_MODEL_6ecdd0e9ba264eec977ed9984e69f306","value":"model-00004-of-00008.safetensors: 100%"}},"675ddee4640c4bab856f3c3c7b560d40":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae134d80724b4d188daa4577b44f2f21","max":1946243936,"min":0,"orientation":"horizontal","style":"IPY_MODEL_51afa76f98524837ab3b2cfdb6b17e8b","value":1946243936}},"926a6e4a250648eaa38c8c47e4967de5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b15eb129959446cbef815a21f197eab","placeholder":"​","style":"IPY_MODEL_b7ffa0186cd54793808b559ad28aa8f9","value":" 1.95G/1.95G [00:08&lt;00:00, 201MB/s]"}},"db22b102b63e4da09f3fd43cd9348872":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a9cc0bfde02417d94281e86f758f110":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ecdd0e9ba264eec977ed9984e69f306":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae134d80724b4d188daa4577b44f2f21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51afa76f98524837ab3b2cfdb6b17e8b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3b15eb129959446cbef815a21f197eab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7ffa0186cd54793808b559ad28aa8f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa8cde51d20a4cb99414922dcce2f5dd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dd9634581edf4016bc98c848dd2dedf4","IPY_MODEL_308d4fc8f1ea402e817919ba719ac454","IPY_MODEL_679b3997c2cf45278eec38d4a295fac8"],"layout":"IPY_MODEL_a2e88a8cb1ae48f28716e4e405abb366"}},"dd9634581edf4016bc98c848dd2dedf4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55965a5b994a4a8aa1cb56e0cbfea4b4","placeholder":"​","style":"IPY_MODEL_971bf7aac9334c2b8cd6a09700b2d7a5","value":"model-00005-of-00008.safetensors: 100%"}},"308d4fc8f1ea402e817919ba719ac454":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c24c2e1bf02e403da8c39e491c433c24","max":1979781416,"min":0,"orientation":"horizontal","style":"IPY_MODEL_32c209fc83814608a805bb3fa961c4b1","value":1979781416}},"679b3997c2cf45278eec38d4a295fac8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6438b1869dd4434f8fe0b70f652f9373","placeholder":"​","style":"IPY_MODEL_6bfcce40cc7a434da9a9db0fd3e9b66d","value":" 1.98G/1.98G [00:08&lt;00:00, 213MB/s]"}},"a2e88a8cb1ae48f28716e4e405abb366":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55965a5b994a4a8aa1cb56e0cbfea4b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"971bf7aac9334c2b8cd6a09700b2d7a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c24c2e1bf02e403da8c39e491c433c24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32c209fc83814608a805bb3fa961c4b1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6438b1869dd4434f8fe0b70f652f9373":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bfcce40cc7a434da9a9db0fd3e9b66d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e229c50a27ec4f99b0cd1cea6a8926d4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_256657eab905442da1fb72bae2ae91f4","IPY_MODEL_eb905f5635ab4040a4a8f6d6b01d7a43","IPY_MODEL_79abda371075460cafddbc104eefdb3b"],"layout":"IPY_MODEL_5ced73ab952a4ecda9d59a02cf7d26b0"}},"256657eab905442da1fb72bae2ae91f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_87b8d1318e2146a9b64b1d3fb5e739cd","placeholder":"​","style":"IPY_MODEL_5945633d202242e39e79688cb78f39b4","value":"model-00006-of-00008.safetensors: 100%"}},"eb905f5635ab4040a4a8f6d6b01d7a43":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a751f9c6dbd44c66848bf4eb25aaea10","max":1946243936,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1de69e26c7774ba3b5e8717914b38843","value":1946243936}},"79abda371075460cafddbc104eefdb3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c13a08b089204ae68a293b8f5eddb18f","placeholder":"​","style":"IPY_MODEL_0643b4402fe246efbcbd77a04f95d323","value":" 1.95G/1.95G [00:08&lt;00:00, 230MB/s]"}},"5ced73ab952a4ecda9d59a02cf7d26b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87b8d1318e2146a9b64b1d3fb5e739cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5945633d202242e39e79688cb78f39b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a751f9c6dbd44c66848bf4eb25aaea10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1de69e26c7774ba3b5e8717914b38843":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c13a08b089204ae68a293b8f5eddb18f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0643b4402fe246efbcbd77a04f95d323":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3bd592a4f88470d8d77ae3e4cd6c605":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_de193a8289554714a98aceb4eea8694e","IPY_MODEL_0a84921dd18a49b2a614a649ce3de0ca","IPY_MODEL_5e42e71e0b474864bcbca164abf26bdd"],"layout":"IPY_MODEL_77e0734acc75490aa07c05f07ba97318"}},"de193a8289554714a98aceb4eea8694e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3f570ea9cbe4a1389b57994c9d69377","placeholder":"​","style":"IPY_MODEL_5a16e525e54a4e6bac17175784721966","value":"model-00007-of-00008.safetensors: 100%"}},"0a84921dd18a49b2a614a649ce3de0ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0891b608965e4b21ad0427544158d24f","max":1979781416,"min":0,"orientation":"horizontal","style":"IPY_MODEL_37c6dc5d2f9f4c35bfcee4ea657be599","value":1979781416}},"5e42e71e0b474864bcbca164abf26bdd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fba787e7cff4bee905e135e6e561112","placeholder":"​","style":"IPY_MODEL_56a7062c886a4e509b60601b90596a2e","value":" 1.98G/1.98G [00:08&lt;00:00, 217MB/s]"}},"77e0734acc75490aa07c05f07ba97318":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3f570ea9cbe4a1389b57994c9d69377":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a16e525e54a4e6bac17175784721966":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0891b608965e4b21ad0427544158d24f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37c6dc5d2f9f4c35bfcee4ea657be599":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1fba787e7cff4bee905e135e6e561112":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56a7062c886a4e509b60601b90596a2e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a25521285b3947f9b2e58b7999afcd7b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5fb25628184642c0b1d5f103a9aaa908","IPY_MODEL_e6d0325e419b4d799f4c8c17bdcee52b","IPY_MODEL_735526d36988467fa0aea046f5307aa1"],"layout":"IPY_MODEL_7b08fdc0d20b4dd1ab093d206102e60d"}},"5fb25628184642c0b1d5f103a9aaa908":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2ce892b37374172a6145e483f802f4f","placeholder":"​","style":"IPY_MODEL_86150527479e44bca70cb19b6d47637a","value":"model-00008-of-00008.safetensors: 100%"}},"e6d0325e419b4d799f4c8c17bdcee52b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9951c75497e04a649fe16f8ec206f7fa","max":815834664,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e68de1acae524038ae13e438456dcd91","value":815834664}},"735526d36988467fa0aea046f5307aa1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76687d8786fd4e58a338d6e2c5eb8776","placeholder":"​","style":"IPY_MODEL_7334ea032fcc4f59a051937dec4884dc","value":" 816M/816M [00:03&lt;00:00, 238MB/s]"}},"7b08fdc0d20b4dd1ab093d206102e60d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2ce892b37374172a6145e483f802f4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86150527479e44bca70cb19b6d47637a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9951c75497e04a649fe16f8ec206f7fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e68de1acae524038ae13e438456dcd91":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"76687d8786fd4e58a338d6e2c5eb8776":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7334ea032fcc4f59a051937dec4884dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18f2ae2fdeca4b469eadfb221c58e869":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bf69432316924a0c897755b615cb121a","IPY_MODEL_ed7a163f059f4eb7b30623e77ab6703a","IPY_MODEL_93e6fb5864324a2fb740602bf0b356b5"],"layout":"IPY_MODEL_ee7d35f16e31455fb1fe7f770596a49d"}},"bf69432316924a0c897755b615cb121a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e6d10b448e445419691ad551acee8f6","placeholder":"​","style":"IPY_MODEL_70ee4592a0f24c2ca6b44a5bc0f9bd06","value":"Loading checkpoint shards: 100%"}},"ed7a163f059f4eb7b30623e77ab6703a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa4b901b1cd0487586dcacd05cc72023","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d80f216472c84dddabba87841a25b3ec","value":8}},"93e6fb5864324a2fb740602bf0b356b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc2eac70325a47b6a881545d31a1090e","placeholder":"​","style":"IPY_MODEL_91db8890ea9a4151be9359b7af887f8c","value":" 8/8 [00:06&lt;00:00,  1.28it/s]"}},"ee7d35f16e31455fb1fe7f770596a49d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e6d10b448e445419691ad551acee8f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70ee4592a0f24c2ca6b44a5bc0f9bd06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa4b901b1cd0487586dcacd05cc72023":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d80f216472c84dddabba87841a25b3ec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bc2eac70325a47b6a881545d31a1090e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91db8890ea9a4151be9359b7af887f8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec8a9a64c2a14ba1b2c81942303a5680":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e33cc6836980435ea99cf9abe8db9b9f","IPY_MODEL_557537fb7385469ba2d359c238b83370","IPY_MODEL_41cbee2bd397452ea52a9cbee8e07d84"],"layout":"IPY_MODEL_7b2bc1c92d3b45609956a9806d53c9be"}},"e33cc6836980435ea99cf9abe8db9b9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_274d42282936451c9e0c0742362f08c6","placeholder":"​","style":"IPY_MODEL_abcc37bb5c3c468aa376c78881a9234e","value":"generation_config.json: 100%"}},"557537fb7385469ba2d359c238b83370":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2626e3820994e68872e1066a8d2b0de","max":111,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3105bc87825740b68982e43f9c2d00b0","value":111}},"41cbee2bd397452ea52a9cbee8e07d84":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_63cb7a34f01741be862a99edb9f877c5","placeholder":"​","style":"IPY_MODEL_b4c6a9718c78418186c18d45952d09d5","value":" 111/111 [00:00&lt;00:00, 8.88kB/s]"}},"7b2bc1c92d3b45609956a9806d53c9be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"274d42282936451c9e0c0742362f08c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abcc37bb5c3c468aa376c78881a9234e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2626e3820994e68872e1066a8d2b0de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3105bc87825740b68982e43f9c2d00b0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"63cb7a34f01741be862a99edb9f877c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4c6a9718c78418186c18d45952d09d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4783cecf74a74aeda62909f75d20fed8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7df7915fdf5e4644a4db878d008ccf0f","IPY_MODEL_4e6dc21eeb0447a9988b21e22898e398","IPY_MODEL_1604159c666646c3b6c1ada5e53528e3"],"layout":"IPY_MODEL_2e89af410e2944028bc5e2e1c276dbab"}},"7df7915fdf5e4644a4db878d008ccf0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1ff674096bc40069275700cca8e1194","placeholder":"​","style":"IPY_MODEL_3f8e723f8ebf45089b408daa1ebfddc9","value":"Loading checkpoint shards: 100%"}},"4e6dc21eeb0447a9988b21e22898e398":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce43a3c8224546db9ecc4121e0d69581","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ee06e2a767ec4c45ace91ec3d9c547fa","value":8}},"1604159c666646c3b6c1ada5e53528e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bd7bf396db64a82a36619624bebda88","placeholder":"​","style":"IPY_MODEL_b35dfc6131e040c687e22287d38a606a","value":" 8/8 [00:07&lt;00:00,  1.14it/s]"}},"2e89af410e2944028bc5e2e1c276dbab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1ff674096bc40069275700cca8e1194":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f8e723f8ebf45089b408daa1ebfddc9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce43a3c8224546db9ecc4121e0d69581":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee06e2a767ec4c45ace91ec3d9c547fa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2bd7bf396db64a82a36619624bebda88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b35dfc6131e040c687e22287d38a606a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89dd96aa135645328243a78d3486a5b4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_41d14c2a186f4eaa8cb535cbd049bdb0","IPY_MODEL_3c61ca9faffe4978bd96864c89712866","IPY_MODEL_35e68241298847129d952ec69692141e"],"layout":"IPY_MODEL_60e51c65033144d99c16dc01b0ae8982"}},"41d14c2a186f4eaa8cb535cbd049bdb0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83fc5b8797f64c33b37e2121be3f5b64","placeholder":"​","style":"IPY_MODEL_59619972e39947c3a2cdae5c4bc15928","value":"tokenizer_config.json: 100%"}},"3c61ca9faffe4978bd96864c89712866":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_36027a643271418aaa9bc3f6369e375b","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b2684182487c4ab181f29a600d54662a","value":25}},"35e68241298847129d952ec69692141e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25537b11b57b4eb4b3ba3c3b96299798","placeholder":"​","style":"IPY_MODEL_86648516b8de4b6b97a2c15eda56eca2","value":" 25.0/25.0 [00:00&lt;00:00, 1.95kB/s]"}},"60e51c65033144d99c16dc01b0ae8982":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83fc5b8797f64c33b37e2121be3f5b64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59619972e39947c3a2cdae5c4bc15928":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36027a643271418aaa9bc3f6369e375b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2684182487c4ab181f29a600d54662a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"25537b11b57b4eb4b3ba3c3b96299798":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86648516b8de4b6b97a2c15eda56eca2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68b1725ba1374555bbf233ca893aff09":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2dfdc244d72e490aa45b7cd789eafc6d","IPY_MODEL_716e42ecc14246e9b9bf0466d0df0d55","IPY_MODEL_1761aeffa8424af1aa43dc021a915222"],"layout":"IPY_MODEL_132387611f1b403599fd0703647da6f0"}},"2dfdc244d72e490aa45b7cd789eafc6d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_208864ce686147269db644fd8841e64a","placeholder":"​","style":"IPY_MODEL_a80fefec009b4c6b9bfda4de9aebec92","value":"config.json: 100%"}},"716e42ecc14246e9b9bf0466d0df0d55":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_798f2f9a4ab14e838c73f69d48ed64c1","max":482,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8e8dbb84146c464498d1565cb70f5f56","value":482}},"1761aeffa8424af1aa43dc021a915222":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2055679f50954fa3b43379c32714b0fb","placeholder":"​","style":"IPY_MODEL_e1e1c088373244488f2e1fad9d1e2ada","value":" 482/482 [00:00&lt;00:00, 39.5kB/s]"}},"132387611f1b403599fd0703647da6f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"208864ce686147269db644fd8841e64a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a80fefec009b4c6b9bfda4de9aebec92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"798f2f9a4ab14e838c73f69d48ed64c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e8dbb84146c464498d1565cb70f5f56":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2055679f50954fa3b43379c32714b0fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1e1c088373244488f2e1fad9d1e2ada":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f75c0fc398e847409148eeee362b1594":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_869c9d878cec4702b463c7ff7ea2527c","IPY_MODEL_f17e36d6e7984b429e5b14baa575ba05","IPY_MODEL_7bde16bd52104585902355c627c0ffdf"],"layout":"IPY_MODEL_23430ca21cac44ae942f3f6c882e4e13"}},"869c9d878cec4702b463c7ff7ea2527c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f262d61a0d3e4f6692fc4fc9f4501e9e","placeholder":"​","style":"IPY_MODEL_010ff152cecb4736b493c446f027f421","value":"vocab.json: 100%"}},"f17e36d6e7984b429e5b14baa575ba05":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_33e94044f5b84c7499bbb5bc024ea9e9","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_57fe7062a7704d9ba2d45d2195e34d79","value":898823}},"7bde16bd52104585902355c627c0ffdf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ebc4362474541cd998ed15a4d03175f","placeholder":"​","style":"IPY_MODEL_e474aa00f8aa450fa6c66e910feac734","value":" 899k/899k [00:00&lt;00:00, 4.68MB/s]"}},"23430ca21cac44ae942f3f6c882e4e13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f262d61a0d3e4f6692fc4fc9f4501e9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"010ff152cecb4736b493c446f027f421":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"33e94044f5b84c7499bbb5bc024ea9e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57fe7062a7704d9ba2d45d2195e34d79":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8ebc4362474541cd998ed15a4d03175f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e474aa00f8aa450fa6c66e910feac734":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5e6256b7458459a842e8fd143393488":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_606d5e63e664451cb30916af48002e70","IPY_MODEL_643b90ec49b14418b37b9289b747ca9e","IPY_MODEL_1f593b605f404d01acd6c60c1b543e8d"],"layout":"IPY_MODEL_38cc378881034f1aa6b32338908c2232"}},"606d5e63e664451cb30916af48002e70":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a9ac7bec18c40fdb15fe9c2efb7583e","placeholder":"​","style":"IPY_MODEL_08b8cdd547d94d2ba1ef9571492ced21","value":"merges.txt: 100%"}},"643b90ec49b14418b37b9289b747ca9e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f3bd98ae7e145589acde67735a2baca","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c8d5a772a6fb455685b3c86849ca3ef1","value":456318}},"1f593b605f404d01acd6c60c1b543e8d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b68c1d96c40743dca69e8b4c12b22500","placeholder":"​","style":"IPY_MODEL_6e98b2c6d45c43e88416eca15538f06e","value":" 456k/456k [00:00&lt;00:00, 2.37MB/s]"}},"38cc378881034f1aa6b32338908c2232":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a9ac7bec18c40fdb15fe9c2efb7583e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08b8cdd547d94d2ba1ef9571492ced21":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f3bd98ae7e145589acde67735a2baca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8d5a772a6fb455685b3c86849ca3ef1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b68c1d96c40743dca69e8b4c12b22500":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e98b2c6d45c43e88416eca15538f06e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a15db6a3c6074a0588eef786f2e8b028":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d89444486a964663b6bf1e456c12b109","IPY_MODEL_c933110165214244b507f8fb854a37b1","IPY_MODEL_c346e1fab88740da8d97ba4a5ed8fc85"],"layout":"IPY_MODEL_c5eeb553daa74e3e98de3d2c1b96937c"}},"d89444486a964663b6bf1e456c12b109":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_09041cb742cc49259e8424441b0e9c30","placeholder":"​","style":"IPY_MODEL_986499c5345540599b7c97c16f3f6dde","value":"tokenizer.json: 100%"}},"c933110165214244b507f8fb854a37b1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cdc7fd14c3049ba867d10b38db7583e","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c7a0344c55c444a9928a974857a32ba8","value":1355863}},"c346e1fab88740da8d97ba4a5ed8fc85":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_728dbd8280db4536bf9bb1825c04899a","placeholder":"​","style":"IPY_MODEL_79bb373d64ee4f8a939cea6bc1e57dfe","value":" 1.36M/1.36M [00:00&lt;00:00, 6.85MB/s]"}},"c5eeb553daa74e3e98de3d2c1b96937c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09041cb742cc49259e8424441b0e9c30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"986499c5345540599b7c97c16f3f6dde":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4cdc7fd14c3049ba867d10b38db7583e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7a0344c55c444a9928a974857a32ba8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"728dbd8280db4536bf9bb1825c04899a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79bb373d64ee4f8a939cea6bc1e57dfe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6bf992d954c54f4599dbce22dc6025f3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_74edfd6f4e4042758f530169544c9053","IPY_MODEL_bf1373021b8c4719bda82e033ab29871","IPY_MODEL_5ad1312058e04fc49f697c406d04bc6a"],"layout":"IPY_MODEL_3c72eb5e512f41f2831eaba45e0c7da2"}},"74edfd6f4e4042758f530169544c9053":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_22179cff6448451eaf86b619b9ede6ea","placeholder":"​","style":"IPY_MODEL_be3e49a095284eb48d402ba19a545be0","value":"model.safetensors: 100%"}},"bf1373021b8c4719bda82e033ab29871":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6fd8eba231f4c209774263fd043e159","max":1421700479,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a8b0e62b1ee94cffbc5ca4708121660f","value":1421700479}},"5ad1312058e04fc49f697c406d04bc6a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27f4079200f84c918386337b10eb10f2","placeholder":"​","style":"IPY_MODEL_0409dd8c5db74be4be420fa4dabd1fa9","value":" 1.42G/1.42G [00:06&lt;00:00, 224MB/s]"}},"3c72eb5e512f41f2831eaba45e0c7da2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22179cff6448451eaf86b619b9ede6ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be3e49a095284eb48d402ba19a545be0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6fd8eba231f4c209774263fd043e159":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8b0e62b1ee94cffbc5ca4708121660f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"27f4079200f84c918386337b10eb10f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0409dd8c5db74be4be420fa4dabd1fa9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b88f3ce179f4535a268db64112b4044":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_76e386f537924548af1d9ea8d63bf9a9","IPY_MODEL_8e0f1e74824643e1b5fdcd7d6a324e04","IPY_MODEL_e72056efa8c34775ab19f3facdc5081b"],"layout":"IPY_MODEL_77ec2390dde346ce9a011b9d17c2f25d"}},"76e386f537924548af1d9ea8d63bf9a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f896fef8482540faa5250a970bab70cd","placeholder":"​","style":"IPY_MODEL_1582241783354acd82436af30d0773e3","value":"config.json: 100%"}},"8e0f1e74824643e1b5fdcd7d6a324e04":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d455eabab4b46b4aa5b187b9094ad66","max":613,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4ec294ddd0ce4c46b6d02db223fbb31b","value":613}},"e72056efa8c34775ab19f3facdc5081b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68ae5e6ac94a479ba6090ff5d16a5784","placeholder":"​","style":"IPY_MODEL_b73f6508deef4771b0bb582adefddd07","value":" 613/613 [00:00&lt;00:00, 50.8kB/s]"}},"77ec2390dde346ce9a011b9d17c2f25d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f896fef8482540faa5250a970bab70cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1582241783354acd82436af30d0773e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9d455eabab4b46b4aa5b187b9094ad66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ec294ddd0ce4c46b6d02db223fbb31b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"68ae5e6ac94a479ba6090ff5d16a5784":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b73f6508deef4771b0bb582adefddd07":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"46d2f9dd666a4073980aa390d99f4a10":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ed0227e154dc4f38bcccc66fad240472","IPY_MODEL_1d10c1add57e4b58984e0a1bf3818c5e","IPY_MODEL_a3df28712a2047e59d3b0c878316c5ac"],"layout":"IPY_MODEL_56a9e33e98284e88a0c1af98bb91b600"}},"ed0227e154dc4f38bcccc66fad240472":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96f36b53bb0d4097a5f6337e8de269a3","placeholder":"​","style":"IPY_MODEL_3e7b2c0bbe8b43a8873a6376bfa9a48b","value":"model.safetensors.index.json: 100%"}},"1d10c1add57e4b58984e0a1bf3818c5e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c640fdaeab0045eeb2ce77fc9a3e5d75","max":25125,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d922c6a2cc2a49f4ac4cba6a28e4a1f9","value":25125}},"a3df28712a2047e59d3b0c878316c5ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a677463e5a444488ac8a4226ff6eab4","placeholder":"​","style":"IPY_MODEL_eca8f026f13c47e39a60412b00ab2e28","value":" 25.1k/25.1k [00:00&lt;00:00, 1.99MB/s]"}},"56a9e33e98284e88a0c1af98bb91b600":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96f36b53bb0d4097a5f6337e8de269a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e7b2c0bbe8b43a8873a6376bfa9a48b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c640fdaeab0045eeb2ce77fc9a3e5d75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d922c6a2cc2a49f4ac4cba6a28e4a1f9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a677463e5a444488ac8a4226ff6eab4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eca8f026f13c47e39a60412b00ab2e28":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0909b910140c4905b3b03706ebebae63":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ac040bbb434942aba232e41a73e9a176","IPY_MODEL_a00b51b8399146949d96d73029f8b7c4","IPY_MODEL_788f48a019584c29afd4ef936e63c8ea"],"layout":"IPY_MODEL_c2915605623149c1a7d1d95678a6467b"}},"ac040bbb434942aba232e41a73e9a176":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbb5fd4896b1417d92acd6ed41ffe572","placeholder":"​","style":"IPY_MODEL_efd576a05fb44df491b91978f5381a8a","value":"Downloading shards: 100%"}},"a00b51b8399146949d96d73029f8b7c4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_335c87961d2f4287aa4a82d106ea1bcd","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_66030e453288483daff58b81037c6029","value":8}},"788f48a019584c29afd4ef936e63c8ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a5a1297ce9d409da53e344a06e1472a","placeholder":"​","style":"IPY_MODEL_bfb06a640f9840539e7c5bdb469b2a23","value":" 8/8 [01:23&lt;00:00,  9.97s/it]"}},"c2915605623149c1a7d1d95678a6467b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbb5fd4896b1417d92acd6ed41ffe572":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efd576a05fb44df491b91978f5381a8a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"335c87961d2f4287aa4a82d106ea1bcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66030e453288483daff58b81037c6029":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7a5a1297ce9d409da53e344a06e1472a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfb06a640f9840539e7c5bdb469b2a23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ff72579058b64c61a81b7e635a00314c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_39bb058abec1409ab925e5e2531359d5","IPY_MODEL_71125613d760417689852ac45bf710a6","IPY_MODEL_b2267a160b8c4ba280a91944d1cbd66b"],"layout":"IPY_MODEL_41dbb10d19d540c7b596fd7fd79f0a26"}},"39bb058abec1409ab925e5e2531359d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64706ceb4b02440ba011c6225c09679f","placeholder":"​","style":"IPY_MODEL_c2e62a434c774332a1ede5ede3dfdc63","value":"model-00001-of-00008.safetensors: 100%"}},"71125613d760417689852ac45bf710a6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7bed2ce31e2c4457a1b7802c704ad007","max":1889587008,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d4639e4e83b3464c9686d4309847a0bc","value":1889587008}},"b2267a160b8c4ba280a91944d1cbd66b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4538d5230fa4f7c947270eaef782186","placeholder":"​","style":"IPY_MODEL_f1a928b4f9074f319f3450245a6d70e4","value":" 1.89G/1.89G [00:09&lt;00:00, 212MB/s]"}},"41dbb10d19d540c7b596fd7fd79f0a26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64706ceb4b02440ba011c6225c09679f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2e62a434c774332a1ede5ede3dfdc63":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7bed2ce31e2c4457a1b7802c704ad007":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4639e4e83b3464c9686d4309847a0bc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e4538d5230fa4f7c947270eaef782186":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1a928b4f9074f319f3450245a6d70e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ffc2fa0ac2f4cc08eb1e814ee9d892e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_393e57fe3cd048dfa2bf21f51d5cc2d2","IPY_MODEL_dfb4a254ecf441918b6815217fcc1990","IPY_MODEL_cb0daca8081b49da930a4fbe018619e7"],"layout":"IPY_MODEL_97efa60ab79f430aa9fdfd64472f00d2"}},"393e57fe3cd048dfa2bf21f51d5cc2d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60bc5ebbf4b84fb481b51091e9e874c1","placeholder":"​","style":"IPY_MODEL_83c36d464d024c6badcd55f36ee09744","value":"model-00002-of-00008.safetensors: 100%"}},"dfb4a254ecf441918b6815217fcc1990":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b97d5cdf7664be8ae0305e86ab6582d","max":1946243896,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6005f9be7c5945e0a2e8d9019d68338f","value":1946243896}},"cb0daca8081b49da930a4fbe018619e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5250b887bfb0460a806c105bd485dc74","placeholder":"​","style":"IPY_MODEL_2ea16ea5ba1c404fb2608bdd60c78685","value":" 1.95G/1.95G [00:11&lt;00:00, 94.5MB/s]"}},"97efa60ab79f430aa9fdfd64472f00d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60bc5ebbf4b84fb481b51091e9e874c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83c36d464d024c6badcd55f36ee09744":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b97d5cdf7664be8ae0305e86ab6582d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6005f9be7c5945e0a2e8d9019d68338f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5250b887bfb0460a806c105bd485dc74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ea16ea5ba1c404fb2608bdd60c78685":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f9151c0890e448f94045b87ab40e511":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d2e080d58c6b4d04a32e01247259d53f","IPY_MODEL_8a46b8de8c6140bbb21fe1179cdf1a04","IPY_MODEL_a6e04eaac5b04edaa0a685c74ee652d0"],"layout":"IPY_MODEL_9ea724316a8b418e962050966ccade0c"}},"d2e080d58c6b4d04a32e01247259d53f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3cb248c8089140a99b55efba78537db0","placeholder":"​","style":"IPY_MODEL_20efbb2ce6e34646a200d5d6f69b8f17","value":"model-00003-of-00008.safetensors: 100%"}},"8a46b8de8c6140bbb21fe1179cdf1a04":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_18b5771eb38c42c2813134d886ae0075","max":1979781392,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0769f685be7f4026ae386b9a7eaf39e4","value":1979781392}},"a6e04eaac5b04edaa0a685c74ee652d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_afdbf022e26c42068bac653cc5cd0759","placeholder":"​","style":"IPY_MODEL_9f3b1a45501d458d9c78393273f5ee89","value":" 1.98G/1.98G [00:10&lt;00:00, 203MB/s]"}},"9ea724316a8b418e962050966ccade0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cb248c8089140a99b55efba78537db0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20efbb2ce6e34646a200d5d6f69b8f17":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18b5771eb38c42c2813134d886ae0075":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0769f685be7f4026ae386b9a7eaf39e4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"afdbf022e26c42068bac653cc5cd0759":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f3b1a45501d458d9c78393273f5ee89":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1eb6c18f8d9246dfb372397f9fff7561":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_98df946577cd4cd9a763fa5f2c7cc5d9","IPY_MODEL_050ff746ede2454b8a0e2d047a6a2f05","IPY_MODEL_505eac55eae945c3b8be9cada6c201c7"],"layout":"IPY_MODEL_124adef03fe74af89ddec5166db30241"}},"98df946577cd4cd9a763fa5f2c7cc5d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_693f0c7ac9de4f0cb458d1bc1f301646","placeholder":"​","style":"IPY_MODEL_7c250c0bd4874a5ab91b1e45f1e9a240","value":"model-00004-of-00008.safetensors: 100%"}},"050ff746ede2454b8a0e2d047a6a2f05":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_992fe5b2bc4e45258a1ce60cfb6e56db","max":1946243936,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dd31e8c0d4e14925974885a9befca88a","value":1946243936}},"505eac55eae945c3b8be9cada6c201c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a67e2195a6c9484d938d11a89c125baa","placeholder":"​","style":"IPY_MODEL_26e1e0a138d840a3912592f4214134f7","value":" 1.95G/1.95G [00:09&lt;00:00, 199MB/s]"}},"124adef03fe74af89ddec5166db30241":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"693f0c7ac9de4f0cb458d1bc1f301646":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c250c0bd4874a5ab91b1e45f1e9a240":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"992fe5b2bc4e45258a1ce60cfb6e56db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd31e8c0d4e14925974885a9befca88a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a67e2195a6c9484d938d11a89c125baa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26e1e0a138d840a3912592f4214134f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13f99b77cf504a34b2379b0f6f064004":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a5d62015caeb4491acc81426a0f2ffa6","IPY_MODEL_8e28352fba924c2f8b2241be28b6cd2c","IPY_MODEL_921482a36fab455c8b017ba522a24659"],"layout":"IPY_MODEL_a3696bd03d724459824ea3da9930b046"}},"a5d62015caeb4491acc81426a0f2ffa6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48121fc621df4fd49f34cf1848add391","placeholder":"​","style":"IPY_MODEL_10ddca7ae73446acb2a868d0ae11bd52","value":"model-00005-of-00008.safetensors: 100%"}},"8e28352fba924c2f8b2241be28b6cd2c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c671508fe584bd98ace8264345de3ed","max":1979781416,"min":0,"orientation":"horizontal","style":"IPY_MODEL_42b8b8dd5ebf495bb44b9d6590fd17c1","value":1979781416}},"921482a36fab455c8b017ba522a24659":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e297a86303b42bc8e6b34e07b363856","placeholder":"​","style":"IPY_MODEL_f21fa2310e9f495ea6d60f130101bc68","value":" 1.98G/1.98G [00:09&lt;00:00, 226MB/s]"}},"a3696bd03d724459824ea3da9930b046":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48121fc621df4fd49f34cf1848add391":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10ddca7ae73446acb2a868d0ae11bd52":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c671508fe584bd98ace8264345de3ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42b8b8dd5ebf495bb44b9d6590fd17c1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4e297a86303b42bc8e6b34e07b363856":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f21fa2310e9f495ea6d60f130101bc68":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8b0bcc60b804a1b8e3fdc5fda115b3c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7429356ef2d34f2bb0fdfa2b669e6404","IPY_MODEL_f4c1579497be42f08916a7fd5ac41d6c","IPY_MODEL_2cb73cfe05184ef7a50b7f406a3a2ff9"],"layout":"IPY_MODEL_d9812d18c72c421386fbb45063788a7a"}},"7429356ef2d34f2bb0fdfa2b669e6404":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_169a47fb130f455d98eac87816f2fdc5","placeholder":"​","style":"IPY_MODEL_b402b7a562d74478955b6d09fffd911e","value":"model-00006-of-00008.safetensors: 100%"}},"f4c1579497be42f08916a7fd5ac41d6c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_18fd924786aa417aa210d966c2738155","max":1946243936,"min":0,"orientation":"horizontal","style":"IPY_MODEL_47af062a92da46ebbacc6eb33b459ddc","value":1946243936}},"2cb73cfe05184ef7a50b7f406a3a2ff9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fd113de59a740de8d4ec4d2bc6adf8c","placeholder":"​","style":"IPY_MODEL_32e3190ade0a4633857d73f27257de3f","value":" 1.95G/1.95G [00:10&lt;00:00, 94.9MB/s]"}},"d9812d18c72c421386fbb45063788a7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"169a47fb130f455d98eac87816f2fdc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b402b7a562d74478955b6d09fffd911e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18fd924786aa417aa210d966c2738155":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47af062a92da46ebbacc6eb33b459ddc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1fd113de59a740de8d4ec4d2bc6adf8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32e3190ade0a4633857d73f27257de3f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"baca5bbaf6b047b6a5bc91179ac6e60f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cbf1bf06747c4721b3d399afbbb96ecd","IPY_MODEL_8d708b2b8a154cc884df08e052913503","IPY_MODEL_02a8e76f707b4521a2dd7076edf0471d"],"layout":"IPY_MODEL_97eb7c4ab8f8473fa0612da5f271e8e8"}},"cbf1bf06747c4721b3d399afbbb96ecd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_097818d627e3446099743c8f55f56a66","placeholder":"​","style":"IPY_MODEL_1b88e20848c241b18e33b110989dd9ec","value":"model-00007-of-00008.safetensors: 100%"}},"8d708b2b8a154cc884df08e052913503":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff8ca5890f0c4c279ffea2f9a9e1608f","max":1979781416,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b735c332920943a9b811b094560436c0","value":1979781416}},"02a8e76f707b4521a2dd7076edf0471d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e7a4d1e37624543940a56fcca95d0e9","placeholder":"​","style":"IPY_MODEL_aa275ffa78a24a51bc6e09e5732a3e07","value":" 1.98G/1.98G [00:14&lt;00:00, 152MB/s]"}},"97eb7c4ab8f8473fa0612da5f271e8e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"097818d627e3446099743c8f55f56a66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b88e20848c241b18e33b110989dd9ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ff8ca5890f0c4c279ffea2f9a9e1608f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b735c332920943a9b811b094560436c0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9e7a4d1e37624543940a56fcca95d0e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa275ffa78a24a51bc6e09e5732a3e07":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8fc95fd2ebbc4578a3172d6364fb51bd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_31e57b57dd3d463499ffdee955fc57e1","IPY_MODEL_df37dc54c91246a28d700bf225118ded","IPY_MODEL_3cb90f26991944f6bb4fcade0311928f"],"layout":"IPY_MODEL_cdb899e096584788a633b7c8cde0cdf1"}},"31e57b57dd3d463499ffdee955fc57e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1721f517190045f898be0cbf2868c280","placeholder":"​","style":"IPY_MODEL_b4beb6b7949742b883117a1bf146f519","value":"model-00008-of-00008.safetensors: 100%"}},"df37dc54c91246a28d700bf225118ded":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_15454751bdfe4f44b9479da7fecc65f9","max":815834664,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4b65a058572241039f82495d4c8419ec","value":815834664}},"3cb90f26991944f6bb4fcade0311928f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_299782287d00421b822d7dbfa60ef53e","placeholder":"​","style":"IPY_MODEL_f7c3778cc3eb43fe89eb432073537899","value":" 816M/816M [00:05&lt;00:00, 165MB/s]"}},"cdb899e096584788a633b7c8cde0cdf1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1721f517190045f898be0cbf2868c280":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4beb6b7949742b883117a1bf146f519":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15454751bdfe4f44b9479da7fecc65f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b65a058572241039f82495d4c8419ec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"299782287d00421b822d7dbfa60ef53e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7c3778cc3eb43fe89eb432073537899":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a45618cbc074a698042fb2b88540841":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ab9d7f8518094f048a9fbbae5f2f9248","IPY_MODEL_f82288eb334e47a8b9b43fdbcc9c9c34","IPY_MODEL_f6c49938e1604977beafcbf6029f7573"],"layout":"IPY_MODEL_893080d3b0cd410a84fd17f508145719"}},"ab9d7f8518094f048a9fbbae5f2f9248":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c5d628b80794f8ca8115a384602ba9e","placeholder":"​","style":"IPY_MODEL_ba77a5a3f10a4974b5e900e3868f0b1b","value":"Loading checkpoint shards: 100%"}},"f82288eb334e47a8b9b43fdbcc9c9c34":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5538af4e5c743f7a54916729d81713b","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_46852ac449c04a28b234fcb892f43e2c","value":8}},"f6c49938e1604977beafcbf6029f7573":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d83581db0e1146be95868f340c0831ad","placeholder":"​","style":"IPY_MODEL_c082ea898edc4b28934b57c408c7315d","value":" 8/8 [00:06&lt;00:00,  1.27it/s]"}},"893080d3b0cd410a84fd17f508145719":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c5d628b80794f8ca8115a384602ba9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba77a5a3f10a4974b5e900e3868f0b1b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5538af4e5c743f7a54916729d81713b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46852ac449c04a28b234fcb892f43e2c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d83581db0e1146be95868f340c0831ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c082ea898edc4b28934b57c408c7315d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d4b813486208417eb30ff1ac172b3d93":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7ef7a8daa06b4596ba57c0c186053622","IPY_MODEL_19e0c73a56f740d097416540c1cb485d","IPY_MODEL_dd3ddc5b4d8d4f16ba629b489e042b00"],"layout":"IPY_MODEL_7920394f6a5349ecb3dc8f2b0ca9a4c2"}},"7ef7a8daa06b4596ba57c0c186053622":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a41852720a5f4c28922c8da43b0b3188","placeholder":"​","style":"IPY_MODEL_94778f44c7c04209bc4eca233796fb93","value":"generation_config.json: 100%"}},"19e0c73a56f740d097416540c1cb485d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c814d25136e43d68180570e1232a208","max":111,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5d74b90a682f4debb09c6fd45e53a3b9","value":111}},"dd3ddc5b4d8d4f16ba629b489e042b00":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef0ad3d9033d4b418e08460ec8661a32","placeholder":"​","style":"IPY_MODEL_8b4b84a3e87a4be6aae1c8ebde8867e6","value":" 111/111 [00:00&lt;00:00, 9.82kB/s]"}},"7920394f6a5349ecb3dc8f2b0ca9a4c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a41852720a5f4c28922c8da43b0b3188":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94778f44c7c04209bc4eca233796fb93":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c814d25136e43d68180570e1232a208":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d74b90a682f4debb09c6fd45e53a3b9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ef0ad3d9033d4b418e08460ec8661a32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b4b84a3e87a4be6aae1c8ebde8867e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}